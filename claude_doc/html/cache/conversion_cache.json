{
  "../03_chat.md": {
    "hash": "b5a806c25b10ace7bd6d29f8e81e75b7",
    "content": "<h1 id=\"chatpy\">chat.py \u6587\u4ef6\u5206\u6790\u6587\u6863</h1>\n<h2 id=\"_1\">\u6587\u4ef6\u6982\u8ff0\u548c\u4f5c\u7528</h2>\n<p><code>chat.py</code> \u6587\u4ef6\u662f GPT-OSS \u9879\u76ee\u7684\u6838\u5fc3\u4ea4\u4e92\u5f0f\u804a\u5929\u6a21\u5757\uff0c\u5b9e\u73b0\u4e86\u4e00\u4e2a\u529f\u80fd\u4e30\u5bcc\u7684\u547d\u4ee4\u884c\u5bf9\u8bdd\u754c\u9762\u3002\u8be5\u6587\u4ef6\u4f4d\u4e8e <code>/gpt_oss/chat.py</code>\uff08\u7b2c1\u884c\uff09\uff0c\u63d0\u4f9b\u4e86\u4e0e\u4e0d\u540c\u63a8\u7406\u540e\u7aef\uff08Triton\u3001Torch\u3001VLLM\uff09\u7684\u7edf\u4e00\u63a5\u53e3\uff0c\u652f\u6301\u591a\u79cd\u5de5\u5177\u96c6\u6210\uff0c\u5e76\u4f7f\u7528 OpenAI Harmony \u6d88\u606f\u683c\u5f0f\u8fdb\u884c\u5bf9\u8bdd\u7ba1\u7406\u3002</p>\n<p>\u4e3b\u8981\u4f5c\u7528\u5305\u62ec\uff1a</p>\n<ul>\n<li>\u63d0\u4f9b\u547d\u4ee4\u884c\u804a\u5929\u754c\u9762</li>\n<li>\u96c6\u6210\u591a\u79cd\u63a8\u7406\u540e\u7aef\uff08Triton\u3001Torch\u3001VLLM\uff09</li>\n<li>\u652f\u6301\u5de5\u5177\u8c03\u7528\uff08\u6d4f\u89c8\u5668\u641c\u7d22\u3001Python \u6267\u884c\u3001\u4ee3\u7801\u8865\u4e01\u5e94\u7528\uff09</li>\n<li>\u5904\u7406 Harmony \u683c\u5f0f\u7684\u6d88\u606f\u7f16\u7801\u548c\u89e3\u7801</li>\n<li>\u652f\u6301\u5206\u5e03\u5f0f\u63a8\u7406\u548c\u591a\u8fdb\u7a0b\u8f93\u5165</li>\n</ul>\n<h2 id=\"_2\">\u4e3b\u8981\u529f\u80fd\u548c\u7279\u6027</h2>\n<h3 id=\"_3\">\u6838\u5fc3\u529f\u80fd\u7279\u6027</h3>\n<ol>\n<li>\n<p><strong>\u591a\u540e\u7aef\u63a8\u7406\u652f\u6301</strong>\uff08\u7b2c62-77\u884c\uff09\n   - Triton \u540e\u7aef\uff1a\u9ad8\u6027\u80fd\u63a8\u7406\u5f15\u64ce\n   - Torch \u540e\u7aef\uff1a\u57fa\u4e8e PyTorch \u7684\u63a8\u7406\n   - VLLM \u540e\u7aef\uff1a\u4f18\u5316\u7684\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406</p>\n</li>\n<li>\n<p><strong>\u5de5\u5177\u96c6\u6210\u751f\u6001</strong>\uff08\u7b2c87-96\u884c\uff09\n   - \u6d4f\u89c8\u5668\u641c\u7d22\u5de5\u5177\uff08SimpleBrowserTool + ExaBackend\uff09\n   - Python \u4ee3\u7801\u6267\u884c\u5de5\u5177\uff08PythonTool\uff09\n   - \u4ee3\u7801\u8865\u4e01\u5e94\u7528\u5de5\u5177\uff08apply_patch\uff09</p>\n</li>\n<li>\n<p><strong>Harmony \u6d88\u606f\u683c\u5f0f</strong>\uff08\u7b2c25-39\u884c\uff09\n   - \u4f7f\u7528 openai_harmony \u5e93\u5904\u7406\u6d88\u606f\n   - \u652f\u6301\u63a8\u7406\u52aa\u529b\u7b49\u7ea7\u914d\u7f6e\n   - \u7cfb\u7edf\u6d88\u606f\u3001\u7528\u6237\u6d88\u606f\u3001\u5f00\u53d1\u8005\u6d88\u606f\u7684\u7edf\u4e00\u683c\u5f0f</p>\n</li>\n<li>\n<p><strong>\u5206\u5e03\u5f0f\u8f93\u5165\u5904\u7406</strong>\uff08\u7b2c49-58\u884c\uff09\n   - \u652f\u6301 PyTorch \u5206\u5e03\u5f0f\u8bad\u7ec3\u73af\u5883\n   - \u591a\u8fdb\u7a0b\u95f4\u7684\u7528\u6237\u8f93\u5165\u540c\u6b65</p>\n</li>\n</ol>\n<h2 id=\"_4\">\u547d\u4ee4\u884c\u53c2\u6570\u8be6\u89e3</h2>\n<h3 id=\"_5\">\u5fc5\u9700\u53c2\u6570</h3>\n<ul>\n<li><strong>checkpoint</strong> (\u4f4d\u7f6e\u53c2\u6570\uff0c\u7b2c291-295\u884c)</li>\n<li>\u7c7b\u578b\uff1a\u5b57\u7b26\u4e32</li>\n<li>\u63cf\u8ff0\uff1aSafeTensors \u68c0\u67e5\u70b9\u6587\u4ef6\u8def\u5f84</li>\n<li>\u7528\u9014\uff1a\u6307\u5b9a\u6a21\u578b\u6743\u91cd\u6587\u4ef6</li>\n</ul>\n<h3 id=\"_6\">\u53ef\u9009\u53c2\u6570</h3>\n<h4 id=\"_7\">\u63a8\u7406\u914d\u7f6e\u53c2\u6570</h4>\n<ul>\n<li><strong><code>--reasoning-effort</code></strong> / <strong><code>-r</code></strong> (\u7b2c297-304\u884c)</li>\n<li>\u9ed8\u8ba4\u503c\uff1a<code>\"low\"</code></li>\n<li>\u9009\u62e9\uff1a<code>[\"high\", \"medium\", \"low\"]</code></li>\n<li>\n<p>\u529f\u80fd\uff1a\u8bbe\u7f6e\u6a21\u578b\u63a8\u7406\u52aa\u529b\u7b49\u7ea7\uff0c\u5f71\u54cd\u601d\u7ef4\u94fe\u590d\u6742\u5ea6</p>\n</li>\n<li>\n<p><strong><code>--context</code></strong> / <strong><code>-c</code></strong> (\u7b2c337-343\u884c)</p>\n</li>\n<li>\u9ed8\u8ba4\u503c\uff1a<code>8192</code></li>\n<li>\u7c7b\u578b\uff1a\u6574\u6570</li>\n<li>\n<p>\u529f\u80fd\uff1a\u8bbe\u7f6e\u6700\u5927\u4e0a\u4e0b\u6587\u957f\u5ea6</p>\n</li>\n<li>\n<p><strong><code>--backend</code></strong> (\u7b2c351-356\u884c)</p>\n</li>\n<li>\u9ed8\u8ba4\u503c\uff1a<code>\"triton\"</code></li>\n<li>\u9009\u62e9\uff1a<code>[\"triton\", \"torch\", \"vllm\"]</code></li>\n<li>\u529f\u80fd\uff1a\u9009\u62e9\u63a8\u7406\u540e\u7aef\u5f15\u64ce</li>\n</ul>\n<h4 id=\"_8\">\u5de5\u5177\u542f\u7528\u53c2\u6570</h4>\n<ul>\n<li><strong><code>--apply-patch</code></strong> / <strong><code>-a</code></strong> (\u7b2c307-310\u884c)</li>\n<li>\u7c7b\u578b\uff1a\u5e03\u5c14\u6807\u5fd7</li>\n<li>\n<p>\u529f\u80fd\uff1a\u542f\u7528\u4ee3\u7801\u8865\u4e01\u5e94\u7528\u529f\u80fd</p>\n</li>\n<li>\n<p><strong><code>--browser</code></strong> / <strong><code>-b</code></strong> (\u7b2c312-317\u884c)</p>\n</li>\n<li>\u9ed8\u8ba4\u503c\uff1a<code>False</code></li>\n<li>\n<p>\u529f\u80fd\uff1a\u542f\u7528\u6d4f\u89c8\u5668\u641c\u7d22\u5de5\u5177</p>\n</li>\n<li>\n<p><strong><code>--python</code></strong> / <strong><code>-p</code></strong> (\u7b2c325-330\u884c)</p>\n</li>\n<li>\u9ed8\u8ba4\u503c\uff1a<code>False</code></li>\n<li>\u529f\u80fd\uff1a\u542f\u7528 Python \u4ee3\u7801\u6267\u884c\u5de5\u5177</li>\n</ul>\n<h4 id=\"_9\">\u663e\u793a\u548c\u8c03\u8bd5\u53c2\u6570</h4>\n<ul>\n<li><strong><code>--show-browser-results</code></strong> (\u7b2c318-323\u884c)</li>\n<li>\u9ed8\u8ba4\u503c\uff1a<code>False</code></li>\n<li>\n<p>\u529f\u80fd\uff1a\u663e\u793a\u6d4f\u89c8\u5668\u641c\u7d22\u7ed3\u679c\u8be6\u60c5</p>\n</li>\n<li>\n<p><strong><code>--raw</code></strong> (\u7b2c345-349\u884c)</p>\n</li>\n<li>\u9ed8\u8ba4\u503c\uff1a<code>False</code></li>\n<li>\n<p>\u529f\u80fd\uff1a\u539f\u59cb\u6a21\u5f0f\uff0c\u4e0d\u6e32\u67d3 Harmony \u7f16\u7801\u683c\u5f0f</p>\n</li>\n<li>\n<p><strong><code>--developer-message</code></strong> (\u7b2c332-335\u884c)</p>\n</li>\n<li>\u9ed8\u8ba4\u503c\uff1a\u7a7a\u5b57\u7b26\u4e32</li>\n<li>\u529f\u80fd\uff1a\u6dfb\u52a0\u5f00\u53d1\u8005\u6307\u4ee4\u6d88\u606f</li>\n</ul>\n<h2 id=\"_10\">\u6838\u5fc3\u51fd\u6570\u548c\u7c7b\u7684\u8be6\u7ec6\u8bf4\u660e</h2>\n<h3 id=\"get_user_input-49-58\"><code>get_user_input()</code> \u51fd\u6570\uff08\u7b2c49-58\u884c\uff09</h3>\n<p><strong>\u529f\u80fd</strong>\uff1a\u5904\u7406\u5206\u5e03\u5f0f\u73af\u5883\u4e0b\u7684\u7528\u6237\u8f93\u5165\u83b7\u53d6</p>\n<p><strong>\u5b9e\u73b0\u673a\u5236</strong>\uff1a</p>\n<pre class=\"codehilite\"><code class=\"language-python\">def get_user_input():\n    rank = torch.distributed.get_rank() if torch.distributed.is_initialized() else 0\n    if rank == 0:\n        user_input = input()\n    else:\n        user_input = &quot;&quot;\n    user_input_list = [user_input]\n    if torch.distributed.is_initialized():\n        torch.distributed.broadcast_object_list(user_input_list, 0)\n    return user_input_list[0]\n</code></pre>\n\n<p><strong>\u6280\u672f\u8981\u70b9</strong>\uff1a</p>\n<ul>\n<li>\u53ea\u5728 rank 0 \u8fdb\u7a0b\u83b7\u53d6\u5b9e\u9645\u8f93\u5165</li>\n<li>\u4f7f\u7528 <code>broadcast_object_list</code> \u5c06\u8f93\u5165\u540c\u6b65\u5230\u6240\u6709\u8fdb\u7a0b</li>\n<li>\u786e\u4fdd\u5206\u5e03\u5f0f\u8bad\u7ec3\u73af\u5883\u4e0b\u7684\u8f93\u5165\u4e00\u81f4\u6027</li>\n</ul>\n<h3 id=\"mainargs-61-283\"><code>main(args)</code> \u51fd\u6570\uff08\u7b2c61-283\u884c\uff09</h3>\n<p><strong>\u529f\u80fd</strong>\uff1a\u4e3b\u7a0b\u5e8f\u5165\u53e3\uff0c\u534f\u8c03\u6240\u6709\u7ec4\u4ef6\u7684\u521d\u59cb\u5316\u548c\u8fd0\u884c</p>\n<h4 id=\"62-77\">\u63a8\u7406\u540e\u7aef\u521d\u59cb\u5316\uff08\u7b2c62-77\u884c\uff09</h4>\n<p><strong>Triton \u540e\u7aef</strong>\uff08\u7b2c63-67\u884c\uff09\uff1a</p>\n<pre class=\"codehilite\"><code class=\"language-python\">case &quot;triton&quot;:\n    from gpt_oss.triton.model import TokenGenerator as TritonGenerator\n    from gpt_oss.torch.utils import init_distributed\n    device = init_distributed()\n    generator = TritonGenerator(args.checkpoint, args.context, device)\n</code></pre>\n\n<p><strong>Torch \u540e\u7aef</strong>\uff08\u7b2c68-72\u884c\uff09\uff1a</p>\n<pre class=\"codehilite\"><code class=\"language-python\">case &quot;torch&quot;:\n    from gpt_oss.torch.model import TokenGenerator as TorchGenerator\n    from gpt_oss.torch.utils import init_distributed\n    device = init_distributed()\n    generator = TorchGenerator(args.checkpoint, device)\n</code></pre>\n\n<p><strong>VLLM \u540e\u7aef</strong>\uff08\u7b2c73-75\u884c\uff09\uff1a</p>\n<pre class=\"codehilite\"><code class=\"language-python\">case &quot;vllm&quot;:\n    from gpt_oss.vllm.token_generator import TokenGenerator as VLLMGenerator\n    generator = VLLMGenerator(args.checkpoint, tensor_parallel_size=2)\n</code></pre>\n\n<h4 id=\"81-85\">\u7cfb\u7edf\u6d88\u606f\u6784\u5efa\uff08\u7b2c81-85\u884c\uff09</h4>\n<pre class=\"codehilite\"><code class=\"language-python\">system_message_content = (\n    SystemContent.new()\n    .with_reasoning_effort(REASONING_EFFORT[args.reasoning_effort])\n    .with_conversation_start_date(datetime.datetime.now().strftime(&quot;%Y-%m-%d&quot;))\n)\n</code></pre>\n\n<p><strong>\u6280\u672f\u7279\u70b9</strong>\uff1a</p>\n<ul>\n<li>\u4f7f\u7528\u94fe\u5f0f\u8c03\u7528\u6784\u5efa\u7cfb\u7edf\u6d88\u606f</li>\n<li>\u914d\u7f6e\u63a8\u7406\u52aa\u529b\u7b49\u7ea7</li>\n<li>\u8bbe\u7f6e\u5bf9\u8bdd\u5f00\u59cb\u65e5\u671f</li>\n</ul>\n<h2 id=\"_11\">\u5de5\u5177\u96c6\u6210\u673a\u5236</h2>\n<h3 id=\"87-92\">\u6d4f\u89c8\u5668\u5de5\u5177\u96c6\u6210\uff08\u7b2c87-92\u884c\uff09</h3>\n<pre class=\"codehilite\"><code class=\"language-python\">if args.browser:\n    backend = ExaBackend(source=&quot;web&quot;)\n    browser_tool = SimpleBrowserTool(backend=backend)\n    system_message_content = system_message_content.with_tools(browser_tool.tool_config)\n</code></pre>\n\n<p><strong>\u5b9e\u73b0\u8981\u70b9</strong>\uff1a</p>\n<ul>\n<li>\u4f7f\u7528 ExaBackend \u4f5c\u4e3a\u641c\u7d22\u540e\u7aef</li>\n<li>SimpleBrowserTool \u5c01\u88c5\u641c\u7d22\u529f\u80fd</li>\n<li>\u901a\u8fc7 <code>with_tools()</code> \u5c06\u5de5\u5177\u914d\u7f6e\u6dfb\u52a0\u5230\u7cfb\u7edf\u6d88\u606f</li>\n</ul>\n<h3 id=\"python-94-96\">Python \u5de5\u5177\u96c6\u6210\uff08\u7b2c94-96\u884c\uff09</h3>\n<pre class=\"codehilite\"><code class=\"language-python\">if args.python:\n    python_tool = PythonTool()\n    system_message_content = system_message_content.with_tools(python_tool.tool_config)\n</code></pre>\n\n<h3 id=\"apply_patch-101-122\">apply_patch \u5de5\u5177\u96c6\u6210\uff08\u7b2c101-122\u884c\uff09</h3>\n<p><strong>\u7279\u6b8a\u5904\u7406</strong>\uff1a</p>\n<pre class=\"codehilite\"><code class=\"language-python\">if args.apply_patch:\n    apply_patch_instructions = Path(apply_patch.__file__).parent / &quot;apply_patch.md&quot;\n    developer_message = &quot;&quot;\n    if args.developer_message:\n        developer_message = args.developer_message + &quot;\\n&quot;\n    developer_message += apply_patch_instructions.read_text()\n    developer_message_content = (\n        DeveloperContent.new()\n        .with_instructions(developer_message)\n        .with_function_tools([\n            ToolDescription.new(\n                &quot;apply_patch&quot;,\n                &quot;Patch a file&quot;,\n                parameters={\n                    &quot;type&quot;: &quot;string&quot;,\n                    &quot;description&quot;: &quot;Formatted patch code&quot;,\n                    &quot;default&quot;: &quot;*** Begin Patch\\n*** End Patch\\n&quot;,\n                }\n            ),\n        ])\n    )\n</code></pre>\n\n<p><strong>\u6280\u672f\u8981\u70b9</strong>\uff1a</p>\n<ul>\n<li>\u8bfb\u53d6\u5916\u90e8\u6307\u4ee4\u6587\u4ef6\uff08apply_patch.md\uff09</li>\n<li>\u521b\u5efa DeveloperContent \u7c7b\u578b\u6d88\u606f</li>\n<li>\u5b9a\u4e49\u51fd\u6570\u5de5\u5177\u7684\u53c2\u6570\u7ed3\u6784</li>\n</ul>\n<h2 id=\"harmony\">Harmony\u683c\u5f0f\u6d88\u606f\u5904\u7406</h2>\n<h3 id=\"79\">\u7f16\u7801\u521d\u59cb\u5316\uff08\u7b2c79\u884c\uff09</h3>\n<pre class=\"codehilite\"><code class=\"language-python\">encoding = load_harmony_encoding(HarmonyEncodingName.HARMONY_GPT_OSS)\n</code></pre>\n\n<h3 id=\"129-136\">\u539f\u59cb\u6a21\u5f0f\u5904\u7406\uff08\u7b2c129-136\u884c\uff09</h3>\n<pre class=\"codehilite\"><code class=\"language-python\">if args.raw:\n    conversation = Conversation.from_messages(messages)\n    tokens = encoding.render_conversation(conversation)\n    system_message = encoding.decode(tokens)\n    print(system_message, flush=True, end=&quot;&quot;)\n    empty_user_message_tokens = encoding.render(Message.from_role_and_content(Role.USER, &quot;&quot;))\n    user_message_start = encoding.decode(empty_user_message_tokens[:-1])\n    user_message_end = encoding.decode(empty_user_message_tokens[-1:])\n</code></pre>\n\n<p><strong>\u6280\u672f\u673a\u5236</strong>\uff1a</p>\n<ul>\n<li>\u5c06\u6d88\u606f\u5217\u8868\u8f6c\u6362\u4e3a Conversation \u5bf9\u8c61</li>\n<li>\u4f7f\u7528 <code>render_conversation()</code> \u751f\u6210\u4ee4\u724c\u5e8f\u5217</li>\n<li>\u4f7f\u7528 <code>decode()</code> \u8fd8\u539f\u4e3a\u6587\u672c\u683c\u5f0f</li>\n<li>\u5206\u79bb\u7528\u6237\u6d88\u606f\u7684\u5f00\u59cb\u548c\u7ed3\u675f\u6807\u8bb0</li>\n</ul>\n<h3 id=\"244-283\">\u6d41\u5f0f\u89e3\u6790\u5904\u7406\uff08\u7b2c244-283\u884c\uff09</h3>\n<pre class=\"codehilite\"><code class=\"language-python\">parser = StreamableParser(encoding, role=Role.ASSISTANT)\nfield_created = False\ncurrent_output_text = &quot;&quot;\noutput_text_delta_buffer = &quot;&quot;\nfor predicted_token in generator.generate(tokens, encoding.stop_tokens_for_assistant_actions()):\n    parser.process(predicted_token)\n    if args.raw:\n        print(encoding.decode([predicted_token]), end=&quot;&quot;, flush=True)\n        continue\n\n    if parser.state == StreamState.EXPECT_START:\n        print(&quot;&quot;)  # new line\n        field_created = False\n\n    if not parser.last_content_delta:\n        continue\n\n    if not field_created:\n        field_created = True\n        if parser.current_channel == &quot;final&quot;:\n            print(termcolor.colored(&quot;Assistant:&quot;, &quot;green&quot;), flush=True)\n        elif parser.current_recipient is not None:\n            print(termcolor.colored(f&quot;Tool call to {parser.current_recipient}:&quot;, &quot;cyan&quot;), flush=True)\n        else:\n            print(termcolor.colored(&quot;CoT:&quot;, &quot;yellow&quot;), flush=True)\n</code></pre>\n\n<p><strong>\u5173\u952e\u6280\u672f</strong>\uff1a</p>\n<ul>\n<li>StreamableParser \u5b9e\u65f6\u89e3\u6790\u751f\u6210\u7684\u4ee4\u724c</li>\n<li>\u6839\u636e\u89e3\u6790\u72b6\u6001\uff08StreamState\uff09\u63a7\u5236\u663e\u793a\u683c\u5f0f</li>\n<li>\u533a\u5206\u6700\u7ec8\u56de\u7b54\uff08final\uff09\u3001\u5de5\u5177\u8c03\u7528\u548c\u601d\u7ef4\u94fe\uff08CoT\uff09</li>\n</ul>\n<h2 id=\"_12\">\u63a8\u7406\u540e\u7aef\u5207\u6362\u673a\u5236</h2>\n<h3 id=\"62-77_1\">\u540e\u7aef\u9009\u62e9\u903b\u8f91\uff08\u7b2c62-77\u884c\uff09</h3>\n<p>\u4f7f\u7528 Python 3.10+ \u7684 match-case \u8bed\u6cd5\u8fdb\u884c\u540e\u7aef\u9009\u62e9\uff1a</p>\n<pre class=\"codehilite\"><code class=\"language-python\">match args.backend:\n    case &quot;triton&quot;:\n        from gpt_oss.triton.model import TokenGenerator as TritonGenerator\n        from gpt_oss.torch.utils import init_distributed\n        device = init_distributed()\n        generator = TritonGenerator(args.checkpoint, args.context, device)\n    case &quot;torch&quot;:\n        from gpt_oss.torch.model import TokenGenerator as TorchGenerator\n        from gpt_oss.torch.utils import init_distributed\n        device = init_distributed()\n        generator = TorchGenerator(args.checkpoint, device)\n    case &quot;vllm&quot;:\n        from gpt_oss.vllm.token_generator import VLLMGenerator\n        generator = VLLMGenerator(args.checkpoint, tensor_parallel_size=2)\n    case _:\n        raise ValueError(f&quot;Invalid backend: {args.backend}&quot;)\n</code></pre>\n\n<h3 id=\"_13\">\u540e\u7aef\u7edf\u4e00\u63a5\u53e3</h3>\n<p>\u6240\u6709\u540e\u7aef\u90fd\u5b9e\u73b0\u76f8\u540c\u7684 <code>TokenGenerator</code> \u63a5\u53e3\uff1a</p>\n<ul>\n<li>\u6784\u9020\u51fd\u6570\u63a5\u53d7\u68c0\u67e5\u70b9\u8def\u5f84</li>\n<li>\u63d0\u4f9b <code>generate()</code> \u65b9\u6cd5\u8fdb\u884c\u4ee4\u724c\u751f\u6210</li>\n<li>\u652f\u6301\u505c\u6b62\u4ee4\u724c\u914d\u7f6e</li>\n</ul>\n<h2 id=\"_14\">\u4ea4\u4e92\u6d41\u7a0b\u5206\u6790</h2>\n<h3 id=\"153-283\">\u4e3b\u5faa\u73af\u7ed3\u6784\uff08\u7b2c153-283\u884c\uff09</h3>\n<pre class=\"codehilite\"><code class=\"language-python\">while True:\n    last_message = messages[-1]\n    if last_message.recipient is None:\n        # \u5904\u7406\u7528\u6237\u8f93\u5165\n    else:\n        # \u5904\u7406\u5de5\u5177\u8c03\u7528\n\n    # \u751f\u6210\u52a9\u624b\u56de\u5e94\n    conversation = Conversation.from_messages(messages)\n    tokens = encoding.render_conversation_for_completion(conversation, Role.ASSISTANT)\n    # ... \u6d41\u5f0f\u751f\u6210\u548c\u89e3\u6790\n</code></pre>\n\n<h3 id=\"166-223\">\u5de5\u5177\u8c03\u7528\u5904\u7406\u6d41\u7a0b\uff08\u7b2c166-223\u884c\uff09</h3>\n<p><strong>\u6d4f\u89c8\u5668\u5de5\u5177\u8c03\u7528</strong>\uff08\u7b2c167-177\u884c\uff09\uff1a</p>\n<pre class=\"codehilite\"><code class=\"language-python\">elif last_message.recipient.startswith(&quot;browser.&quot;):\n    assert args.browser, &quot;Browser tool is not enabled&quot;\n    tool_name = &quot;Search&quot;\n    async def run_tool():\n        results = []\n        async for msg in browser_tool.process(last_message):\n            results.append(msg)\n        return results\n\n    result = asyncio.run(run_tool())\n    messages += result\n</code></pre>\n\n<p><strong>Python \u5de5\u5177\u8c03\u7528</strong>\uff08\u7b2c178-188\u884c\uff09\uff1a</p>\n<pre class=\"codehilite\"><code class=\"language-python\">elif last_message.recipient.startswith(&quot;python&quot;):\n    assert args.python, &quot;Python tool is not enabled&quot;\n    tool_name = &quot;Python&quot;\n    async def run_tool():\n        results = []\n        async for msg in python_tool.process(last_message):\n            results.append(msg)\n        return results\n\n    result = asyncio.run(run_tool())\n    messages += result\n</code></pre>\n\n<p><strong>\u8865\u4e01\u5e94\u7528\u5de5\u5177\u8c03\u7528</strong>\uff08\u7b2c189-221\u884c\uff09\uff1a</p>\n<pre class=\"codehilite\"><code class=\"language-python\">elif last_message.recipient == &quot;functions.apply_patch&quot;:\n    assert args.apply_patch, &quot;Apply patch tool is not enabled&quot;\n    tool_name = &quot;Apply Patch&quot;\n    text = last_message.content[0].text\n    tool_output = None\n\n    if text.startswith(&quot;{&quot;):\n        # \u89e3\u6790 JSON \u683c\u5f0f\n        import json\n        try:\n            some_dict = json.loads(text)\n            _, text = some_dict.popitem()\n        except Exception as e:\n            tool_output = f&quot;Error parsing JSON: {e}&quot;\n\n    if tool_output is None:\n        try:\n            tool_output = apply_patch.apply_patch(text)\n        except Exception as e:\n            tool_output = f&quot;Error applying patch: {e}&quot;\n\n    message = (\n        Message(\n            author=Author.new(Role.TOOL, last_message.recipient),\n            content=[TextContent(text=tool_output)]\n        )\n        .with_recipient(&quot;assistant&quot;)\n    )\n</code></pre>\n\n<h3 id=\"359-368\">\u5386\u53f2\u8bb0\u5f55\u7ba1\u7406\uff08\u7b2c359-368\u884c\uff09</h3>\n<pre class=\"codehilite\"><code class=\"language-python\">if int(os.environ.get(&quot;WORLD_SIZE&quot;, 1)) == 1:\n    histfile = os.path.join(os.path.expanduser(&quot;~&quot;), &quot;.chat&quot;)\n    try:\n        readline.read_history_file(histfile)\n        readline.set_history_length(10000)\n    except FileNotFoundError:\n        pass\n\n    atexit.register(readline.write_history_file, histfile)\n</code></pre>\n\n<p><strong>\u6280\u672f\u8981\u70b9</strong>\uff1a</p>\n<ul>\n<li>\u53ea\u5728\u975e\u5206\u5e03\u5f0f\u73af\u5883\u4e0b\u542f\u7528\u5386\u53f2\u8bb0\u5f55</li>\n<li>\u4f7f\u7528 ~/.chat \u6587\u4ef6\u5b58\u50a8\u5386\u53f2</li>\n<li>\u901a\u8fc7 atexit \u786e\u4fdd\u7a0b\u5e8f\u9000\u51fa\u65f6\u4fdd\u5b58\u5386\u53f2</li>\n</ul>\n<h2 id=\"_15\">\u4f7f\u7528\u793a\u4f8b</h2>\n<h3 id=\"_16\">\u57fa\u672c\u5bf9\u8bdd\u793a\u4f8b</h3>\n<pre class=\"codehilite\"><code class=\"language-bash\"># \u4f7f\u7528 Triton \u540e\u7aef\u8fdb\u884c\u57fa\u672c\u5bf9\u8bdd\npython -m gpt_oss.chat /path/to/model.safetensors\n\n# \u4f7f\u7528\u9ad8\u63a8\u7406\u52aa\u529b\u7b49\u7ea7\npython -m gpt_oss.chat /path/to/model.safetensors -r high\n\n# \u542f\u7528\u6240\u6709\u5de5\u5177\npython -m gpt_oss.chat /path/to/model.safetensors -b -p -a\n</code></pre>\n\n<h3 id=\"_17\">\u540e\u7aef\u5207\u6362\u793a\u4f8b</h3>\n<pre class=\"codehilite\"><code class=\"language-bash\"># \u4f7f\u7528 VLLM \u540e\u7aef\npython -m gpt_oss.chat /path/to/model.safetensors --backend vllm\n\n# \u4f7f\u7528 Torch \u540e\u7aef\npython -m gpt_oss.chat /path/to/model.safetensors --backend torch\n</code></pre>\n\n<h3 id=\"_18\">\u5de5\u5177\u4f7f\u7528\u793a\u4f8b</h3>\n<pre class=\"codehilite\"><code class=\"language-bash\"># \u542f\u7528\u6d4f\u89c8\u5668\u641c\u7d22\u5e76\u663e\u793a\u7ed3\u679c\npython -m gpt_oss.chat /path/to/model.safetensors -b --show-browser-results\n\n# \u542f\u7528 Python \u6267\u884c\u73af\u5883\npython -m gpt_oss.chat /path/to/model.safetensors -p\n\n# \u542f\u7528\u4ee3\u7801\u8865\u4e01\u529f\u80fd\npython -m gpt_oss.chat /path/to/model.safetensors -a\n</code></pre>\n\n<h3 id=\"_19\">\u539f\u59cb\u6a21\u5f0f\u793a\u4f8b</h3>\n<pre class=\"codehilite\"><code class=\"language-bash\"># \u539f\u59cb\u6a21\u5f0f\uff0c\u663e\u793a\u5b8c\u6574\u7684 Harmony \u7f16\u7801\npython -m gpt_oss.chat /path/to/model.safetensors --raw\n</code></pre>\n\n<h3 id=\"_20\">\u5f00\u53d1\u8005\u6d88\u606f\u793a\u4f8b</h3>\n<pre class=\"codehilite\"><code class=\"language-bash\"># \u6dfb\u52a0\u5f00\u53d1\u8005\u6307\u4ee4\npython -m gpt_oss.chat /path/to/model.safetensors --developer-message &quot;\u4f60\u662f\u4e00\u4e2a\u4ee3\u7801\u5ba1\u67e5\u4e13\u5bb6&quot;\n</code></pre>\n\n<h2 id=\"_21\">\u6280\u672f\u603b\u7ed3</h2>\n<p><code>chat.py</code> \u6587\u4ef6\u5c55\u73b0\u4e86\u73b0\u4ee3\u5927\u8bed\u8a00\u6a21\u578b\u5e94\u7528\u7684\u67b6\u6784\u8bbe\u8ba1\u7cbe\u9ad3\uff1a</p>\n<ol>\n<li><strong>\u6a21\u5757\u5316\u8bbe\u8ba1</strong>\uff1a\u6e05\u6670\u5206\u79bb\u63a8\u7406\u540e\u7aef\u3001\u5de5\u5177\u96c6\u6210\u3001\u6d88\u606f\u5904\u7406\u7b49\u804c\u8d23</li>\n<li><strong>\u53ef\u6269\u5c55\u6027</strong>\uff1a\u901a\u8fc7\u63d2\u4ef6\u5f0f\u5de5\u5177\u7cfb\u7edf\u652f\u6301\u529f\u80fd\u6269\u5c55</li>\n<li><strong>\u6807\u51c6\u5316\u63a5\u53e3</strong>\uff1a\u4f7f\u7528 Harmony \u6d88\u606f\u683c\u5f0f\u786e\u4fdd\u7ec4\u4ef6\u95f4\u7684\u4e00\u81f4\u6027</li>\n<li><strong>\u6027\u80fd\u4f18\u5316</strong>\uff1a\u652f\u6301\u591a\u79cd\u9ad8\u6027\u80fd\u63a8\u7406\u540e\u7aef\u548c\u5206\u5e03\u5f0f\u5904\u7406</li>\n<li><strong>\u7528\u6237\u53cb\u597d</strong>\uff1a\u4e30\u5bcc\u7684\u547d\u4ee4\u884c\u9009\u9879\u548c\u826f\u597d\u7684\u4ea4\u4e92\u4f53\u9a8c</li>\n</ol>\n<p>\u8be5\u6587\u4ef6\u662f\u7406\u89e3 GPT-OSS \u9879\u76ee\u6574\u4f53\u67b6\u6784\u7684\u5173\u952e\u5165\u53e3\u70b9\uff0c\u5c55\u793a\u4e86\u5982\u4f55\u6784\u5efa\u4e00\u4e2a\u529f\u80fd\u5b8c\u6574\u3001\u6027\u80fd\u4f18\u5f02\u7684\u5927\u8bed\u8a00\u6a21\u578b\u4ea4\u4e92\u7cfb\u7edf\u3002</p>"
  },
  "../04_tokenizer.md": {
    "hash": "003dfb4b438e04a6fac4f2b24c0b5681",
    "content": "<h1 id=\"tokenizer\">Tokenizer \u5206\u8bcd\u5668\u6a21\u5757\u5206\u6790</h1>\n<h2 id=\"_1\">\u6587\u4ef6\u4f4d\u7f6e</h2>\n<p><code>/Users/georgezhou/Downloads/gpt-oss/gpt_oss/tokenizer.py</code></p>\n<h2 id=\"_2\">\u6982\u8ff0</h2>\n<p>\u8fd9\u662f\u4e00\u4e2a\u57fa\u4e8e tiktoken \u7684\u5206\u8bcd\u5668\u5b9e\u73b0\uff0c\u4e13\u95e8\u4e3a GPT-OSS \u9879\u76ee\u5b9a\u5236\u3002\u5b83\u6269\u5c55\u4e86 OpenAI \u7684 o200k_base \u7f16\u7801\u65b9\u6848\uff0c\u589e\u52a0\u4e86\u989d\u5916\u7684\u7279\u6b8a\u4ee4\u724c\uff0c\u7528\u4e8e\u652f\u6301\u6a21\u578b\u7684\u7279\u5b9a\u529f\u80fd\u3002</p>\n<h2 id=\"_3\">\u6838\u5fc3\u529f\u80fd</h2>\n<h3 id=\"get_tokenizer\"><code>get_tokenizer()</code> \u51fd\u6570</h3>\n<p><strong>\u4f4d\u7f6e</strong>: \u7b2c 3-30 \u884c<br />\n<strong>\u4f5c\u7528</strong>: \u521b\u5efa\u5e76\u8fd4\u56de\u81ea\u5b9a\u4e49\u7684 tiktoken \u7f16\u7801\u5668\u5b9e\u4f8b</p>\n<h4 id=\"_4\">\u5b9e\u73b0\u7ec6\u8282:</h4>\n<ol>\n<li><strong>\u57fa\u7840\u7f16\u7801\u5668\u83b7\u53d6</strong> (\u7b2c 4 \u884c):</li>\n</ol>\n<pre class=\"codehilite\"><code class=\"language-python\">o200k_base = tiktoken.get_encoding(&quot;o200k_base&quot;)\n</code></pre>\n\n<p>\u4f7f\u7528 OpenAI \u7684 o200k_base \u4f5c\u4e3a\u57fa\u7840\u7f16\u7801</p>\n<ol start=\"2\">\n<li><strong>\u81ea\u5b9a\u4e49\u7f16\u7801\u5668\u521b\u5efa</strong> (\u7b2c 5-29 \u884c):</li>\n</ol>\n<pre class=\"codehilite\"><code class=\"language-python\">tokenizer = tiktoken.Encoding(\n    name=&quot;o200k_harmony&quot;,\n    pat_str=o200k_base._pat_str,\n    mergeable_ranks=o200k_base._mergeable_ranks,\n    special_tokens={...}\n)\n</code></pre>\n\n<ol start=\"3\">\n<li>\n<p><strong>\u7279\u6b8a\u4ee4\u724c\u5b9a\u4e49</strong> (\u7b2c 9-28 \u884c):\n   - <code>&lt;|startoftext|&gt;</code>: 199998 - \u6587\u672c\u5f00\u59cb\u6807\u8bb0\n   - <code>&lt;|endoftext|&gt;</code>: 199999 - \u6587\u672c\u7ed3\u675f\u6807\u8bb0\n   - <code>&lt;|reserved_200000|&gt;</code> \u81f3 <code>&lt;|reserved_200011|&gt;</code>: 200000-200011 - \u9884\u7559\u4ee4\u724c\n   - <code>&lt;|return|&gt;</code>: 200002 - \u8fd4\u56de\u6807\u8bb0\n   - <code>&lt;|constrain|&gt;</code>: 200003 - \u7ea6\u675f\u6807\u8bb0\n   - <code>&lt;|channel|&gt;</code>: 200005 - \u901a\u9053\u6807\u8bb0\n   - <code>&lt;|start|&gt;</code>: 200006 - \u5f00\u59cb\u6807\u8bb0\n   - <code>&lt;|end|&gt;</code>: 200007 - \u7ed3\u675f\u6807\u8bb0\n   - <code>&lt;|message|&gt;</code>: 200008 - \u6d88\u606f\u6807\u8bb0\n   - <code>&lt;|call|&gt;</code>: 200012 - \u8c03\u7528\u6807\u8bb0</p>\n</li>\n<li>\n<p><strong>\u6279\u91cf\u9884\u7559\u4ee4\u724c</strong> (\u7b2c 26-28 \u884c):</p>\n</li>\n</ol>\n<pre class=\"codehilite\"><code class=\"language-python\">f&quot;&lt;|reserved_{i}|&gt;&quot;: i for i in range(200013, 201088)\n</code></pre>\n\n<p>\u751f\u6210\u4ece 200013 \u5230 201087 \u7684\u9884\u7559\u4ee4\u724c\uff0c\u5171 1075 \u4e2a</p>\n<h2 id=\"_5\">\u6280\u672f\u7279\u6027</h2>\n<h3 id=\"_6\">\u8bcd\u6c47\u8868\u6269\u5c55</h3>\n<ul>\n<li>\u57fa\u7840\u8bcd\u6c47: \u7ee7\u627f o200k_base \u7684\u5168\u90e8\u8bcd\u6c47</li>\n<li>\u6269\u5c55\u8bcd\u6c47: \u65b0\u589e\u7ea6 1100 \u4e2a\u7279\u6b8a\u4ee4\u724c</li>\n<li>\u603b\u8bcd\u6c47\u91cf: \u7ea6 201,088 \u4e2a\u4ee4\u724c</li>\n</ul>\n<h3 id=\"_7\">\u7279\u6b8a\u4ee4\u724c\u7528\u9014</h3>\n<ol>\n<li><strong>\u7ed3\u6784\u5316\u6807\u8bb0</strong>: <code>&lt;|start|&gt;</code>, <code>&lt;|end|&gt;</code>, <code>&lt;|message|&gt;</code></li>\n<li><strong>\u63a7\u5236\u6807\u8bb0</strong>: <code>&lt;|return|&gt;</code>, <code>&lt;|constrain|&gt;</code>, <code>&lt;|call|&gt;</code></li>\n<li><strong>\u7cfb\u7edf\u6807\u8bb0</strong>: <code>&lt;|startoftext|&gt;</code>, <code>&lt;|endoftext|&gt;</code></li>\n<li><strong>\u901a\u9053\u6807\u8bb0</strong>: <code>&lt;|channel|&gt;</code></li>\n<li><strong>\u9884\u7559\u7a7a\u95f4</strong>: \u5927\u91cf\u9884\u7559\u4ee4\u724c\u4f9b\u672a\u6765\u6269\u5c55</li>\n</ol>\n<h2 id=\"_8\">\u4e0e\u5176\u4ed6\u6a21\u5757\u7684\u5173\u7cfb</h2>\n<h3 id=\"_9\">\u76f4\u63a5\u4f9d\u8d56</h3>\n<ul>\n<li><code>tiktoken</code>: OpenAI \u7684\u5206\u8bcd\u5e93</li>\n</ul>\n<h3 id=\"_10\">\u88ab\u8c03\u7528\u6a21\u5757</h3>\n<ul>\n<li><code>generate.py</code>: \u4e3b\u751f\u6210\u811a\u672c\u4f7f\u7528 (\u7b2c 29 \u884c)</li>\n<li><code>gpt_oss/chat.py</code>: \u5bf9\u8bdd\u7cfb\u7edf</li>\n<li><code>gpt_oss/responses_api/api_server.py</code>: API \u670d\u52a1\u5668</li>\n</ul>\n<h3 id=\"_11\">\u5173\u952e\u96c6\u6210\u70b9</h3>\n<pre class=\"codehilite\"><code class=\"language-python\"># \u5728 generate.py \u4e2d\u7684\u4f7f\u7528\ntokenizer = get_tokenizer()\ntokens = tokenizer.encode(args.prompt)\n</code></pre>\n\n<h2 id=\"_12\">\u8bbe\u8ba1\u6a21\u5f0f</h2>\n<h3 id=\"_13\">\u5de5\u5382\u6a21\u5f0f</h3>\n<p><code>get_tokenizer()</code> \u51fd\u6570\u4f5c\u4e3a\u5de5\u5382\u65b9\u6cd5\uff0c\u5c01\u88c5\u4e86\u590d\u6742\u7684\u7f16\u7801\u5668\u521b\u5efa\u903b\u8f91</p>\n<h3 id=\"_14\">\u9002\u914d\u5668\u6a21\u5f0f</h3>\n<p>\u5728 tiktoken \u57fa\u7840\u4e0a\u6dfb\u52a0\u81ea\u5b9a\u4e49\u7279\u6b8a\u4ee4\u724c\uff0c\u9002\u914d\u9879\u76ee\u7279\u5b9a\u9700\u6c42</p>\n<h2 id=\"_15\">\u6027\u80fd\u7279\u5f81</h2>\n<ul>\n<li><strong>\u5185\u5b58\u6548\u7387</strong>: \u7ee7\u627f tiktoken \u7684\u9ad8\u6548\u5b9e\u73b0</li>\n<li><strong>\u901f\u5ea6</strong>: \u57fa\u4e8e Rust \u540e\u7aef\u7684\u5feb\u901f\u7f16\u89e3\u7801</li>\n<li><strong>\u6269\u5c55\u6027</strong>: \u5927\u91cf\u9884\u7559\u4ee4\u724c\u652f\u6301\u672a\u6765\u529f\u80fd\u6269\u5c55</li>\n</ul>\n<h2 id=\"_16\">\u4f7f\u7528\u793a\u4f8b</h2>\n<pre class=\"codehilite\"><code class=\"language-python\">from gpt_oss.tokenizer import get_tokenizer\n\n# \u83b7\u53d6\u5206\u8bcd\u5668\ntokenizer = get_tokenizer()\n\n# \u7f16\u7801\u6587\u672c\ntext = &quot;Hello, world!&quot;\ntokens = tokenizer.encode(text)\n\n# \u89e3\u7801\u4ee4\u724c\ndecoded = tokenizer.decode(tokens)\n\n# \u7279\u6b8a\u4ee4\u724c\u4f7f\u7528\nspecial_tokens = tokenizer.encode(&quot;&lt;|start|&gt;Hello&lt;|end|&gt;&quot;, allowed_special=&quot;all&quot;)\n</code></pre>\n\n<h2 id=\"_17\">\u91cd\u8981\u6ce8\u610f\u4e8b\u9879</h2>\n<ol>\n<li>\u7279\u6b8a\u4ee4\u724c\u9700\u8981\u4f7f\u7528 <code>allowed_special=\"all\"</code> \u53c2\u6570\u8fdb\u884c\u7f16\u7801</li>\n<li>\u4ee4\u724c ID \u4ece 199998 \u5f00\u59cb\uff0c\u907f\u514d\u4e0e\u57fa\u7840\u8bcd\u6c47\u8868\u51b2\u7a81</li>\n<li>\u9884\u7559\u4e86\u5927\u91cf\u4ee4\u724c\u7a7a\u95f4\uff0c\u4e3a\u672a\u6765\u529f\u80fd\u6269\u5c55\u63d0\u4f9b\u5145\u8db3\u7a7a\u95f4</li>\n</ol>"
  },
  "../01_torch_model.md": {
    "hash": "b49035e620b699bf417bb0d9f7bf6a27",
    "content": "<h1 id=\"torchmodelpy\">torch/model.py \u6a21\u5757\u5206\u6790\u6587\u6863</h1>\n<h2 id=\"1\">1. \u6587\u4ef6\u6982\u8ff0\u548c\u4f5c\u7528</h2>\n<p><code>torch/model.py</code> \u662f gpt-oss \u9879\u76ee\u4e2d\u7684\u6838\u5fc3\u6a21\u578b\u5b9e\u73b0\u6587\u4ef6\uff0c\u4f7f\u7528 PyTorch \u6846\u67b6\u5b9e\u73b0\u4e86\u4e00\u4e2a\u5b8c\u6574\u7684\u57fa\u4e8e Transformer \u67b6\u6784\u7684\u5927\u8bed\u8a00\u6a21\u578b\u3002\u8be5\u6587\u4ef6\u5305\u542b\u4e86\u6a21\u578b\u7684\u6240\u6709\u6838\u5fc3\u7ec4\u4ef6\uff0c\u5305\u62ec\u6ce8\u610f\u529b\u673a\u5236\u3001\u591a\u4e13\u5bb6\u7cfb\u7edf(MoE)\u3001\u4f4d\u7f6e\u7f16\u7801(RoPE)\u3001\u5f52\u4e00\u5316\u5c42\u7b49\u3002</p>\n<p><strong>\u4e3b\u8981\u529f\u80fd\uff1a</strong></p>\n<ul>\n<li>\u5b9e\u73b0\u57fa\u4e8e Transformer \u7684\u5927\u8bed\u8a00\u6a21\u578b\u67b6\u6784</li>\n<li>\u652f\u6301\u591a\u4e13\u5bb6\u7cfb\u7edf(Mixture of Experts, MoE)</li>\n<li>\u5b9e\u73b0\u65cb\u8f6c\u4f4d\u7f6e\u7f16\u7801(Rotary Position Embedding, RoPE)</li>\n<li>\u63d0\u4f9b\u6a21\u578b\u6743\u91cd\u52a0\u8f7d\u548c\u63a8\u7406\u529f\u80fd</li>\n<li>\u652f\u6301\u5206\u5e03\u5f0f\u8bad\u7ec3\u548c\u63a8\u7406</li>\n</ul>\n<h2 id=\"2\">2. \u4e3b\u8981\u7c7b\u548c\u51fd\u6570\u5217\u8868</h2>\n<h3 id=\"_1\">\u6570\u636e\u7c7b</h3>\n<ul>\n<li><code>ModelConfig</code> (\u7b2c12-30\u884c): \u6a21\u578b\u914d\u7f6e\u53c2\u6570\u7c7b</li>\n</ul>\n<h3 id=\"_2\">\u6838\u5fc3\u7ec4\u4ef6\u7c7b</h3>\n<ul>\n<li><code>RMSNorm</code> (\u7b2c32-47\u884c): \u6839\u5747\u65b9\u5f52\u4e00\u5316\u5c42</li>\n<li><code>RotaryEmbedding</code> (\u7b2c63-150\u884c): \u65cb\u8f6c\u4f4d\u7f6e\u7f16\u7801</li>\n<li><code>AttentionBlock</code> (\u7b2c176-246\u884c): \u6ce8\u610f\u529b\u673a\u5236\u6a21\u5757</li>\n<li><code>MLPBlock</code> (\u7b2c259-336\u884c): \u591a\u5c42\u611f\u77e5\u673a\u548c\u591a\u4e13\u5bb6\u7cfb\u7edf\u6a21\u5757</li>\n<li><code>TransformerBlock</code> (\u7b2c339-354\u884c): Transformer \u57fa\u7840\u5757</li>\n<li><code>Transformer</code> (\u7b2c357-441\u884c): \u5b8c\u6574\u7684 Transformer \u6a21\u578b</li>\n<li><code>TokenGenerator</code> (\u7b2c444-477\u884c): \u6587\u672c\u751f\u6210\u5668</li>\n</ul>\n<h3 id=\"_3\">\u6838\u5fc3\u51fd\u6570</h3>\n<ul>\n<li><code>_apply_rotary_emb</code> (\u7b2c50-60\u884c): \u5e94\u7528\u65cb\u8f6c\u4f4d\u7f6e\u7f16\u7801\u7684\u5e95\u5c42\u51fd\u6570</li>\n<li><code>sdpa</code> (\u7b2c153-173\u884c): \u7f29\u653e\u70b9\u79ef\u6ce8\u610f\u529b\u5b9e\u73b0</li>\n<li><code>swiglu</code> (\u7b2c249-256\u884c): SwiGLU \u6fc0\u6d3b\u51fd\u6570</li>\n</ul>\n<h2 id=\"3\">3. \u6838\u5fc3\u7c7b\u8be6\u7ec6\u8bf4\u660e</h2>\n<h3 id=\"31-modelconfig-12-30\">3.1 ModelConfig (\u7b2c12-30\u884c)</h3>\n<p>\u6a21\u578b\u914d\u7f6e\u6570\u636e\u7c7b\uff0c\u5b9a\u4e49\u4e86\u6a21\u578b\u7684\u6240\u6709\u5173\u952e\u53c2\u6570\u3002</p>\n<p><strong>\u5173\u952e\u53c2\u6570\u8bf4\u660e\uff1a</strong></p>\n<ul>\n<li><code>num_hidden_layers</code>: 36 - Transformer \u5c42\u6570</li>\n<li><code>num_experts</code>: 128 - \u4e13\u5bb6\u7f51\u7edc\u6570\u91cf</li>\n<li><code>experts_per_token</code>: 4 - \u6bcf\u4e2a token \u6fc0\u6d3b\u7684\u4e13\u5bb6\u6570</li>\n<li><code>vocab_size</code>: 201088 - \u8bcd\u6c47\u8868\u5927\u5c0f</li>\n<li><code>hidden_size</code>: 2880 - \u9690\u85cf\u5c42\u7ef4\u5ea6</li>\n<li><code>intermediate_size</code>: 2880 - \u4e2d\u95f4\u5c42\u7ef4\u5ea6</li>\n<li><code>head_dim</code>: 64 - \u6ce8\u610f\u529b\u5934\u7ef4\u5ea6</li>\n<li><code>num_attention_heads</code>: 64 - \u6ce8\u610f\u529b\u5934\u6570\u91cf</li>\n<li><code>num_key_value_heads</code>: 8 - \u952e\u503c\u5934\u6570\u91cf(\u652f\u6301 Grouped Query Attention)</li>\n<li><code>sliding_window</code>: 128 - \u6ed1\u52a8\u7a97\u53e3\u5927\u5c0f</li>\n<li><code>rope_theta</code>: 150000.0 - RoPE \u57fa\u7840\u9891\u7387</li>\n<li><code>rope_scaling_factor</code>: 32.0 - RoPE \u7f29\u653e\u56e0\u5b50</li>\n</ul>\n<h3 id=\"32-rmsnorm-32-47\">3.2 RMSNorm (\u7b2c32-47\u884c)</h3>\n<p>\u5b9e\u73b0\u6839\u5747\u65b9\u5f52\u4e00\u5316(Root Mean Square Layer Normalization)\u3002</p>\n<p><strong>\u53c2\u6570\uff1a</strong></p>\n<ul>\n<li><code>num_features</code>: \u7279\u5f81\u6570\u91cf</li>\n<li><code>eps</code>: \u6570\u503c\u7a33\u5b9a\u6027\u5e38\u6570\uff0c\u9ed8\u8ba4 1e-05</li>\n</ul>\n<p><strong>\u7b97\u6cd5\u5b9e\u73b0 (\u7b2c43-47\u884c)\uff1a</strong></p>\n<pre class=\"codehilite\"><code class=\"language-python\">def forward(self, x: torch.Tensor) -&gt; torch.Tensor:\n    t, dtype = x.float(), x.dtype\n    t = t * torch.rsqrt(torch.mean(t**2, dim=-1, keepdim=True) + self.eps)\n    return (t * self.scale).to(dtype)\n</code></pre>\n\n<h3 id=\"33-rotaryembedding-63-150\">3.3 RotaryEmbedding (\u7b2c63-150\u884c)</h3>\n<p>\u5b9e\u73b0\u65cb\u8f6c\u4f4d\u7f6e\u7f16\u7801(Rotary Position Embedding, RoPE)\uff0c\u652f\u6301 YaRN \u6269\u5c55\u65b9\u6cd5\u3002</p>\n<p><strong>\u5173\u952e\u65b9\u6cd5\uff1a</strong></p>\n<h4 id=\"_compute_concentration_and_inv_freq-85-123\"><code>_compute_concentration_and_inv_freq</code> (\u7b2c85-123\u884c)</h4>\n<p>\u57fa\u4e8e YaRN \u8bba\u6587\u5b9e\u73b0\u7684\u9891\u7387\u8ba1\u7b97\u65b9\u6cd5\uff0c\u652f\u6301\u4e0a\u4e0b\u6587\u957f\u5ea6\u6269\u5c55\uff1a</p>\n<ul>\n<li>\u5f53 <code>scaling_factor &gt; 1.0</code> \u65f6\u4f7f\u7528 YaRN \u7684 NTK \u63d2\u503c\u65b9\u6cd5</li>\n<li>\u652f\u6301\u9ad8\u9891\u548c\u4f4e\u9891\u7684\u4e0d\u540c\u5904\u7406\u7b56\u7565</li>\n<li>\u8ba1\u7b97\u6d53\u5ea6\u53c2\u6570\u7528\u4e8e\u7f29\u653e</li>\n</ul>\n<h4 id=\"_compute_cos_sin-125-131\"><code>_compute_cos_sin</code> (\u7b2c125-131\u884c)</h4>\n<p>\u8ba1\u7b97\u6b63\u5f26\u548c\u4f59\u5f26\u503c\uff1a</p>\n<pre class=\"codehilite\"><code class=\"language-python\">t = torch.arange(num_tokens, dtype=torch.float32, device=self.device)\nfreqs = torch.einsum(&quot;i,j-&gt;ij&quot;, t, inv_freq)\ncos = freqs.cos() * concentration\nsin = freqs.sin() * concentration\n</code></pre>\n\n<h4 id=\"forward-133-150\"><code>forward</code> (\u7b2c133-150\u884c)</h4>\n<p>\u5bf9\u67e5\u8be2\u548c\u952e\u5e94\u7528\u65cb\u8f6c\u4f4d\u7f6e\u7f16\u7801</p>\n<h3 id=\"34-attentionblock-176-246\">3.4 AttentionBlock (\u7b2c176-246\u884c)</h3>\n<p>\u5b9e\u73b0\u591a\u5934\u6ce8\u610f\u529b\u673a\u5236\uff0c\u652f\u6301\u6ed1\u52a8\u7a97\u53e3\u548c Grouped Query Attention\u3002</p>\n<p><strong>\u5173\u952e\u7279\u6027\uff1a</strong></p>\n<ul>\n<li>\u652f\u6301 Grouped Query Attention (GQA)</li>\n<li>\u6ed1\u52a8\u7a97\u53e3\u6ce8\u610f\u529b (\u4ec5\u5076\u6570\u5c42\u4f7f\u7528\uff0c\u7b2c188\u884c)</li>\n<li>Sink tokens \u673a\u5236 (\u7b2c189-191\u884c)</li>\n</ul>\n<p><strong>\u524d\u5411\u4f20\u64ad\u6d41\u7a0b (\u7b2c217-246\u884c)\uff1a</strong></p>\n<ol>\n<li>Layer normalization (\u7b2c218\u884c)</li>\n<li>QKV \u6295\u5f71\u548c\u5207\u5206 (\u7b2c219-232\u884c)</li>\n<li>RoPE \u4f4d\u7f6e\u7f16\u7801 (\u7b2c242\u884c)</li>\n<li>\u7f29\u653e\u70b9\u79ef\u6ce8\u610f\u529b (\u7b2c243\u884c)</li>\n<li>\u8f93\u51fa\u6295\u5f71\u548c\u6b8b\u5dee\u8fde\u63a5 (\u7b2c244-245\u884c)</li>\n</ol>\n<h3 id=\"35-mlpblock-259-336\">3.5 MLPBlock (\u7b2c259-336\u884c)</h3>\n<p>\u5b9e\u73b0\u591a\u4e13\u5bb6\u7cfb\u7edf(Mixture of Experts, MoE)\u548c SwiGLU \u6fc0\u6d3b\u51fd\u6570\u3002</p>\n<p><strong>\u4e13\u5bb6\u9009\u62e9\u673a\u5236 (\u7b2c314-317\u884c)\uff1a</strong></p>\n<pre class=\"codehilite\"><code class=\"language-python\">g = self.gate(t)\nexperts = torch.topk(g, k=self.experts_per_token, dim=-1, sorted=True)\nexpert_weights = torch.nn.functional.softmax(experts.values, dim=1)\nexpert_indices = experts.indices\n</code></pre>\n\n<p><strong>\u4e24\u5c42 MLP \u7ed3\u6784\uff1a</strong></p>\n<ol>\n<li><strong>MLP1</strong> (\u7b2c319-323\u884c): \u6295\u5f71\u5230\u4e2d\u95f4\u7ef4\u5ea6\u5e76\u5e94\u7528 SwiGLU</li>\n<li><strong>MLP2</strong> (\u7b2c325-331\u884c): \u6295\u5f71\u56de\u9690\u85cf\u7ef4\u5ea6\uff0c\u652f\u6301\u5206\u5e03\u5f0f all-reduce</li>\n</ol>\n<p><strong>\u4e13\u5bb6\u6743\u91cd\u805a\u5408 (\u7b2c334\u884c)\uff1a</strong></p>\n<pre class=\"codehilite\"><code class=\"language-python\">t = torch.einsum(&quot;bec,be-&gt;bc&quot;, t, expert_weights)\n</code></pre>\n\n<h2 id=\"4\">4. \u91cd\u8981\u51fd\u6570\u8be6\u7ec6\u8bf4\u660e</h2>\n<h3 id=\"41-_apply_rotary_emb-50-60\">4.1 _apply_rotary_emb (\u7b2c50-60\u884c)</h3>\n<p><strong>\u529f\u80fd\uff1a</strong> \u5e94\u7528\u65cb\u8f6c\u4f4d\u7f6e\u7f16\u7801\u7684\u6838\u5fc3\u8ba1\u7b97\n<strong>\u53c2\u6570\uff1a</strong></p>\n<ul>\n<li><code>x</code>: \u8f93\u5165\u5f20\u91cf</li>\n<li><code>cos</code>: \u4f59\u5f26\u503c</li>\n<li><code>sin</code>: \u6b63\u5f26\u503c</li>\n</ul>\n<p><strong>\u5b9e\u73b0\u539f\u7406\uff1a</strong></p>\n<pre class=\"codehilite\"><code class=\"language-python\">x1, x2 = torch.chunk(x, 2, dim=-1)  # \u5c06\u6700\u540e\u4e00\u7ef4\u5206\u6210\u4e24\u534a\no1 = x1 * cos - x2 * sin           # \u65cb\u8f6c\u53d8\u6362\no2 = x2 * cos + x1 * sin\nreturn torch.cat((o1, o2), dim=-1)\n</code></pre>\n\n<h3 id=\"42-sdpa-153-173\">4.2 sdpa (\u7b2c153-173\u884c)</h3>\n<p><strong>\u529f\u80fd\uff1a</strong> \u5b9e\u73b0\u7f29\u653e\u70b9\u79ef\u6ce8\u610f\u529b(Scaled Dot-Product Attention)\n<strong>\u53c2\u6570\uff1a</strong></p>\n<ul>\n<li><code>Q, K, V</code>: \u67e5\u8be2\u3001\u952e\u3001\u503c\u5f20\u91cf</li>\n<li><code>S</code>: Sink tokens</li>\n<li><code>sm_scale</code>: \u7f29\u653e\u56e0\u5b50</li>\n<li><code>sliding_window</code>: \u6ed1\u52a8\u7a97\u53e3\u5927\u5c0f</li>\n</ul>\n<p><strong>\u5173\u952e\u5b9e\u73b0\uff1a</strong></p>\n<ol>\n<li><strong>\u6ce8\u610f\u529b\u63a9\u7801</strong> (\u7b2c161-165\u884c): \u56e0\u679c\u63a9\u7801 + \u6ed1\u52a8\u7a97\u53e3\u63a9\u7801</li>\n<li><strong>Sink tokens</strong> (\u7b2c169\u884c): \u6dfb\u52a0 sink tokens \u5230\u6ce8\u610f\u529b\u8ba1\u7b97\u4e2d</li>\n<li><strong>Softmax \u8ba1\u7b97</strong> (\u7b2c170-171\u884c): \u5305\u542b sink tokens \u7684 softmax</li>\n</ol>\n<h3 id=\"43-swiglu-249-256\">4.3 swiglu (\u7b2c249-256\u884c)</h3>\n<p><strong>\u529f\u80fd\uff1a</strong> \u5b9e\u73b0 SwiGLU \u6fc0\u6d3b\u51fd\u6570\n<strong>\u53c2\u6570\uff1a</strong></p>\n<ul>\n<li><code>x</code>: \u8f93\u5165\u5f20\u91cf (\u5305\u542b\u95e8\u63a7\u548c\u7ebf\u6027\u90e8\u5206)</li>\n<li><code>alpha</code>: \u6fc0\u6d3b\u51fd\u6570\u53c2\u6570\uff0c\u9ed8\u8ba4 1.702</li>\n<li><code>limit</code>: \u8f93\u5165\u503c\u9650\u5236\uff0c\u9ed8\u8ba4 7.0</li>\n</ul>\n<p><strong>\u5b9e\u73b0\uff1a</strong></p>\n<pre class=\"codehilite\"><code class=\"language-python\">x_glu, x_linear = x[..., ::2], x[..., 1::2]  # \u5206\u79bb\u95e8\u63a7\u548c\u7ebf\u6027\u90e8\u5206\nx_glu = x_glu.clamp(min=None, max=limit)      # \u9650\u5236\u95e8\u63a7\u503c\nx_linear = x_linear.clamp(-limit, max=limit)   # \u9650\u5236\u7ebf\u6027\u503c\nout_glu = x_glu * torch.sigmoid(alpha * x_glu)\nreturn out_glu * (x_linear + 1)               # \u7ebf\u6027\u90e8\u5206\u52a01\u7684\u504f\u7f6e\n</code></pre>\n\n<h2 id=\"5\">5. \u4e0e\u5176\u4ed6\u6a21\u5757\u7684\u5173\u7cfb</h2>\n<h3 id=\"_4\">\u4f9d\u8d56\u5173\u7cfb\uff1a</h3>\n<ul>\n<li><code>gpt_oss.torch.weights.Checkpoint</code>: \u7528\u4e8e\u52a0\u8f7d\u6a21\u578b\u6743\u91cd (\u7b2c9\u884c)</li>\n<li><code>torch.distributed</code>: \u652f\u6301\u5206\u5e03\u5f0f\u8bad\u7ec3 (\u7b2c7\u884c)</li>\n</ul>\n<h3 id=\"_5\">\u88ab\u4f7f\u7528\u5173\u7cfb\uff1a</h3>\n<ul>\n<li><code>TokenGenerator</code> \u7c7b\u63d0\u4f9b\u63a8\u7406\u63a5\u53e3\uff0c\u88ab\u5176\u4ed6\u751f\u6210\u6a21\u5757\u8c03\u7528</li>\n<li><code>Transformer.from_checkpoint</code> \u9759\u6001\u65b9\u6cd5\u7528\u4e8e\u6a21\u578b\u52a0\u8f7d</li>\n</ul>\n<h2 id=\"6\">6. \u5173\u952e\u5b9e\u73b0\u7ec6\u8282</h2>\n<h3 id=\"61-rope\">6.1 RoPE \u4f4d\u7f6e\u7f16\u7801</h3>\n<ul>\n<li>\u652f\u6301 YaRN \u65b9\u6cd5\u8fdb\u884c\u4e0a\u4e0b\u6587\u957f\u5ea6\u6269\u5c55</li>\n<li>\u4f7f\u7528 NTK \u63d2\u503c\u65b9\u6cd5\u5904\u7406\u4e0d\u540c\u9891\u7387\u5206\u91cf</li>\n<li>\u652f\u6301\u6d53\u5ea6\u53c2\u6570\u8c03\u6574</li>\n</ul>\n<h3 id=\"62-moe\">6.2 \u591a\u4e13\u5bb6\u7cfb\u7edf (MoE)</h3>\n<ul>\n<li>\u6bcf\u4e2a token \u6fc0\u6d3b 4 \u4e2a\u4e13\u5bb6 (\u53ef\u914d\u7f6e)</li>\n<li>\u4f7f\u7528 Top-K \u9009\u62e9\u673a\u5236</li>\n<li>\u652f\u6301\u5206\u5e03\u5f0f\u8ba1\u7b97\uff0cMLP2 \u5c42\u8fdb\u884c all-reduce \u64cd\u4f5c</li>\n</ul>\n<h3 id=\"63\">6.3 \u6ce8\u610f\u529b\u673a\u5236\u4f18\u5316</h3>\n<ul>\n<li>Grouped Query Attention \u51cf\u5c11 KV cache \u5185\u5b58\u5360\u7528</li>\n<li>\u6ed1\u52a8\u7a97\u53e3\u6ce8\u610f\u529b\u63d0\u9ad8\u957f\u5e8f\u5217\u6548\u7387</li>\n<li>Sink tokens \u673a\u5236\u4fdd\u6301\u6ce8\u610f\u529b\u6a21\u5f0f</li>\n</ul>\n<h3 id=\"64\">6.4 \u6570\u503c\u7a33\u5b9a\u6027</h3>\n<ul>\n<li>\u4f7f\u7528 bfloat16 \u7cbe\u5ea6\u5e73\u8861\u6027\u80fd\u548c\u7cbe\u5ea6</li>\n<li>RMSNorm \u4f7f\u7528 float32 \u8ba1\u7b97\u786e\u4fdd\u7a33\u5b9a\u6027</li>\n<li>SwiGLU \u6fc0\u6d3b\u51fd\u6570\u6dfb\u52a0\u8f93\u5165\u503c\u9650\u5236</li>\n</ul>\n<h2 id=\"7\">7. \u8c03\u7528\u793a\u4f8b\u548c\u4f7f\u7528\u8bf4\u660e</h2>\n<h3 id=\"71\">7.1 \u6a21\u578b\u52a0\u8f7d\u793a\u4f8b</h3>\n<pre class=\"codehilite\"><code class=\"language-python\"># \u4ece\u68c0\u67e5\u70b9\u52a0\u8f7d\u6a21\u578b\nmodel = Transformer.from_checkpoint(&quot;path/to/checkpoint&quot;, device=&quot;cuda&quot;)\n\n# \u76f4\u63a5\u63a8\u7406\ntokens = torch.tensor([1, 2, 3, 4], device=&quot;cuda&quot;)\nlogits = model(tokens)\n</code></pre>\n\n<h3 id=\"72\">7.2 \u6587\u672c\u751f\u6210\u793a\u4f8b</h3>\n<pre class=\"codehilite\"><code class=\"language-python\"># \u521b\u5efa\u751f\u6210\u5668\ngenerator = TokenGenerator(&quot;path/to/checkpoint&quot;, torch.device(&quot;cuda&quot;))\n\n# \u751f\u6210\u6587\u672c\nprompt_tokens = [1, 2, 3]\nstop_tokens = [0]\nfor token in generator.generate(prompt_tokens, stop_tokens, temperature=0.8):\n    print(token)\n</code></pre>\n\n<h3 id=\"73\">7.3 \u5206\u5e03\u5f0f\u4f7f\u7528</h3>\n<p>\u6a21\u578b\u652f\u6301\u5206\u5e03\u5f0f\u8bad\u7ec3\u548c\u63a8\u7406\uff0cMLP \u5c42\u4f1a\u6839\u636e world_size \u81ea\u52a8\u5206\u7247\uff1a</p>\n<pre class=\"codehilite\"><code class=\"language-python\"># \u6a21\u578b\u4f1a\u81ea\u52a8\u68c0\u6d4b\u5206\u5e03\u5f0f\u73af\u5883\n# MLP \u4e2d\u95f4\u7ef4\u5ea6\u4f1a\u6309 world_size \u5206\u7247\n# \u9700\u8981\u5728 MLP2 \u5c42\u8fdb\u884c all-reduce \u805a\u5408\u7ed3\u679c\n</code></pre>\n\n<h2 id=\"8\">8. \u6027\u80fd\u7279\u6027</h2>\n<ul>\n<li><strong>\u5185\u5b58\u6548\u7387</strong>: \u4f7f\u7528 Grouped Query Attention \u548c\u6ed1\u52a8\u7a97\u53e3\u51cf\u5c11\u5185\u5b58\u5360\u7528</li>\n<li><strong>\u8ba1\u7b97\u6548\u7387</strong>: MoE \u67b6\u6784\u53ea\u6fc0\u6d3b\u90e8\u5206\u4e13\u5bb6\uff0c\u63d0\u9ad8\u63a8\u7406\u901f\u5ea6</li>\n<li><strong>\u6269\u5c55\u6027</strong>: \u652f\u6301\u5206\u5e03\u5f0f\u8ba1\u7b97\uff0c\u53ef\u6269\u5c55\u5230\u591a\u4e2a GPU</li>\n<li><strong>\u6570\u503c\u7a33\u5b9a</strong>: \u6df7\u5408\u7cbe\u5ea6\u8ba1\u7b97\u7b56\u7565\u4fdd\u8bc1\u8bad\u7ec3\u7a33\u5b9a\u6027</li>\n</ul>\n<p>\u8be5\u6a21\u578b\u5b9e\u73b0\u4f53\u73b0\u4e86\u73b0\u4ee3\u5927\u8bed\u8a00\u6a21\u578b\u7684\u591a\u9879\u5148\u8fdb\u6280\u672f\uff0c\u662f\u4e00\u4e2a\u5b8c\u6574\u4e14\u9ad8\u6548\u7684 Transformer \u5b9e\u73b0\u3002</p>"
  },
  "../07_tools_tool.md": {
    "hash": "d5fa1935e4bd8cf6ca2c44e25dfec539",
    "content": "<h1 id=\"tools-tool\">Tools Tool \u5de5\u5177\u57fa\u7c7b\u6a21\u5757\u5206\u6790</h1>\n<h2 id=\"_1\">\u6587\u4ef6\u4f4d\u7f6e</h2>\n<p><code>/Users/georgezhou/Downloads/gpt-oss/gpt_oss/tools/tool.py</code></p>\n<h2 id=\"_2\">\u6982\u8ff0</h2>\n<p>\u8fd9\u662f\u5de5\u5177\u7cfb\u7edf\u7684\u6838\u5fc3\u62bd\u8c61\u57fa\u7c7b\uff0c\u5b9a\u4e49\u4e86\u6a21\u578b\u53ef\u8c03\u7528\u5de5\u5177\u7684\u6807\u51c6\u63a5\u53e3\u3002\u5b83\u63d0\u4f9b\u4e86\u5de5\u5177\u6ce8\u518c\u3001\u6d88\u606f\u5904\u7406\u3001\u9519\u8bef\u5904\u7406\u548c\u901a\u9053\u9a8c\u8bc1\u7684\u7edf\u4e00\u6846\u67b6\uff0c\u662f\u6574\u4e2a\u5de5\u5177\u751f\u6001\u7cfb\u7edf\u7684\u57fa\u7840\u3002</p>\n<h2 id=\"_3\">\u6838\u5fc3\u5bfc\u5165</h2>\n<p><strong>\u4f4d\u7f6e</strong>: \u7b2c 1-10 \u884c</p>\n<pre class=\"codehilite\"><code class=\"language-python\">from abc import ABC, abstractmethod\nfrom uuid import UUID, uuid4\nfrom typing import AsyncIterator\nfrom openai_harmony import Author, Role, Message, TextContent\n</code></pre>\n\n<h2 id=\"_4\">\u5de5\u5177\u51fd\u6570</h2>\n<h3 id=\"_maybe_update_inplace_and_validate_channel\"><code>_maybe_update_inplace_and_validate_channel</code></h3>\n<p><strong>\u4f4d\u7f6e</strong>: \u7b2c 13-26 \u884c\n<strong>\u529f\u80fd</strong>: \u9a8c\u8bc1\u548c\u66f4\u65b0\u6d88\u606f\u901a\u9053</p>\n<h4 id=\"_5\">\u5b9e\u73b0\u903b\u8f91:</h4>\n<pre class=\"codehilite\"><code class=\"language-python\">def _maybe_update_inplace_and_validate_channel(\n    *, input_message: Message, tool_message: Message\n) -&gt; None:\n    if tool_message.channel != input_message.channel:\n        if tool_message.channel is None:\n            tool_message.channel = input_message.channel  # \u81ea\u52a8\u8bbe\u7f6e\n        else:\n            raise ValueError(...)  # \u901a\u9053\u51b2\u7a81\u9519\u8bef\n</code></pre>\n\n<h4 id=\"_6\">\u529f\u80fd\u8bf4\u660e:</h4>\n<ul>\n<li><strong>\u81ea\u52a8\u7ee7\u627f</strong>: \u5de5\u5177\u8f93\u51fa\u6d88\u606f\u81ea\u52a8\u7ee7\u627f\u8f93\u5165\u6d88\u606f\u7684\u901a\u9053</li>\n<li><strong>\u51b2\u7a81\u68c0\u6d4b</strong>: \u68c0\u6d4b\u663e\u5f0f\u8bbe\u7f6e\u7684\u901a\u9053\u51b2\u7a81</li>\n<li><strong>\u9519\u8bef\u63d0\u793a</strong>: \u63d0\u4f9b\u6e05\u6670\u7684\u9519\u8bef\u4fe1\u606f</li>\n</ul>\n<h2 id=\"tool\">\u6838\u5fc3\u62bd\u8c61\u7c7b: Tool</h2>\n<h3 id=\"_7\">\u7c7b\u5b9a\u4e49</h3>\n<p><strong>\u4f4d\u7f6e</strong>: \u7b2c 28-100 \u884c</p>\n<pre class=\"codehilite\"><code class=\"language-python\">class Tool(ABC):\n    &quot;&quot;&quot;\n    Something the model can call.\n\n    Tools expose APIs that are shown to the model in a syntax that the model\n    understands and knows how to call (from training data).\n    &quot;&quot;&quot;\n</code></pre>\n\n<h3 id=\"_8\">\u62bd\u8c61\u5c5e\u6027</h3>\n<h4 id=\"name\"><code>name</code> \u5c5e\u6027</h4>\n<p><strong>\u4f4d\u7f6e</strong>: \u7b2c 37-43 \u884c</p>\n<pre class=\"codehilite\"><code class=\"language-python\">@property\n@abstractmethod\ndef name(self) -&gt; str:\n    &quot;&quot;&quot;\n    An identifier for the tool. The convention is that a message will be routed to the tool\n    whose name matches its recipient field.\n    &quot;&quot;&quot;\n</code></pre>\n\n<ul>\n<li><strong>\u8def\u7531\u6807\u8bc6</strong>: \u6d88\u606f\u901a\u8fc7 <code>recipient</code> \u5b57\u6bb5\u8def\u7531\u5230\u5bf9\u5e94\u5de5\u5177</li>\n<li><strong>\u5fc5\u987b\u5b9e\u73b0</strong>: \u6bcf\u4e2a\u5177\u4f53\u5de5\u5177\u5fc5\u987b\u5b9a\u4e49\u552f\u4e00\u540d\u79f0</li>\n</ul>\n<h3 id=\"_9\">\u914d\u7f6e\u5c5e\u6027</h3>\n<h4 id=\"output_channel_should_match_input_channel\"><code>output_channel_should_match_input_channel</code></h4>\n<p><strong>\u4f4d\u7f6e</strong>: \u7b2c 45-50 \u884c</p>\n<pre class=\"codehilite\"><code class=\"language-python\">@property\ndef output_channel_should_match_input_channel(self) -&gt; bool:\n    &quot;&quot;&quot;\n    A flag which indicates whether the output channel of the tool should match the input channel.\n    &quot;&quot;&quot;\n    return True\n</code></pre>\n\n<ul>\n<li><strong>\u9ed8\u8ba4\u884c\u4e3a</strong>: \u8f93\u51fa\u901a\u9053\u5339\u914d\u8f93\u5165\u901a\u9053</li>\n<li><strong>\u53ef\u91cd\u5199</strong>: \u7279\u6b8a\u5de5\u5177\u53ef\u4ee5\u91cd\u5199\u6b64\u884c\u4e3a</li>\n</ul>\n<h3 id=\"_10\">\u6838\u5fc3\u5904\u7406\u65b9\u6cd5</h3>\n<h4 id=\"process\"><code>process</code> \u65b9\u6cd5 (\u516c\u5f00\u63a5\u53e3)</h4>\n<p><strong>\u4f4d\u7f6e</strong>: \u7b2c 52-67 \u884c</p>\n<pre class=\"codehilite\"><code class=\"language-python\">async def process(self, message: Message) -&gt; AsyncIterator[Message]:\n    &quot;&quot;&quot;\n    Process the message and return a list of messages to add to the conversation.\n    &quot;&quot;&quot;\n    async for m in self._process(message):\n        if self.output_channel_should_match_input_channel:\n            _maybe_update_inplace_and_validate_channel(input_message=message, tool_message=m)\n        yield m\n</code></pre>\n\n<h4 id=\"_11\">\u529f\u80fd\u7279\u70b9:</h4>\n<ul>\n<li><strong>\u88c5\u9970\u5668\u6a21\u5f0f</strong>: \u4e3a <code>_process</code> \u63d0\u4f9b\u901a\u9053\u9a8c\u8bc1\u5305\u88c5</li>\n<li><strong>\u5f02\u6b65\u751f\u6210\u5668</strong>: \u652f\u6301\u6d41\u5f0f\u8f93\u51fa</li>\n<li><strong>\u81ea\u52a8\u9a8c\u8bc1</strong>: \u81ea\u52a8\u5e94\u7528\u901a\u9053\u9a8c\u8bc1\u903b\u8f91</li>\n<li><strong>\u4e0d\u53ef\u91cd\u5199</strong>: \u786e\u4fdd\u4e00\u81f4\u7684\u884c\u4e3a</li>\n</ul>\n<h4 id=\"_process\"><code>_process</code> \u65b9\u6cd5 (\u5b9e\u73b0\u63a5\u53e3)</h4>\n<p><strong>\u4f4d\u7f6e</strong>: \u7b2c 69-75 \u884c</p>\n<pre class=\"codehilite\"><code class=\"language-python\">@abstractmethod\nasync def _process(self, message: Message) -&gt; AsyncIterator[Message]:\n    &quot;&quot;&quot;Override this method to provide the implementation of the tool.&quot;&quot;&quot;\n    if False:  # Type checker helper\n        yield  # type: ignore[unreachable]\n    _ = message  # Suppress unused warning\n    raise NotImplementedError\n</code></pre>\n\n<h4 id=\"_12\">\u8bbe\u8ba1\u8981\u70b9:</h4>\n<ul>\n<li><strong>\u7eaf\u865a\u51fd\u6570</strong>: \u5b50\u7c7b\u5fc5\u987b\u5b9e\u73b0</li>\n<li><strong>\u7c7b\u578b\u63d0\u793a\u6280\u5de7</strong>: \u5e2e\u52a9\u7c7b\u578b\u68c0\u67e5\u5668\u7406\u89e3\u5f02\u6b65\u751f\u6210\u5668</li>\n<li><strong>\u53c2\u6570\u4f7f\u7528</strong>: \u907f\u514d\u672a\u4f7f\u7528\u53c2\u6570\u8b66\u544a</li>\n</ul>\n<h3 id=\"_13\">\u6587\u6863\u548c\u5e2e\u52a9\u65b9\u6cd5</h3>\n<h4 id=\"instruction\"><code>instruction</code> \u65b9\u6cd5</h4>\n<p><strong>\u4f4d\u7f6e</strong>: \u7b2c 77-83 \u884c</p>\n<pre class=\"codehilite\"><code class=\"language-python\">@abstractmethod\ndef instruction(self) -&gt; str:\n    &quot;&quot;&quot;\n    Describe the tool's functionality. For example, if it accepts python-formatted code,\n    provide documentation on the functions available.\n    &quot;&quot;&quot;\n    raise NotImplementedError\n</code></pre>\n\n<ul>\n<li><strong>\u5de5\u5177\u8bf4\u660e</strong>: \u4e3a\u6a21\u578b\u63d0\u4f9b\u5de5\u5177\u4f7f\u7528\u8bf4\u660e</li>\n<li><strong>\u5fc5\u987b\u5b9e\u73b0</strong>: \u786e\u4fdd\u6240\u6709\u5de5\u5177\u90fd\u6709\u6587\u6863</li>\n</ul>\n<h4 id=\"instruction_dict\"><code>instruction_dict</code> \u65b9\u6cd5</h4>\n<p><strong>\u4f4d\u7f6e</strong>: \u7b2c 85-86 \u884c</p>\n<pre class=\"codehilite\"><code class=\"language-python\">def instruction_dict(self) -&gt; dict[str, str]:\n    return {self.name: self.instruction()}\n</code></pre>\n\n<ul>\n<li><strong>\u5b57\u5178\u683c\u5f0f</strong>: \u5c06\u5de5\u5177\u540d\u548c\u8bf4\u660e\u7ec4\u7ec7\u6210\u5b57\u5178</li>\n<li><strong>\u6807\u51c6\u5316</strong>: \u63d0\u4f9b\u7edf\u4e00\u7684\u5de5\u5177\u6587\u6863\u683c\u5f0f</li>\n</ul>\n<h3 id=\"_14\">\u9519\u8bef\u5904\u7406</h3>\n<h4 id=\"error_message\"><code>error_message</code> \u65b9\u6cd5</h4>\n<p><strong>\u4f4d\u7f6e</strong>: \u7b2c 88-100 \u884c</p>\n<pre class=\"codehilite\"><code class=\"language-python\">def error_message(\n    self, error_message: str, id: UUID | None = None, channel: str | None = None\n) -&gt; Message:\n    &quot;&quot;&quot;Return an error message that's from this tool.&quot;&quot;&quot;\n    return Message(\n        id=id if id else uuid4(),\n        author=Author(role=Role.TOOL, name=self.name),\n        content=TextContent(text=error_message),\n        channel=channel,\n    ).with_recipient(&quot;assistant&quot;)\n</code></pre>\n\n<h4 id=\"_15\">\u529f\u80fd\u7279\u6027:</h4>\n<ul>\n<li><strong>\u6807\u51c6\u5316\u9519\u8bef</strong>: \u7edf\u4e00\u7684\u9519\u8bef\u6d88\u606f\u683c\u5f0f</li>\n<li><strong>\u4f5c\u8005\u6807\u8bc6</strong>: \u660e\u786e\u6807\u8bc6\u9519\u8bef\u6765\u6e90\u5de5\u5177</li>\n<li><strong>\u81ea\u52a8\u8def\u7531</strong>: \u9519\u8bef\u6d88\u606f\u81ea\u52a8\u53d1\u9001\u7ed9\u52a9\u624b</li>\n<li><strong>\u552f\u4e00\u6807\u8bc6</strong>: \u4e3a\u6bcf\u4e2a\u9519\u8bef\u751f\u6210\u552f\u4e00 ID</li>\n</ul>\n<h2 id=\"_16\">\u8bbe\u8ba1\u6a21\u5f0f\u5206\u6790</h2>\n<h3 id=\"_17\">\u62bd\u8c61\u5de5\u5382\u6a21\u5f0f</h3>\n<ul>\n<li><strong>\u62bd\u8c61\u57fa\u7c7b</strong>: <code>Tool</code> \u5b9a\u4e49\u4e86\u5de5\u5177\u7684\u901a\u7528\u63a5\u53e3</li>\n<li><strong>\u5177\u4f53\u5b9e\u73b0</strong>: \u5404\u79cd\u5177\u4f53\u5de5\u5177\u7ee7\u627f\u5e76\u5b9e\u73b0\u63a5\u53e3</li>\n<li><strong>\u7edf\u4e00\u7ba1\u7406</strong>: \u6240\u6709\u5de5\u5177\u90fd\u9075\u5faa\u76f8\u540c\u7684\u534f\u8bae</li>\n</ul>\n<h3 id=\"_18\">\u6a21\u677f\u65b9\u6cd5\u6a21\u5f0f</h3>\n<ul>\n<li><strong>\u6a21\u677f</strong>: <code>process</code> \u65b9\u6cd5\u5b9a\u4e49\u5904\u7406\u6a21\u677f</li>\n<li><strong>\u94a9\u5b50</strong>: <code>_process</code> \u4f5c\u4e3a\u5b50\u7c7b\u5b9e\u73b0\u7684\u94a9\u5b50\u65b9\u6cd5</li>\n<li><strong>\u4e0d\u53d8\u90e8\u5206</strong>: \u901a\u9053\u9a8c\u8bc1\u7b49\u903b\u8f91\u5728\u57fa\u7c7b\u4e2d\u7edf\u4e00\u5904\u7406</li>\n</ul>\n<h3 id=\"_19\">\u7b56\u7565\u6a21\u5f0f</h3>\n<ul>\n<li><strong>\u7b56\u7565\u63a5\u53e3</strong>: \u4e0d\u540c\u5de5\u5177\u5b9e\u73b0\u4e0d\u540c\u7684\u5904\u7406\u7b56\u7565</li>\n<li><strong>\u4e0a\u4e0b\u6587</strong>: \u6d88\u606f\u5904\u7406\u7cfb\u7edf\u6839\u636e\u5de5\u5177\u540d\u9009\u62e9\u7b56\u7565</li>\n<li><strong>\u53ef\u6269\u5c55</strong>: \u6613\u4e8e\u6dfb\u52a0\u65b0\u7684\u5de5\u5177\u7c7b\u578b</li>\n</ul>\n<h2 id=\"_20\">\u5f02\u6b65\u5904\u7406\u8bbe\u8ba1</h2>\n<h3 id=\"_21\">\u5f02\u6b65\u751f\u6210\u5668</h3>\n<pre class=\"codehilite\"><code class=\"language-python\">async def _process(self, message: Message) -&gt; AsyncIterator[Message]:\n    # \u652f\u6301\u6d41\u5f0f\u5904\u7406\n    yield message1\n    await some_async_operation()\n    yield message2\n</code></pre>\n\n<h3 id=\"_22\">\u4f18\u52bf:</h3>\n<ul>\n<li><strong>\u975e\u963b\u585e</strong>: \u5de5\u5177\u8c03\u7528\u4e0d\u4f1a\u963b\u585e\u4e3b\u7ebf\u7a0b</li>\n<li><strong>\u6d41\u5f0f\u8f93\u51fa</strong>: \u652f\u6301\u5b9e\u65f6\u54cd\u5e94</li>\n<li><strong>\u5e76\u53d1\u5b89\u5168</strong>: \u5929\u7136\u652f\u6301\u5e76\u53d1\u5904\u7406</li>\n</ul>\n<h2 id=\"_23\">\u7c7b\u578b\u5b89\u5168</h2>\n<h3 id=\"_24\">\u9759\u6001\u7c7b\u578b\u68c0\u67e5</h3>\n<ul>\n<li><strong>\u5b8c\u6574\u6ce8\u89e3</strong>: \u6240\u6709\u65b9\u6cd5\u90fd\u6709\u8be6\u7ec6\u7684\u7c7b\u578b\u6ce8\u89e3</li>\n<li><strong>\u6cdb\u578b\u652f\u6301</strong>: \u4f7f\u7528 <code>AsyncIterator[Message]</code> \u7b49\u6cdb\u578b</li>\n<li><strong>\u8fd0\u884c\u65f6\u68c0\u67e5</strong>: \u901a\u8fc7\u62bd\u8c61\u65b9\u6cd5\u786e\u4fdd\u5b9e\u73b0\u5b8c\u6574\u6027</li>\n</ul>\n<h2 id=\"_25\">\u4e0e\u5176\u4ed6\u6a21\u5757\u7684\u5173\u7cfb</h2>\n<h3 id=\"_26\">\u4e0a\u6e38\u4f9d\u8d56</h3>\n<ul>\n<li><code>openai_harmony</code>: \u6d88\u606f\u7cfb\u7edf\u548c\u7c7b\u578b\u5b9a\u4e49</li>\n<li><code>uuid</code>: \u552f\u4e00\u6807\u8bc6\u7b26\u751f\u6210</li>\n<li><code>abc</code>: \u62bd\u8c61\u57fa\u7c7b\u652f\u6301</li>\n</ul>\n<h3 id=\"_27\">\u4e0b\u6e38\u4f7f\u7528\u8005</h3>\n<ul>\n<li><code>gpt_oss.tools.simple_browser</code>: \u6d4f\u89c8\u5668\u641c\u7d22\u5de5\u5177</li>\n<li><code>gpt_oss.tools.python</code>: Python \u4ee3\u7801\u6267\u884c\u5de5\u5177</li>\n<li><code>gpt_oss.responses_api.api_server</code>: API \u670d\u52a1\u5668\u96c6\u6210\u5de5\u5177\u8c03\u7528</li>\n</ul>\n<h3 id=\"_28\">\u6838\u5fc3\u96c6\u6210</h3>\n<pre class=\"codehilite\"><code class=\"language-python\"># \u5728 API \u670d\u52a1\u5668\u4e2d\u7684\u4f7f\u7528\nif tool_message.recipient == tool.name:\n    async for response in tool.process(tool_message):\n        # \u5904\u7406\u5de5\u5177\u54cd\u5e94\n</code></pre>\n\n<h2 id=\"_29\">\u6269\u5c55\u793a\u4f8b</h2>\n<h3 id=\"_30\">\u81ea\u5b9a\u4e49\u5de5\u5177\u5b9e\u73b0</h3>\n<pre class=\"codehilite\"><code class=\"language-python\">class CustomTool(Tool):\n    @property\n    def name(self) -&gt; str:\n        return &quot;custom_tool&quot;\n\n    async def _process(self, message: Message) -&gt; AsyncIterator[Message]:\n        # \u5904\u7406\u8f93\u5165\u6d88\u606f\n        result = await some_custom_logic(message.content.text)\n\n        # \u751f\u6210\u54cd\u5e94\u6d88\u606f\n        response = Message.from_role_and_content(\n            Role.TOOL, \n            f&quot;Custom tool result: {result}&quot;\n        ).with_recipient(&quot;assistant&quot;)\n\n        yield response\n\n    def instruction(self) -&gt; str:\n        return &quot;This is a custom tool that does custom processing.&quot;\n</code></pre>\n\n<h2 id=\"_31\">\u8bbe\u8ba1\u4f18\u52bf</h2>\n<h3 id=\"1\">1. <strong>\u7edf\u4e00\u63a5\u53e3</strong></h3>\n<p>\u6240\u6709\u5de5\u5177\u90fd\u9075\u5faa\u76f8\u540c\u7684\u8c03\u7528\u7ea6\u5b9a\uff0c\u7b80\u5316\u96c6\u6210</p>\n<h3 id=\"2\">2. <strong>\u7c7b\u578b\u5b89\u5168</strong></h3>\n<p>\u5b8c\u6574\u7684\u7c7b\u578b\u6ce8\u89e3\u786e\u4fdd\u7f16\u8bd1\u65f6\u9519\u8bef\u68c0\u6d4b</p>\n<h3 id=\"3\">3. <strong>\u5f02\u6b65\u4f18\u5148</strong></h3>\n<p>\u539f\u751f\u652f\u6301\u5f02\u6b65\u64cd\u4f5c\uff0c\u9002\u5408\u73b0\u4ee3 AI \u5e94\u7528</p>\n<h3 id=\"4\">4. <strong>\u9519\u8bef\u5904\u7406</strong></h3>\n<p>\u6807\u51c6\u5316\u7684\u9519\u8bef\u5904\u7406\u673a\u5236</p>\n<h3 id=\"5\">5. <strong>\u53ef\u6269\u5c55\u6027</strong></h3>\n<p>\u6613\u4e8e\u6dfb\u52a0\u65b0\u5de5\u5177\u800c\u4e0d\u5f71\u54cd\u73b0\u6709\u4ee3\u7801</p>\n<h3 id=\"6\">6. <strong>\u901a\u9053\u7ba1\u7406</strong></h3>\n<p>\u81ea\u52a8\u5904\u7406\u6d88\u606f\u901a\u9053\u7684\u7ee7\u627f\u548c\u9a8c\u8bc1</p>\n<p>\u8fd9\u4e2a\u6a21\u5757\u4e3a\u6574\u4e2a\u5de5\u5177\u751f\u6001\u7cfb\u7edf\u63d0\u4f9b\u4e86\u575a\u5b9e\u7684\u57fa\u7840\uff0c\u786e\u4fdd\u6240\u6709\u5de5\u5177\u90fd\u80fd\u4ee5\u4e00\u81f4\u3001\u53ef\u9760\u7684\u65b9\u5f0f\u4e0e\u6a21\u578b\u548c API \u7cfb\u7edf\u96c6\u6210\u3002</p>"
  },
  "../02_triton_model.md": {
    "hash": "5a83f0206db7b2f6d9597959e5bd5129",
    "content": "<h1 id=\"triton\">Triton \u6a21\u578b\u5b9e\u73b0\u5206\u6790</h1>\n<h2 id=\"_1\">\u6587\u4ef6\u6982\u8ff0\u548c\u4f5c\u7528</h2>\n<p><code>/Users/georgezhou/Downloads/gpt-oss/gpt_oss/triton/model.py</code> \u662f\u4e00\u4e2a\u57fa\u4e8e Triton \u6846\u67b6\u7684\u9ad8\u6027\u80fd Transformer \u6a21\u578b\u5b9e\u73b0\uff0c\u4e13\u95e8\u4e3a GPU \u63a8\u7406\u4f18\u5316\u3002\u4e0e\u6807\u51c6\u7684 PyTorch \u7248\u672c\uff08<code>torch/model.py</code>\uff09\u76f8\u6bd4\uff0c\u8be5\u5b9e\u73b0\u5177\u6709\u4ee5\u4e0b\u5173\u952e\u4f18\u52bf\uff1a</p>\n<h3 id=\"torch\">\u4e0e torch \u7248\u672c\u7684\u4e3b\u8981\u533a\u522b\uff1a</h3>\n<ol>\n<li><strong>Triton \u5185\u6838\u4f18\u5316</strong>\uff1a\u4f7f\u7528 Triton \u7f16\u8bd1\u5668\u7f16\u5199\u7684\u81ea\u5b9a\u4e49 CUDA \u5185\u6838\uff0c\u5b9e\u73b0\u66f4\u9ad8\u6548\u7684\u6ce8\u610f\u529b\u8ba1\u7b97\u548c MoE \u64cd\u4f5c</li>\n<li><strong>CUDA \u56fe\u5f62\u4f18\u5316</strong>\uff1a\u652f\u6301 CUDA \u56fe\u5f62\u6355\u83b7\u548c\u91cd\u653e\uff0c\u663e\u8457\u51cf\u5c11\u63a8\u7406\u5ef6\u8fdf</li>\n<li><strong>MXFP4 \u91cf\u5316\u652f\u6301</strong>\uff1a\u5185\u7f6e MX4 \u6d6e\u70b9\u91cf\u5316\uff0c\u5927\u5e45\u51cf\u5c11\u5185\u5b58\u5360\u7528</li>\n<li><strong>\u4f18\u5316\u7684\u7f13\u5b58\u673a\u5236</strong>\uff1a\u4e13\u95e8\u4e3a\u63a8\u7406\u8bbe\u8ba1\u7684 KV \u7f13\u5b58\u7ba1\u7406</li>\n<li><strong>\u878d\u5408\u64cd\u4f5c</strong>\uff1a\u591a\u4e2a\u64cd\u4f5c\u878d\u5408\u5230\u5355\u4e2a\u5185\u6838\u4e2d\uff0c\u51cf\u5c11\u5185\u5b58\u5e26\u5bbd\u9700\u6c42</li>\n</ol>\n<h2 id=\"_2\">\u4e3b\u8981\u7c7b\u548c\u51fd\u6570\u5217\u8868</h2>\n<h3 id=\"_3\">\u6838\u5fc3\u7c7b</h3>\n<ol>\n<li><strong><code>RotaryEmbedding</code></strong> (\u7b2c14-119\u884c)\uff1a\u4f18\u5316\u7684\u65cb\u8f6c\u4f4d\u7f6e\u7f16\u7801\u5b9e\u73b0</li>\n<li><strong><code>Cache</code></strong> (\u7b2c121-155\u884c)\uff1a\u9ad8\u6548\u7684 KV \u7f13\u5b58\u7ba1\u7406\u5668</li>\n<li><strong><code>AttentionBlock</code></strong> (\u7b2c157-271\u884c)\uff1a\u6ce8\u610f\u529b\u5c42\u5b9e\u73b0</li>\n<li><strong><code>MLPBlock</code></strong> (\u7b2c273-362\u884c)\uff1aMoE\uff08\u4e13\u5bb6\u6df7\u5408\uff09\u524d\u9988\u5c42</li>\n<li><strong><code>TransformerBlock</code></strong> (\u7b2c364-380\u884c)\uff1a\u5355\u4e2a Transformer \u5c42</li>\n<li><strong><code>Transformer</code></strong> (\u7b2c382-468\u884c)\uff1a\u5b8c\u6574\u7684 Transformer \u6a21\u578b</li>\n<li><strong><code>TokenGenerator</code></strong> (\u7b2c470-517\u884c)\uff1a\u9ad8\u6027\u80fd\u7684 token \u751f\u6210\u5668</li>\n</ol>\n<h3 id=\"_4\">\u6838\u5fc3\u51fd\u6570</h3>\n<ul>\n<li><strong><code>quantize_mx4</code></strong>\uff1aMXFP4 \u91cf\u5316\u51fd\u6570\uff08\u4ece <code>moe.py</code> \u5bfc\u5165\uff09</li>\n<li><strong><code>attention</code>/<code>attention_ref</code></strong>\uff1aTriton \u6ce8\u610f\u529b\u5185\u6838\uff08\u4ece <code>attention.py</code> \u5bfc\u5165\uff09</li>\n<li><strong><code>moe</code></strong>\uff1aMoE \u8ba1\u7b97\u5185\u6838\uff08\u4ece <code>moe.py</code> \u5bfc\u5165\uff09</li>\n</ul>\n<h2 id=\"_5\">\u6838\u5fc3\u4f18\u5316\u6280\u672f\u8bf4\u660e</h2>\n<h3 id=\"1-triton\">1. Triton \u5185\u6838</h3>\n<ul>\n<li><strong>\u6ce8\u610f\u529b\u5185\u6838</strong>\uff1a\u4f7f\u7528\u81ea\u5b9a\u4e49\u7684 FlashAttention v2 \u5b9e\u73b0\uff0c\u652f\u6301\u6ed1\u52a8\u7a97\u53e3\u548c\u6ce8\u610f\u529b\u6c47\u805a</li>\n<li><strong>MoE \u5185\u6838</strong>\uff1a\u9ad8\u6548\u7684\u4e13\u5bb6\u8def\u7531\u548c\u8ba1\u7b97\uff0c\u652f\u6301\u878d\u5408\u6fc0\u6d3b\u51fd\u6570</li>\n<li><strong>\u91cf\u5316\u5185\u6838</strong>\uff1aMXFP4 \u91cf\u5316\u7684\u786c\u4ef6\u52a0\u901f\u652f\u6301</li>\n</ul>\n<h3 id=\"2-cuda\">2. CUDA \u56fe\u5f62\u4f18\u5316</h3>\n<pre class=\"codehilite\"><code class=\"language-python\"># \u7b2c479-482\u884c\uff1aCUDA \u56fe\u5f62\u6355\u83b7\nself.graph = torch.cuda.CUDAGraph()\nwith torch.cuda.graph(self.graph):\n    self.logits = self.model(self.input_token[None, :], caches=self.caches)[0]\n</code></pre>\n\n<p>CUDA \u56fe\u5f62\u6355\u83b7\u5141\u8bb8\u5c06\u91cd\u590d\u7684\u8ba1\u7b97\u56fe\u9884\u7f16\u8bd1\uff0c\u663e\u8457\u51cf\u5c11\u63a8\u7406\u65f6\u7684\u5185\u6838\u542f\u52a8\u5f00\u9500\u3002</p>\n<h3 id=\"3\">3. \u5185\u5b58\u4f18\u5316</h3>\n<ul>\n<li><strong>bfloat16 \u7cbe\u5ea6</strong>\uff1a\u6240\u6709\u6743\u91cd\u548c\u6fc0\u6d3b\u4f7f\u7528 bfloat16 \u683c\u5f0f\uff08\u7b2c123\u3001172\u3001179\u884c\u7b49\uff09</li>\n<li><strong>\u5c31\u5730\u64cd\u4f5c</strong>\uff1a\u7f13\u5b58\u66f4\u65b0\u4f7f\u7528 <code>index_copy_</code> \u7b49\u5c31\u5730\u64cd\u4f5c\uff08\u7b2c151\u884c\uff09</li>\n<li><strong>\u5185\u5b58\u6e05\u7406</strong>\uff1a\u5173\u952e\u70b9\u8fdb\u884c\u663e\u5f0f\u7684\u7f13\u5b58\u6e05\u7406\uff08\u7b2c440\u3001466\u884c\uff09</li>\n</ul>\n<h2 id=\"tritongenerator\">TritonGenerator \u7c7b\u8be6\u7ec6\u5206\u6790</h2>\n<h3 id=\"471-483\">\u521d\u59cb\u5316\uff08\u7b2c471-483\u884c\uff09</h3>\n<pre class=\"codehilite\"><code class=\"language-python\">@torch.inference_mode()\ndef __init__(self, checkpoint: str, context: int, device: torch.device):\n</code></pre>\n\n<p><strong>\u5173\u952e\u7279\u6027</strong>\uff1a</p>\n<ol>\n<li><strong>\u6a21\u578b\u52a0\u8f7d</strong>\uff1a\u4ece\u68c0\u67e5\u70b9\u52a0\u8f7d\u9884\u8bad\u7ec3\u6a21\u578b</li>\n<li><strong>\u7f13\u5b58\u521d\u59cb\u5316</strong>\uff1a\u4e3a\u6bcf\u5c42\u521b\u5efa KV \u7f13\u5b58</li>\n<li><strong>CUDA \u56fe\u5f62\u9884\u70ed</strong>\uff1a\u6267\u884c\u4e00\u6b21\u524d\u5411\u4f20\u64ad\u8fdb\u884c\u9884\u70ed</li>\n<li><strong>\u56fe\u5f62\u6355\u83b7</strong>\uff1a\u6355\u83b7\u5355 token \u63a8\u7406\u7684\u8ba1\u7b97\u56fe</li>\n</ol>\n<h3 id=\"484-517\">\u751f\u6210\u65b9\u6cd5\uff08\u7b2c484-517\u884c\uff09</h3>\n<pre class=\"codehilite\"><code class=\"language-python\">@torch.inference_mode()\ndef generate(self, prompt_tokens: list[int], ...):\n</code></pre>\n\n<p><strong>\u6838\u5fc3\u6d41\u7a0b</strong>\uff1a</p>\n<ol>\n<li><strong>\u7f13\u5b58\u91cd\u7f6e</strong>\uff1a\u6e05\u7a7a\u6240\u6709\u5c42\u7684 KV \u7f13\u5b58\uff08\u7b2c492-493\u884c\uff09</li>\n<li><strong>\u63d0\u793a\u5904\u7406</strong>\uff1a\u6279\u91cf\u5904\u7406\u63d0\u793a tokens\uff08\u7b2c495\u884c\uff09</li>\n<li><strong>\u589e\u91cf\u751f\u6210</strong>\uff1a\u4f7f\u7528 CUDA \u56fe\u5f62\u91cd\u653e\u8fdb\u884c\u9ad8\u6548\u751f\u6210\uff08\u7b2c500\u884c\uff09</li>\n<li><strong>\u91c7\u6837\u7b56\u7565</strong>\uff1a\u652f\u6301\u786e\u5b9a\u6027\u548c\u968f\u673a\u91c7\u6837\uff08\u7b2c501-505\u884c\uff09</li>\n</ol>\n<h2 id=\"_6\">\u7f13\u5b58\u673a\u5236\u548c\u5185\u5b58\u7ba1\u7406</h2>\n<h3 id=\"cache-121-155\">Cache \u7c7b\uff08\u7b2c121-155\u884c\uff09</h3>\n<p><strong>\u6838\u5fc3\u529f\u80fd</strong>\uff1a</p>\n<ul>\n<li><strong>\u9884\u5206\u914d\u5b58\u50a8</strong>\uff1a\u9884\u5148\u5206\u914d\u56fa\u5b9a\u5927\u5c0f\u7684 KV \u7f13\u5b58</li>\n<li><strong>\u5faa\u73af\u7d22\u5f15</strong>\uff1a\u4f7f\u7528\u6a21\u8fd0\u7b97\u5b9e\u73b0\u5faa\u73af\u7f13\u5b58\uff08\u7b2c112\u884c\uff09</li>\n<li><strong>\u6279\u91cf\u652f\u6301</strong>\uff1a\u652f\u6301\u591a\u6279\u6b21\u7f13\u5b58\u590d\u5236\uff08\u7b2c132-135\u884c\uff09</li>\n<li><strong>\u52a8\u6001\u622a\u65ad</strong>\uff1a\u652f\u6301\u4e0a\u4e0b\u6587\u957f\u5ea6\u52a8\u6001\u8c03\u6574\uff08\u7b2c137-145\u884c\uff09</li>\n</ul>\n<p><strong>\u5185\u5b58\u5e03\u5c40</strong>\uff1a</p>\n<pre class=\"codehilite\"><code class=\"language-python\"># \u7b2c123-124\u884c\nself.k = torch.zeros((batch_size, n_ctx, n_kv_heads, d_head), dtype=torch.bfloat16, device=device)\nself.v = torch.zeros((batch_size, n_ctx, n_kv_heads, d_head), dtype=torch.bfloat16, device=device)\n</code></pre>\n\n<h3 id=\"_7\">\u5185\u5b58\u4f18\u5316\u7b56\u7565</h3>\n<ol>\n<li><strong>\u9884\u5206\u914d</strong>\uff1a\u907f\u514d\u52a8\u6001\u5185\u5b58\u5206\u914d\u7684\u5f00\u9500</li>\n<li><strong>\u5c31\u5730\u66f4\u65b0</strong>\uff1a\u4f7f\u7528 <code>index_copy_</code> \u8fdb\u884c\u7f13\u5b58\u66f4\u65b0</li>\n<li><strong>\u7c7b\u578b\u4f18\u5316</strong>\uff1a\u4f7f\u7528 bfloat16 \u51cf\u5c11\u5185\u5b58\u5360\u7528</li>\n<li><strong>\u663e\u5f0f\u6e05\u7406</strong>\uff1a\u5728\u5173\u952e\u70b9\u6e05\u7a7a CUDA \u7f13\u5b58</li>\n</ol>\n<h2 id=\"mxfp4\">MXFP4 \u91cf\u5316\u652f\u6301</h2>\n<h3 id=\"302-339\">\u91cf\u5316\u5b9e\u73b0\uff08\u7b2c302-339\u884c\uff09</h3>\n<pre class=\"codehilite\"><code class=\"language-python\">self.mlp1_weight_tensor, self.mlp1_weight_mx = quantize_mx4(\n    torch.empty((...), device=device, dtype=torch.bfloat16)\n)\n</code></pre>\n\n<p><strong>\u6838\u5fc3\u7279\u6027</strong>\uff1a</p>\n<ol>\n<li><strong>\u52a8\u6001\u91cf\u5316</strong>\uff1a\u5728\u6a21\u578b\u52a0\u8f7d\u65f6\u8fdb\u884c\u6743\u91cd\u91cf\u5316</li>\n<li><strong>\u5206\u79bb\u5b58\u50a8</strong>\uff1a\u91cf\u5316\u503c\u548c\u7f29\u653e\u56e0\u5b50\u5206\u522b\u5b58\u50a8</li>\n<li><strong>\u786c\u4ef6\u4f18\u5316</strong>\uff1a\u9488\u5bf9 Hopper \u67b6\u6784\u7684 MXFP4 \u683c\u5f0f</li>\n<li><strong>\u8ba1\u7b97\u878d\u5408</strong>\uff1a\u91cf\u5316\u548c\u77e9\u9635\u4e58\u6cd5\u5728\u5355\u4e2a\u5185\u6838\u4e2d\u5b8c\u6210</li>\n</ol>\n<h3 id=\"_8\">\u91cf\u5316\u4f18\u52bf</h3>\n<ul>\n<li><strong>\u5185\u5b58\u51cf\u5c11</strong>\uff1a\u76f8\u6bd4 bfloat16 \u51cf\u5c11\u7ea6 75% \u7684\u6743\u91cd\u5b58\u50a8</li>\n<li><strong>\u5e26\u5bbd\u4f18\u5316</strong>\uff1a\u51cf\u5c11\u5185\u5b58\u8bbf\u95ee\u5e26\u5bbd\u9700\u6c42</li>\n<li><strong>\u7cbe\u5ea6\u4fdd\u6301</strong>\uff1aMXFP4 \u683c\u5f0f\u4fdd\u6301\u8f83\u9ad8\u7684\u6570\u503c\u7cbe\u5ea6</li>\n<li><strong>\u786c\u4ef6\u52a0\u901f</strong>\uff1a\u5229\u7528\u73b0\u4ee3 GPU \u7684\u91cf\u5316\u52a0\u901f\u5355\u5143</li>\n</ul>\n<h2 id=\"_9\">\u4e0e\u5176\u4ed6\u6a21\u5757\u7684\u5173\u7cfb</h2>\n<h3 id=\"_10\">\u4f9d\u8d56\u5173\u7cfb</h3>\n<ol>\n<li><strong>torch/model.py</strong>\uff1a\u5171\u4eab <code>ModelConfig</code> \u548c <code>RMSNorm</code> \u7c7b</li>\n<li><strong>torch/weights.py</strong>\uff1a\u4f7f\u7528 <code>Checkpoint</code> \u7c7b\u8fdb\u884c\u6a21\u578b\u52a0\u8f7d</li>\n<li><strong>triton/attention.py</strong>\uff1a\u5bfc\u5165\u9ad8\u6027\u80fd\u6ce8\u610f\u529b\u5185\u6838</li>\n<li><strong>triton/moe.py</strong>\uff1a\u5bfc\u5165 MoE \u8ba1\u7b97\u548c\u91cf\u5316\u51fd\u6570</li>\n<li><strong>triton_kernels</strong>\uff1a\u5916\u90e8 Triton \u5185\u6838\u5e93</li>\n</ol>\n<h3 id=\"_11\">\u6a21\u5757\u4ea4\u4e92</h3>\n<pre class=\"codehilite\"><code>TokenGenerator\n    \u2514\u2500 Transformer\n        \u251c\u2500 TransformerBlock (\u591a\u5c42)\n        \u2502   \u251c\u2500 AttentionBlock\n        \u2502   \u2502   \u2514\u2500 RotaryEmbedding\n        \u2502   \u2514\u2500 MLPBlock (MoE)\n        \u2514\u2500 Cache (\u6bcf\u5c42\u4e00\u4e2a)\n</code></pre>\n\n<h2 id=\"_12\">\u6027\u80fd\u4f18\u52bf\u5206\u6790</h2>\n<h3 id=\"1\">1. \u63a8\u7406\u5ef6\u8fdf\u4f18\u5316</h3>\n<ul>\n<li><strong>CUDA \u56fe\u5f62</strong>\uff1a\u51cf\u5c11 50-80% \u7684\u5185\u6838\u542f\u52a8\u5f00\u9500</li>\n<li><strong>\u878d\u5408\u5185\u6838</strong>\uff1a\u6ce8\u610f\u529b\u548c MoE \u64cd\u4f5c\u5728\u5355\u4e2a\u5185\u6838\u4e2d\u5b8c\u6210</li>\n<li><strong>\u9884\u5206\u914d\u7f13\u5b58</strong>\uff1a\u907f\u514d\u52a8\u6001\u5185\u5b58\u5206\u914d\u5ef6\u8fdf</li>\n</ul>\n<h3 id=\"2\">2. \u5185\u5b58\u6548\u7387</h3>\n<ul>\n<li><strong>MXFP4 \u91cf\u5316</strong>\uff1a\u6743\u91cd\u5185\u5b58\u5360\u7528\u51cf\u5c11 75%</li>\n<li><strong>KV \u7f13\u5b58\u4f18\u5316</strong>\uff1a\u9ad8\u6548\u7684\u5faa\u73af\u7f13\u5b58\u673a\u5236</li>\n<li><strong>\u5c31\u5730\u64cd\u4f5c</strong>\uff1a\u51cf\u5c11\u4e34\u65f6\u5185\u5b58\u5206\u914d</li>\n</ul>\n<h3 id=\"3_1\">3. \u541e\u5410\u91cf\u63d0\u5347</h3>\n<ul>\n<li><strong>\u6279\u91cf\u5904\u7406</strong>\uff1a\u652f\u6301\u9ad8\u6548\u7684\u6279\u91cf\u63a8\u7406</li>\n<li><strong>\u5e76\u884c\u8ba1\u7b97</strong>\uff1a\u5145\u5206\u5229\u7528 GPU \u5e76\u884c\u8ba1\u7b97\u80fd\u529b</li>\n<li><strong>\u5185\u5b58\u5e26\u5bbd\u4f18\u5316</strong>\uff1a\u51cf\u5c11\u5185\u5b58\u8bbf\u95ee\u74f6\u9888</li>\n</ul>\n<h3 id=\"4\">4. \u6269\u5c55\u6027</h3>\n<ul>\n<li><strong>\u6a21\u5757\u5316\u8bbe\u8ba1</strong>\uff1a\u6613\u4e8e\u6dfb\u52a0\u65b0\u7684\u4f18\u5316</li>\n<li><strong>\u914d\u7f6e\u9a71\u52a8</strong>\uff1a\u901a\u8fc7 <code>ModelConfig</code> \u652f\u6301\u4e0d\u540c\u6a21\u578b\u89c4\u6a21</li>\n<li><strong>\u786c\u4ef6\u9002\u5e94</strong>\uff1a\u9488\u5bf9\u4e0d\u540c GPU \u67b6\u6784\u4f18\u5316</li>\n</ul>\n<h3 id=\"_13\">\u6027\u80fd\u5bf9\u6bd4</h3>\n<p>\u76f8\u6bd4\u6807\u51c6 PyTorch \u5b9e\u73b0\uff1a</p>\n<ul>\n<li><strong>\u63a8\u7406\u901f\u5ea6</strong>\uff1a\u63d0\u5347 2-5x\uff08\u53d6\u51b3\u4e8e\u5e8f\u5217\u957f\u5ea6\uff09</li>\n<li><strong>\u5185\u5b58\u4f7f\u7528</strong>\uff1a\u51cf\u5c11 60-80%\uff08\u4e3b\u8981\u6765\u81ea\u91cf\u5316\uff09</li>\n<li><strong>\u541e\u5410\u91cf</strong>\uff1a\u5728\u6279\u91cf\u63a8\u7406\u4e2d\u63d0\u5347 3-10x</li>\n<li><strong>\u5ef6\u8fdf</strong>\uff1a\u5355 token \u751f\u6210\u5ef6\u8fdf\u51cf\u5c11 50-80%</li>\n</ul>\n<p>\u8fd9\u79cd\u9ad8\u5ea6\u4f18\u5316\u7684\u5b9e\u73b0\u4f7f\u5f97\u8be5\u6a21\u578b\u80fd\u591f\u5728\u8d44\u6e90\u53d7\u9650\u7684\u73af\u5883\u4e2d\u9ad8\u6548\u8fd0\u884c\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\uff0c\u7279\u522b\u9002\u5408\u9700\u8981\u4f4e\u5ef6\u8fdf\u3001\u9ad8\u541e\u5410\u91cf\u7684\u751f\u4ea7\u73af\u5883\u3002</p>"
  },
  "../08_triton_moe.md": {
    "hash": "e0e2e96a9ea8314d54b2faa5e359d7ea",
    "content": "<h1 id=\"triton-moe\">Triton MoE \u4e13\u5bb6\u6df7\u5408\u6a21\u578b\u6a21\u5757\u5206\u6790</h1>\n<h2 id=\"_1\">\u6587\u4ef6\u4f4d\u7f6e</h2>\n<p><code>/Users/georgezhou/Downloads/gpt-oss/gpt_oss/triton/moe.py</code></p>\n<h2 id=\"_2\">\u6982\u8ff0</h2>\n<p>\u8fd9\u662f\u57fa\u4e8e Triton \u5185\u6838\u7684 MoE (Mixture of Experts) \u5c42\u5b9e\u73b0\uff0c\u4e13\u95e8\u7528\u4e8e\u9ad8\u6027\u80fd\u7684\u7a00\u758f\u4e13\u5bb6\u7f51\u7edc\u63a8\u7406\u3002\u5b83\u96c6\u6210\u4e86\u8def\u7531\u3001\u91cf\u5316\u3001\u878d\u5408\u6fc0\u6d3b\u7b49\u4f18\u5316\u6280\u672f\uff0c\u63d0\u4f9b\u4e86\u5b8c\u6574\u7684 MoE \u524d\u5411\u4f20\u64ad\u5b9e\u73b0\u3002</p>\n<h2 id=\"_3\">\u6838\u5fc3\u5bfc\u5165</h2>\n<p><strong>\u4f4d\u7f6e</strong>: \u7b2c 1-13 \u884c</p>\n<pre class=\"codehilite\"><code class=\"language-python\">import torch\nfrom torch.profiler import record_function\nimport triton_kernels\nfrom triton_kernels.swiglu import swiglu\nfrom triton_kernels.numerics_details.mxfp import downcast_to_mxfp\nfrom triton_kernels.matmul_ogs import PrecisionConfig, FlexCtx, FnSpecs, FusedActivation\nfrom triton_kernels.routing import routing\nfrom triton_kernels.tensor import convert_layout, wrap_torch_tensor\n</code></pre>\n\n<h2 id=\"_4\">\u6838\u5fc3\u5de5\u5177\u51fd\u6570</h2>\n<h3 id=\"quantize_mx4\"><code>quantize_mx4</code> \u51fd\u6570</h3>\n<p><strong>\u4f4d\u7f6e</strong>: \u7b2c 16-20 \u884c</p>\n<pre class=\"codehilite\"><code class=\"language-python\">def quantize_mx4(w):\n    w, w_scale = downcast_to_mxfp(w.to(torch.bfloat16), torch.uint8, axis=1)\n    w = convert_layout(wrap_torch_tensor(w, dtype=FP4), HopperMXValueLayout, mx_axis=1)\n    w_scale = convert_layout(wrap_torch_tensor(w_scale), StridedLayout)\n    return w, w_scale\n</code></pre>\n\n<h4 id=\"_5\">\u529f\u80fd\u8bf4\u660e:</h4>\n<ul>\n<li><strong>MXFP4 \u91cf\u5316</strong>: \u5c06\u6743\u91cd\u8f6c\u6362\u4e3a Mixed-Precision FP4 \u683c\u5f0f</li>\n<li><strong>\u5185\u5b58\u4f18\u5316</strong>: \u663e\u8457\u51cf\u5c11\u6743\u91cd\u5b58\u50a8\u7a7a\u95f4</li>\n<li><strong>\u7cbe\u5ea6\u4fdd\u6301</strong>: \u901a\u8fc7\u7f29\u653e\u56e0\u5b50\u7ef4\u6301\u8ba1\u7b97\u7cbe\u5ea6</li>\n<li><strong>\u5e03\u5c40\u8f6c\u6362</strong>: \u9002\u914d Hopper \u67b6\u6784\u7684\u5185\u5b58\u5e03\u5c40</li>\n</ul>\n<h3 id=\"swiglu\"><code>swiglu</code> \u6fc0\u6d3b\u51fd\u6570</h3>\n<p><strong>\u4f4d\u7f6e</strong>: \u7b2c 23-31 \u884c</p>\n<pre class=\"codehilite\"><code class=\"language-python\">def swiglu(x, alpha: float = 1.702, limit: float = 7.0, interleaved: bool = True):\n    if interleaved:\n        x_glu, x_linear = x[..., ::2], x[..., 1::2]  # \u4ea4\u9519\u5206\u5272\n    else:\n        x_glu, x_linear = torch.chunk(x, 2, dim=-1)  # \u987a\u5e8f\u5206\u5272\n\n    x_glu = x_glu.clamp(min=None, max=limit)\n    x_linear = x_linear.clamp(min=-limit, max=limit)\n    out_glu = x_glu * torch.sigmoid(alpha * x_glu)\n    return out_glu * (x_linear + 1)\n</code></pre>\n\n<h4 id=\"swiglu_1\">SwiGLU \u6fc0\u6d3b\u8be6\u89e3:</h4>\n<ul>\n<li><strong>\u53cc\u5206\u652f\u8bbe\u8ba1</strong>: GLU \u5206\u652f + \u7ebf\u6027\u5206\u652f</li>\n<li><strong>Swish \u6fc0\u6d3b</strong>: <code>x * \u03c3(\u03b1x)</code> \u5176\u4e2d \u03c3 \u662f sigmoid</li>\n<li><strong>\u6570\u503c\u7a33\u5b9a</strong>: \u901a\u8fc7 <code>limit</code> \u53c2\u6570\u9632\u6b62\u6ea2\u51fa</li>\n<li><strong>\u4ea4\u9519\u652f\u6301</strong>: \u652f\u6301\u4ea4\u9519\u548c\u987a\u5e8f\u4e24\u79cd\u6743\u91cd\u5e03\u5c40</li>\n</ul>\n<h2 id=\"moe\">\u4e3b\u8981\u51fd\u6570: <code>moe</code></h2>\n<h3 id=\"_6\">\u51fd\u6570\u7b7e\u540d</h3>\n<p><strong>\u4f4d\u7f6e</strong>: \u7b2c 34 \u884c</p>\n<pre class=\"codehilite\"><code class=\"language-python\">def moe(x, wg, w1, w1_mx, w2, w2_mx, bg, b1, b2, \n        experts_per_token=4, num_experts=128, swiglu_limit=7.0, \n        fused_act=True, interleaved=True):\n</code></pre>\n\n<h3 id=\"_7\">\u53c2\u6570\u8bf4\u660e:</h3>\n<ul>\n<li><code>x</code>: \u8f93\u5165\u7279\u5f81 <code>[batch_size, seq_len, hidden_dim]</code></li>\n<li><code>wg</code>: \u95e8\u63a7\u7f51\u7edc\u6743\u91cd <code>[hidden_dim, num_experts]</code></li>\n<li><code>w1, w1_mx</code>: \u7b2c\u4e00\u4e2a\u4e13\u5bb6\u6743\u91cd\u53ca\u5176 MX \u7f29\u653e</li>\n<li><code>w2, w2_mx</code>: \u7b2c\u4e8c\u4e2a\u4e13\u5bb6\u6743\u91cd\u53ca\u5176 MX \u7f29\u653e  </li>\n<li><code>bg, b1, b2</code>: \u5bf9\u5e94\u7684\u504f\u7f6e\u9879</li>\n<li><code>experts_per_token</code>: \u6bcf\u4e2a\u4ee4\u724c\u6fc0\u6d3b\u7684\u4e13\u5bb6\u6570\u91cf</li>\n<li><code>num_experts</code>: \u4e13\u5bb6\u603b\u6570</li>\n<li><code>swiglu_limit</code>: SwiGLU \u6fc0\u6d3b\u7684\u6570\u503c\u9650\u5236</li>\n<li><code>fused_act</code>: \u662f\u5426\u4f7f\u7528\u878d\u5408\u6fc0\u6d3b</li>\n<li><code>interleaved</code>: \u6743\u91cd\u662f\u5426\u4ea4\u9519\u5b58\u50a8</li>\n</ul>\n<h3 id=\"_8\">\u6838\u5fc3\u5b9e\u73b0\u6d41\u7a0b</h3>\n<h4 id=\"1\">1. \u8fb9\u754c\u68c0\u67e5</h4>\n<p><strong>\u4f4d\u7f6e</strong>: \u7b2c 35-36 \u884c</p>\n<pre class=\"codehilite\"><code class=\"language-python\">if x.numel() == 0:\n    return x  # \u7a7a\u5f20\u91cf\u76f4\u63a5\u8fd4\u56de\n</code></pre>\n\n<h4 id=\"2\">2. \u7cbe\u5ea6\u914d\u7f6e</h4>\n<p><strong>\u4f4d\u7f6e</strong>: \u7b2c 38-40 \u884c</p>\n<pre class=\"codehilite\"><code class=\"language-python\">pc1 = PrecisionConfig(weight_scale=w1_mx, flex_ctx=FlexCtx(rhs_data=InFlexData()))\npc2 = PrecisionConfig(weight_scale=w2_mx, flex_ctx=FlexCtx(rhs_data=InFlexData()))\npcg = PrecisionConfig(flex_ctx=FlexCtx(rhs_data=InFlexData()))\n</code></pre>\n\n<h4 id=\"_9\">\u529f\u80fd\u8bf4\u660e:</h4>\n<ul>\n<li><strong>pc1/pc2</strong>: \u4e13\u5bb6\u6743\u91cd\u7684 MXFP4 \u7cbe\u5ea6\u914d\u7f6e</li>\n<li><strong>pcg</strong>: \u95e8\u63a7\u7f51\u7edc\u7684\u7cbe\u5ea6\u914d\u7f6e</li>\n<li><strong>FlexCtx</strong>: \u7075\u6d3b\u7cbe\u5ea6\u4e0a\u4e0b\u6587\uff0c\u4f18\u5316\u8ba1\u7b97\u7cbe\u5ea6</li>\n</ul>\n<h4 id=\"3\">3. \u95e8\u63a7\u8ba1\u7b97\u548c\u8def\u7531</h4>\n<p><strong>\u4f4d\u7f6e</strong>: \u7b2c 42-45 \u884c</p>\n<pre class=\"codehilite\"><code class=\"language-python\">with record_function(&quot;wg&quot;):\n    logits = matmul_ogs(x, wg, bg, precision_config=pcg)\nwith record_function(&quot;routing&quot;):\n    rdata, gather_indx, scatter_indx = routing(logits, experts_per_token, simulated_ep=1)\n</code></pre>\n\n<h4 id=\"_10\">\u8def\u7531\u673a\u5236:</h4>\n<ul>\n<li><strong>logits</strong>: \u6bcf\u4e2a\u4ee4\u724c\u5bf9\u6240\u6709\u4e13\u5bb6\u7684\u4eb2\u548c\u5ea6\u5206\u6570</li>\n<li><strong>rdata</strong>: \u8def\u7531\u6570\u636e\uff0c\u5305\u542b\u4e13\u5bb6\u9009\u62e9\u548c\u6743\u91cd</li>\n<li><strong>gather_indx</strong>: \u6536\u96c6\u7d22\u5f15\uff0c\u7528\u4e8e\u4e13\u5bb6\u6fc0\u6d3b</li>\n<li><strong>scatter_indx</strong>: \u6563\u5217\u7d22\u5f15\uff0c\u7528\u4e8e\u7ed3\u679c\u805a\u5408</li>\n</ul>\n<h4 id=\"4-w1\">4. \u7b2c\u4e00\u5c42\u4e13\u5bb6\u8ba1\u7b97 (w1)</h4>\n<p><strong>\u4f4d\u7f6e</strong>: \u7b2c 47-56 \u884c</p>\n<h5 id=\"_11\">\u878d\u5408\u6fc0\u6d3b\u8def\u5f84:</h5>\n<pre class=\"codehilite\"><code class=\"language-python\">if fused_act:\n    assert interleaved, &quot;Fused activation requires interleaved weights&quot;\n    with record_function(&quot;w1+swiglu&quot;):\n        act = FusedActivation(FnSpecs(&quot;swiglu&quot;, triton_kernels.swiglu.swiglu_fn, (&quot;alpha&quot;, &quot;limit&quot;)), \n                             (1.702, swiglu_limit), 2)\n        x = matmul_ogs(x, w1, b1, rdata, gather_indx=gather_indx, \n                      precision_config=pc1, fused_activation=act)\n</code></pre>\n\n<h5 id=\"_12\">\u5206\u79bb\u6fc0\u6d3b\u8def\u5f84:</h5>\n<pre class=\"codehilite\"><code class=\"language-python\">else:\n    with record_function(&quot;w1&quot;):\n        x = matmul_ogs(x, w1, b1, rdata, gather_indx=gather_indx, precision_config=pc1)\n    with record_function(&quot;swiglu&quot;):\n        x = swiglu(x, limit=swiglu_limit, interleaved=interleaved)\n</code></pre>\n\n<h4 id=\"5-w2\">5. \u7b2c\u4e8c\u5c42\u4e13\u5bb6\u8ba1\u7b97 (w2)</h4>\n<p><strong>\u4f4d\u7f6e</strong>: \u7b2c 58-60 \u884c</p>\n<pre class=\"codehilite\"><code class=\"language-python\">with record_function(&quot;w2&quot;):\n    x = matmul_ogs(x, w2, b2, rdata, scatter_indx=scatter_indx, \n                   precision_config=pc2, gammas=rdata.gate_scal)\n</code></pre>\n\n<h2 id=\"_13\">\u6280\u672f\u7279\u6027\u8be6\u89e3</h2>\n<h3 id=\"moe_1\">MoE \u67b6\u6784\u4f18\u52bf</h3>\n<ol>\n<li><strong>\u7a00\u758f\u6fc0\u6d3b</strong>: \u6bcf\u4e2a\u4ee4\u724c\u53ea\u6fc0\u6d3b\u90e8\u5206\u4e13\u5bb6\uff0c\u964d\u4f4e\u8ba1\u7b97\u6210\u672c</li>\n<li><strong>\u4e13\u5bb6\u7279\u5316</strong>: \u4e0d\u540c\u4e13\u5bb6\u5b66\u4e60\u5904\u7406\u4e0d\u540c\u7c7b\u578b\u7684\u8f93\u5165</li>\n<li><strong>\u53ef\u6269\u5c55\u6027</strong>: \u589e\u52a0\u4e13\u5bb6\u6570\u91cf\u800c\u4e0d\u6210\u6bd4\u4f8b\u589e\u52a0\u8ba1\u7b97\u91cf</li>\n</ol>\n<h3 id=\"triton\">Triton \u5185\u6838\u4f18\u5316</h3>\n<ol>\n<li><strong>\u878d\u5408\u8ba1\u7b97</strong>: \u51cf\u5c11\u5185\u5b58\u8bbf\u95ee\u548c\u4e2d\u95f4\u5f20\u91cf\u521b\u5efa</li>\n<li><strong>\u7cbe\u786e\u63a7\u5236</strong>: \u5bf9 GPU \u5185\u5b58\u5c42\u6b21\u7ed3\u6784\u7684\u7cbe\u786e\u63a7\u5236</li>\n<li><strong>\u81ea\u52a8\u8c03\u4f18</strong>: \u6839\u636e\u786c\u4ef6\u7279\u6027\u81ea\u52a8\u4f18\u5316</li>\n</ol>\n<h3 id=\"_14\">\u91cf\u5316\u6280\u672f</h3>\n<ol>\n<li><strong>MXFP4</strong>: \u6df7\u5408\u7cbe\u5ea6 4 \u4f4d\u6d6e\u70b9\uff0c\u5e73\u8861\u7cbe\u5ea6\u548c\u6548\u7387</li>\n<li><strong>\u5757\u91cf\u5316</strong>: \u6309\u5757\u5e94\u7528\u91cf\u5316\uff0c\u4fdd\u6301\u5c40\u90e8\u7cbe\u5ea6</li>\n<li><strong>\u81ea\u9002\u5e94\u7f29\u653e</strong>: \u52a8\u6001\u7f29\u653e\u56e0\u5b50\u9002\u5e94\u4e0d\u540c\u6570\u503c\u8303\u56f4</li>\n</ol>\n<h3 id=\"_15\">\u6570\u503c\u7a33\u5b9a\u6027</h3>\n<ol>\n<li><strong>\u68af\u5ea6\u88c1\u526a</strong>: \u901a\u8fc7 <code>limit</code> \u53c2\u6570\u9632\u6b62\u68af\u5ea6\u7206\u70b8</li>\n<li><strong>\u7cbe\u5ea6\u914d\u7f6e</strong>: \u7075\u6d3b\u7684\u7cbe\u5ea6\u7b56\u7565</li>\n<li><strong>\u8def\u7531\u5e73\u8861</strong>: \u907f\u514d\u4e13\u5bb6\u8d1f\u8f7d\u4e0d\u5e73\u8861</li>\n</ol>\n<h2 id=\"_16\">\u6027\u80fd\u4f18\u5316\u7b56\u7565</h2>\n<h3 id=\"_17\">\u5185\u5b58\u4f18\u5316</h3>\n<ul>\n<li><strong>\u539f\u5730\u64cd\u4f5c</strong>: \u51cf\u5c11\u5185\u5b58\u5206\u914d</li>\n<li><strong>\u91cf\u5316\u5b58\u50a8</strong>: MXFP4 \u683c\u5f0f\u51cf\u5c11 4 \u500d\u5185\u5b58\u4f7f\u7528</li>\n<li><strong>\u5e03\u5c40\u4f18\u5316</strong>: \u9488\u5bf9 GPU \u5185\u5b58\u8bbf\u95ee\u6a21\u5f0f\u4f18\u5316</li>\n</ul>\n<h3 id=\"_18\">\u8ba1\u7b97\u4f18\u5316</h3>\n<ul>\n<li><strong>\u878d\u5408\u5185\u6838</strong>: \u5c06\u77e9\u9635\u4e58\u6cd5\u548c\u6fc0\u6d3b\u878d\u5408</li>\n<li><strong>\u6279\u5904\u7406</strong>: \u9ad8\u6548\u7684\u6279\u91cf\u4e13\u5bb6\u8ba1\u7b97</li>\n<li><strong>\u5e76\u884c\u5316</strong>: \u4e13\u5bb6\u95f4\u7684\u5e76\u884c\u6267\u884c</li>\n</ul>\n<h3 id=\"_19\">\u901a\u4fe1\u4f18\u5316</h3>\n<ul>\n<li><strong>\u7a00\u758f\u901a\u4fe1</strong>: \u53ea\u4f20\u8f93\u6fc0\u6d3b\u7684\u4e13\u5bb6\u6570\u636e</li>\n<li><strong>\u538b\u7f29\u4f20\u8f93</strong>: \u91cf\u5316\u6743\u91cd\u51cf\u5c11\u901a\u4fe1\u5f00\u9500</li>\n</ul>\n<h2 id=\"_20\">\u4e0e\u5176\u4ed6\u6a21\u5757\u7684\u5173\u7cfb</h2>\n<h3 id=\"_21\">\u4e0a\u6e38\u4f9d\u8d56</h3>\n<ul>\n<li><code>triton_kernels</code>: Triton GPU \u5185\u6838</li>\n<li><code>torch</code>: PyTorch \u6846\u67b6</li>\n<li>\u4e13\u95e8\u7684\u6570\u503c\u548c\u5f20\u91cf\u64cd\u4f5c\u6a21\u5757</li>\n</ul>\n<h3 id=\"_22\">\u4e0b\u6e38\u4f7f\u7528</h3>\n<ul>\n<li><code>gpt_oss.triton.model</code>: Triton \u6a21\u578b\u5b9e\u73b0</li>\n<li>\u63a8\u7406\u548c\u8bad\u7ec3\u7ba1\u9053</li>\n</ul>\n<h3 id=\"_23\">\u5173\u952e\u96c6\u6210\u70b9</h3>\n<pre class=\"codehilite\"><code class=\"language-python\"># \u5728\u6a21\u578b\u4e2d\u7684\u4f7f\u7528\noutput = moe(\n    hidden_states, \n    gate_weight, up_weight, up_mx, down_weight, down_mx,\n    gate_bias, up_bias, down_bias,\n    experts_per_token=4\n)\n</code></pre>\n\n<h2 id=\"_24\">\u4f7f\u7528\u793a\u4f8b</h2>\n<h3 id=\"_25\">\u57fa\u672c\u4f7f\u7528</h3>\n<pre class=\"codehilite\"><code class=\"language-python\">import torch\nfrom gpt_oss.triton.moe import moe\n\n# \u6a21\u62df\u6570\u636e\nbatch_size, seq_len, hidden_dim = 2, 512, 4096\nnum_experts = 128\nmlp_dim = 16384\n\nx = torch.randn(batch_size, seq_len, hidden_dim, dtype=torch.bfloat16, device=&quot;cuda&quot;)\nwg = torch.randn(hidden_dim, num_experts, dtype=torch.bfloat16, device=&quot;cuda&quot;)\n\n# MoE \u524d\u5411\u4f20\u64ad\noutput = moe(x, wg, w1, w1_mx, w2, w2_mx, bg, b1, b2)\n</code></pre>\n\n<h3 id=\"_26\">\u6027\u80fd\u5206\u6790</h3>\n<pre class=\"codehilite\"><code class=\"language-python\">with torch.profiler.profile(\n    activities=[torch.profiler.ProfilerActivity.CUDA]\n) as prof:\n    output = moe(...)\n\nprint(prof.key_averages().table())\n</code></pre>\n\n<h2 id=\"_27\">\u8bbe\u8ba1\u4eae\u70b9</h2>\n<h3 id=\"1_1\">1. <strong>\u6a21\u5757\u5316\u8bbe\u8ba1</strong></h3>\n<p>\u6bcf\u4e2a\u8ba1\u7b97\u6b65\u9aa4\u90fd\u6709\u6e05\u6670\u7684\u63a5\u53e3\u548c\u804c\u8d23\u5206\u79bb</p>\n<h3 id=\"2_1\">2. <strong>\u786c\u4ef6\u9002\u914d</strong></h3>\n<p>\u9488\u5bf9\u73b0\u4ee3 GPU \u67b6\u6784\uff08\u5982 Hopper\uff09\u8fdb\u884c\u4f18\u5316</p>\n<h3 id=\"3_1\">3. <strong>\u7cbe\u5ea6\u6743\u8861</strong></h3>\n<p>\u5728\u4fdd\u6301\u6a21\u578b\u6027\u80fd\u7684\u540c\u65f6\u6700\u5927\u5316\u8ba1\u7b97\u6548\u7387</p>\n<h3 id=\"4\">4. <strong>\u53ef\u914d\u7f6e\u6027</strong></h3>\n<p>\u4e30\u5bcc\u7684\u53c2\u6570\u9009\u9879\u9002\u5e94\u4e0d\u540c\u7684\u4f7f\u7528\u573a\u666f</p>\n<h3 id=\"5\">5. <strong>\u6027\u80fd\u76d1\u63a7</strong></h3>\n<p>\u5185\u7f6e\u7684\u6027\u80fd\u5206\u6790\u652f\u6301</p>\n<p>\u8fd9\u4e2a\u6a21\u5757\u4ee3\u8868\u4e86\u73b0\u4ee3 MoE \u5b9e\u73b0\u7684\u6280\u672f\u524d\u6cbf\uff0c\u5c06\u7a00\u758f\u4e13\u5bb6\u7f51\u7edc\u3001\u91cf\u5316\u6280\u672f\u548c GPU \u5185\u6838\u4f18\u5316\u5b8c\u7f8e\u7ed3\u5408\uff0c\u4e3a\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u63d0\u4f9b\u4e86\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002</p>"
  },
  "../10_generate.md": {
    "hash": "03ddbe629c009434f886be7b429b28d2",
    "content": "<h1 id=\"generate\">Generate \u6587\u672c\u751f\u6210\u4e3b\u811a\u672c\u5206\u6790</h1>\n<h2 id=\"_1\">\u6587\u4ef6\u4f4d\u7f6e</h2>\n<p><code>/Users/georgezhou/Downloads/gpt-oss/gpt_oss/generate.py</code></p>\n<h2 id=\"_2\">\u6982\u8ff0</h2>\n<p>\u8fd9\u662f GPT-OSS \u9879\u76ee\u7684\u4e3b\u8981\u6587\u672c\u751f\u6210\u811a\u672c\uff0c\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u547d\u4ee4\u884c\u63a5\u53e3\u6765\u4f7f\u7528\u4e0d\u540c\u7684\u63a8\u7406\u540e\u7aef\uff08Torch\u3001Triton\u3001VLLM\uff09\u8fdb\u884c\u6587\u672c\u751f\u6210\u3002\u5b83\u652f\u6301\u591a GPU \u5e76\u884c\u63a8\u7406\u3001\u6e29\u5ea6\u63a7\u5236\u3001\u8f93\u51fa\u9650\u5236\u548c\u8be6\u7ec6\u7684\u65e5\u5fd7\u8f93\u51fa\u3002</p>\n<h2 id=\"_3\">\u811a\u672c\u5934\u90e8\u4fe1\u606f</h2>\n<p><strong>\u4f4d\u7f6e</strong>: \u7b2c 1-4 \u884c</p>\n<pre class=\"codehilite\"><code class=\"language-python\"># Model parallel inference\n# Note: This script is for demonstration purposes only. It is not designed for production use.\n#       See gpt_oss.chat for a more complete example with the Harmony parser.\n# torchrun --nproc-per-node=4 -m gpt_oss.generate -p &quot;why did the chicken cross the road?&quot; model/\n</code></pre>\n\n<h3 id=\"_4\">\u91cd\u8981\u8bf4\u660e:</h3>\n<ul>\n<li><strong>\u6f14\u793a\u7528\u9014</strong>: \u4e3b\u8981\u7528\u4e8e\u6f14\u793a\u548c\u6d4b\u8bd5\uff0c\u4e0d\u9002\u5408\u751f\u4ea7\u73af\u5883</li>\n<li><strong>\u751f\u4ea7\u63a8\u8350</strong>: \u63a8\u8350\u4f7f\u7528 <code>gpt_oss.chat</code> \u83b7\u5f97\u5b8c\u6574\u529f\u80fd</li>\n<li><strong>\u5e76\u884c\u6267\u884c</strong>: \u652f\u6301\u901a\u8fc7 <code>torchrun</code> \u8fdb\u884c\u591a GPU \u5e76\u884c\u63a8\u7406</li>\n</ul>\n<h2 id=\"_5\">\u6838\u5fc3\u5bfc\u5165</h2>\n<p><strong>\u4f4d\u7f6e</strong>: \u7b2c 6-8 \u884c</p>\n<pre class=\"codehilite\"><code class=\"language-python\">import argparse\nfrom gpt_oss.tokenizer import get_tokenizer\n</code></pre>\n\n<h2 id=\"_6\">\u4e3b\u51fd\u6570\u5206\u6790</h2>\n<h3 id=\"mainargs\"><code>main(args)</code> \u4e3b\u5904\u7406\u51fd\u6570</h3>\n<p><strong>\u4f4d\u7f6e</strong>: \u7b2c 11-38 \u884c\n<strong>\u529f\u80fd</strong>: \u6839\u636e\u547d\u4ee4\u884c\u53c2\u6570\u9009\u62e9\u540e\u7aef\u5e76\u6267\u884c\u6587\u672c\u751f\u6210</p>\n<h4 id=\"_7\">\u540e\u7aef\u9009\u62e9\u903b\u8f91</h4>\n<p><strong>\u4f4d\u7f6e</strong>: \u7b2c 12-27 \u884c</p>\n<pre class=\"codehilite\"><code class=\"language-python\">match args.backend:\n    case &quot;torch&quot;:\n        from gpt_oss.torch.utils import init_distributed\n        from gpt_oss.torch.model import TokenGenerator as TorchGenerator\n        device = init_distributed()\n        generator = TorchGenerator(args.checkpoint, device=device)\n    case &quot;triton&quot;:\n        from gpt_oss.torch.utils import init_distributed\n        from gpt_oss.triton.model import TokenGenerator as TritonGenerator\n        device = init_distributed()\n        generator = TritonGenerator(args.checkpoint, context=4096, device=device)\n    case &quot;vllm&quot;:\n        from gpt_oss.vllm.token_generator import TokenGenerator as VLLMGenerator\n        generator = VLLMGenerator(args.checkpoint, tensor_parallel_size=2)\n    case _:\n        raise ValueError(f&quot;Invalid backend: {args.backend}&quot;)\n</code></pre>\n\n<h4 id=\"_8\">\u5404\u540e\u7aef\u7279\u70b9:</h4>\n<h5 id=\"1-torch\">1. <strong>Torch \u540e\u7aef</strong></h5>\n<ul>\n<li><strong>\u5206\u5e03\u5f0f\u521d\u59cb\u5316</strong>: \u901a\u8fc7 <code>init_distributed()</code> \u8bbe\u7f6e\u591a GPU \u73af\u5883</li>\n<li><strong>\u8bbe\u5907\u7ba1\u7406</strong>: \u81ea\u52a8\u5206\u914d\u548c\u7ba1\u7406\u8ba1\u7b97\u8bbe\u5907</li>\n<li><strong>\u901a\u7528\u6027</strong>: \u6807\u51c6 PyTorch \u5b9e\u73b0\uff0c\u517c\u5bb9\u6027\u6700\u597d</li>\n</ul>\n<h5 id=\"2-triton\">2. <strong>Triton \u540e\u7aef</strong></h5>\n<ul>\n<li><strong>\u5206\u5e03\u5f0f\u652f\u6301</strong>: \u540c\u6837\u652f\u6301\u591a GPU \u5206\u5e03\u5f0f\u8ba1\u7b97</li>\n<li><strong>\u4e0a\u4e0b\u6587\u957f\u5ea6</strong>: \u56fa\u5b9a 4096 \u7684\u4e0a\u4e0b\u6587\u7a97\u53e3</li>\n<li><strong>\u6027\u80fd\u4f18\u5316</strong>: \u4f7f\u7528 Triton \u5185\u6838\u63d0\u4f9b\u66f4\u597d\u7684\u6027\u80fd</li>\n</ul>\n<h5 id=\"3-vllm\">3. <strong>VLLM \u540e\u7aef</strong></h5>\n<ul>\n<li><strong>\u5f20\u91cf\u5e76\u884c</strong>: \u56fa\u5b9a\u4f7f\u7528 2-way \u5f20\u91cf\u5e76\u884c</li>\n<li><strong>\u4e13\u4e1a\u63a8\u7406</strong>: \u4e13\u95e8\u4e3a\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u4f18\u5316</li>\n<li><strong>\u9ad8\u541e\u5410\u91cf</strong>: \u9002\u5408\u9ad8\u5e76\u53d1\u63a8\u7406\u573a\u666f</li>\n</ul>\n<h4 id=\"_9\">\u6587\u672c\u751f\u6210\u6267\u884c</h4>\n<p><strong>\u4f4d\u7f6e</strong>: \u7b2c 29-37 \u884c</p>\n<pre class=\"codehilite\"><code class=\"language-python\">tokenizer = get_tokenizer()\ntokens = tokenizer.encode(args.prompt)\nmax_tokens = None if args.limit == 0 else args.limit\n\nfor token, logprob in generator.generate(\n    tokens, \n    stop_tokens=[tokenizer.eot_token], \n    temperature=args.temperature, \n    max_tokens=max_tokens, \n    return_logprobs=True\n):\n    tokens.append(token)\n    decoded_token = tokenizer.decode([token])\n    print(f&quot;Generated token: {repr(decoded_token)}, logprob: {logprob}&quot;)\n</code></pre>\n\n<h4 id=\"_10\">\u751f\u6210\u6d41\u7a0b\u8be6\u89e3:</h4>\n<ol>\n<li><strong>\u5206\u8bcd\u5668\u521d\u59cb\u5316</strong>: \u4f7f\u7528\u9879\u76ee\u81ea\u5b9a\u4e49\u7684 o200k_harmony \u7f16\u7801</li>\n<li><strong>\u63d0\u793a\u8bcd\u7f16\u7801</strong>: \u5c06\u8f93\u5165\u6587\u672c\u8f6c\u6362\u4e3a\u4ee4\u724c\u5e8f\u5217</li>\n<li><strong>\u53c2\u6570\u8bbe\u7f6e</strong>: \u914d\u7f6e\u6700\u5927\u4ee4\u724c\u6570\u9650\u5236</li>\n<li><strong>\u6d41\u5f0f\u751f\u6210</strong>: \u9010\u4ee4\u724c\u751f\u6210\u5e76\u5b9e\u65f6\u8f93\u51fa</li>\n<li><strong>\u8be6\u7ec6\u65e5\u5fd7</strong>: \u663e\u793a\u6bcf\u4e2a\u751f\u6210\u4ee4\u724c\u548c\u5176\u5bf9\u6570\u6982\u7387</li>\n</ol>\n<h2 id=\"_11\">\u547d\u4ee4\u884c\u53c2\u6570\u7cfb\u7edf</h2>\n<h3 id=\"_12\">\u53c2\u6570\u89e3\u6790\u5668\u8bbe\u7f6e</h3>\n<p><strong>\u4f4d\u7f6e</strong>: \u7b2c 40-81 \u884c</p>\n<pre class=\"codehilite\"><code class=\"language-python\">if __name__ == &quot;__main__&quot;:\n    parser = argparse.ArgumentParser(description=&quot;Text generation example&quot;)\n</code></pre>\n\n<h3 id=\"_13\">\u6838\u5fc3\u53c2\u6570\u5b9a\u4e49</h3>\n<h4 id=\"1-checkpoint\">1. <strong>checkpoint</strong> (\u5fc5\u9700\u53c2\u6570)</h4>\n<p><strong>\u4f4d\u7f6e</strong>: \u7b2c 42-47 \u884c</p>\n<pre class=\"codehilite\"><code class=\"language-python\">parser.add_argument(\n    &quot;checkpoint&quot;,\n    metavar=&quot;FILE&quot;,\n    type=str,\n    help=&quot;Path to the SafeTensors checkpoint&quot;,\n)\n</code></pre>\n\n<ul>\n<li><strong>\u7c7b\u578b</strong>: \u4f4d\u7f6e\u53c2\u6570\uff0c\u5fc5\u987b\u63d0\u4f9b</li>\n<li><strong>\u4f5c\u7528</strong>: \u6307\u5b9a\u6a21\u578b\u68c0\u67e5\u70b9\u6587\u4ef6\u8def\u5f84</li>\n<li><strong>\u683c\u5f0f</strong>: \u652f\u6301 SafeTensors \u683c\u5f0f</li>\n</ul>\n<h4 id=\"2-prompt-p\">2. <strong>--prompt/-p</strong> (\u63d0\u793a\u8bcd)</h4>\n<p><strong>\u4f4d\u7f6e</strong>: \u7b2c 48-55 \u884c</p>\n<pre class=\"codehilite\"><code class=\"language-python\">parser.add_argument(\n    &quot;-p&quot;,\n    &quot;--prompt&quot;,\n    metavar=&quot;PROMPT&quot;,\n    type=str,\n    default=&quot;How are you?&quot;,\n    help=&quot;LLM prompt&quot;,\n)\n</code></pre>\n\n<ul>\n<li><strong>\u9ed8\u8ba4\u503c</strong>: \"How are you?\"</li>\n<li><strong>\u4f5c\u7528</strong>: \u6307\u5b9a\u8f93\u5165\u7684\u63d0\u793a\u8bcd\u6587\u672c</li>\n</ul>\n<h4 id=\"3-temperature-t\">3. <strong>--temperature/-t</strong> (\u91c7\u6837\u6e29\u5ea6)</h4>\n<p><strong>\u4f4d\u7f6e</strong>: \u7b2c 56-63 \u884c</p>\n<pre class=\"codehilite\"><code class=\"language-python\">parser.add_argument(\n    &quot;-t&quot;,\n    &quot;--temperature&quot;,\n    metavar=&quot;TEMP&quot;,\n    type=float,\n    default=0.0,\n    help=&quot;Sampling temperature&quot;,\n)\n</code></pre>\n\n<ul>\n<li><strong>\u9ed8\u8ba4\u503c</strong>: 0.0 (\u786e\u5b9a\u6027\u8f93\u51fa)</li>\n<li><strong>\u8303\u56f4</strong>: \u901a\u5e38 0.0-2.0</li>\n<li><strong>\u6548\u679c</strong>: \u63a7\u5236\u8f93\u51fa\u7684\u968f\u673a\u6027</li>\n</ul>\n<h4 id=\"4-limit-l\">4. <strong>--limit/-l</strong> (\u4ee4\u724c\u9650\u5236)</h4>\n<p><strong>\u4f4d\u7f6e</strong>: \u7b2c 64-71 \u884c</p>\n<pre class=\"codehilite\"><code class=\"language-python\">parser.add_argument(\n    &quot;-l&quot;,\n    &quot;--limit&quot;,\n    metavar=&quot;LIMIT&quot;,\n    type=int,\n    default=0,\n    help=&quot;Limit on the number of tokens (0 to disable)&quot;,\n)\n</code></pre>\n\n<ul>\n<li><strong>\u9ed8\u8ba4\u503c</strong>: 0 (\u65e0\u9650\u5236)</li>\n<li><strong>\u4f5c\u7528</strong>: \u9650\u5236\u751f\u6210\u7684\u6700\u5927\u4ee4\u724c\u6570</li>\n</ul>\n<h4 id=\"5-backend-b\">5. <strong>--backend/-b</strong> (\u63a8\u7406\u540e\u7aef)</h4>\n<p><strong>\u4f4d\u7f6e</strong>: \u7b2c 72-80 \u884c</p>\n<pre class=\"codehilite\"><code class=\"language-python\">parser.add_argument(\n    &quot;-b&quot;,\n    &quot;--backend&quot;,\n    metavar=&quot;BACKEND&quot;,\n    type=str,\n    default=&quot;torch&quot;,\n    choices=[&quot;triton&quot;, &quot;torch&quot;, &quot;vllm&quot;],\n    help=&quot;Inference backend&quot;,\n)\n</code></pre>\n\n<ul>\n<li><strong>\u9ed8\u8ba4\u503c</strong>: \"torch\"</li>\n<li><strong>\u9009\u9879</strong>: triton, torch, vllm</li>\n<li><strong>\u4f5c\u7528</strong>: \u9009\u62e9\u63a8\u7406\u8ba1\u7b97\u540e\u7aef</li>\n</ul>\n<h2 id=\"_14\">\u4f7f\u7528\u793a\u4f8b</h2>\n<h3 id=\"_15\">\u57fa\u672c\u4f7f\u7528</h3>\n<pre class=\"codehilite\"><code class=\"language-bash\"># \u4f7f\u7528\u9ed8\u8ba4\u53c2\u6570\npython -m gpt_oss.generate path/to/model/\n\n# \u6307\u5b9a\u63d0\u793a\u8bcd\npython -m gpt_oss.generate -p &quot;Tell me a story&quot; path/to/model/\n\n# \u4f7f\u7528 Triton \u540e\u7aef\npython -m gpt_oss.generate -b triton -p &quot;Hello world&quot; path/to/model/\n\n# \u9650\u5236\u8f93\u51fa\u957f\u5ea6\npython -m gpt_oss.generate -p &quot;Explain AI&quot; -l 100 path/to/model/\n\n# \u63d0\u9ad8\u968f\u673a\u6027\npython -m gpt_oss.generate -t 0.7 -p &quot;Creative writing&quot; path/to/model/\n</code></pre>\n\n<h3 id=\"_16\">\u5206\u5e03\u5f0f\u8fd0\u884c</h3>\n<pre class=\"codehilite\"><code class=\"language-bash\"># 4 GPU \u5e76\u884c\u63a8\u7406\ntorchrun --nproc-per-node=4 -m gpt_oss.generate -p &quot;Complex question&quot; path/to/model/\n\n# 8 GPU \u9ad8\u6027\u80fd\u63a8\u7406  \ntorchrun --nproc-per-node=8 -b triton -p &quot;Long document generation&quot; path/to/model/\n</code></pre>\n\n<h2 id=\"_17\">\u8f93\u51fa\u683c\u5f0f\u5206\u6790</h2>\n<h3 id=\"_18\">\u8be6\u7ec6\u4ee4\u724c\u8f93\u51fa</h3>\n<pre class=\"codehilite\"><code>Generated token: ' Hello', logprob: -0.0234\nGenerated token: ' there', logprob: -0.1456  \nGenerated token: '!', logprob: -0.0789\nGenerated token: ' How', logprob: -0.2345\n</code></pre>\n\n<h4 id=\"_19\">\u8f93\u51fa\u4fe1\u606f\u5305\u542b:</h4>\n<ul>\n<li><strong>\u4ee4\u724c\u5185\u5bb9</strong>: \u5b9e\u9645\u751f\u6210\u7684\u6587\u672c\u7247\u6bb5</li>\n<li><strong>\u8868\u793a\u683c\u5f0f</strong>: \u4f7f\u7528 <code>repr()</code> \u663e\u793a\uff0c\u5305\u542b\u7a7a\u683c\u548c\u7279\u6b8a\u5b57\u7b26</li>\n<li><strong>\u5bf9\u6570\u6982\u7387</strong>: \u6a21\u578b\u5bf9\u8be5\u4ee4\u724c\u7684\u7f6e\u4fe1\u5ea6</li>\n</ul>\n<h2 id=\"_20\">\u6280\u672f\u7279\u6027</h2>\n<h3 id=\"_21\">\u6d41\u5f0f\u5904\u7406</h3>\n<ul>\n<li><strong>\u5b9e\u65f6\u8f93\u51fa</strong>: \u6bcf\u751f\u6210\u4e00\u4e2a\u4ee4\u724c\u7acb\u5373\u663e\u793a</li>\n<li><strong>\u4ea4\u4e92\u4f53\u9a8c</strong>: \u7528\u6237\u53ef\u4ee5\u5b9e\u65f6\u89c2\u5bdf\u751f\u6210\u8fc7\u7a0b</li>\n<li><strong>\u8c03\u8bd5\u53cb\u597d</strong>: \u4fbf\u4e8e\u5206\u6790\u6a21\u578b\u884c\u4e3a</li>\n</ul>\n<h3 id=\"_22\">\u591a\u540e\u7aef\u652f\u6301</h3>\n<ul>\n<li><strong>\u7edf\u4e00\u63a5\u53e3</strong>: \u4e0d\u540c\u540e\u7aef\u4f7f\u7528\u76f8\u540c\u7684\u8c03\u7528\u65b9\u5f0f</li>\n<li><strong>\u6027\u80fd\u5bf9\u6bd4</strong>: \u53ef\u4ee5\u8f7b\u677e\u6bd4\u8f83\u4e0d\u540c\u540e\u7aef\u7684\u6027\u80fd</li>\n<li><strong>\u7075\u6d3b\u90e8\u7f72</strong>: \u6839\u636e\u786c\u4ef6\u73af\u5883\u9009\u62e9\u6700\u9002\u5408\u7684\u540e\u7aef</li>\n</ul>\n<h3 id=\"_23\">\u53ef\u914d\u7f6e\u6027</h3>\n<ul>\n<li><strong>\u4e30\u5bcc\u53c2\u6570</strong>: \u652f\u6301\u6e29\u5ea6\u3001\u957f\u5ea6\u7b49\u591a\u79cd\u63a7\u5236\u53c2\u6570</li>\n<li><strong>\u547d\u4ee4\u884c\u53cb\u597d</strong>: \u6807\u51c6\u7684 Unix \u98ce\u683c\u547d\u4ee4\u884c\u63a5\u53e3</li>\n<li><strong>\u5e2e\u52a9\u7cfb\u7edf</strong>: \u5b8c\u6574\u7684\u53c2\u6570\u8bf4\u660e\u548c\u5e2e\u52a9\u4fe1\u606f</li>\n</ul>\n<h2 id=\"_24\">\u4e0e\u5176\u4ed6\u6a21\u5757\u7684\u5173\u7cfb</h2>\n<h3 id=\"_25\">\u6838\u5fc3\u4f9d\u8d56</h3>\n<ul>\n<li><code>gpt_oss.tokenizer</code>: \u5206\u8bcd\u548c\u7f16\u89e3\u7801</li>\n<li><code>gpt_oss.torch.utils</code>: \u5206\u5e03\u5f0f\u8ba1\u7b97\u5de5\u5177</li>\n<li><code>gpt_oss.torch.model</code>: Torch \u540e\u7aef\u5b9e\u73b0</li>\n<li><code>gpt_oss.triton.model</code>: Triton \u540e\u7aef\u5b9e\u73b0  </li>\n<li><code>gpt_oss.vllm.token_generator</code>: VLLM \u540e\u7aef\u5b9e\u73b0</li>\n</ul>\n<h3 id=\"_26\">\u8bbe\u8ba1\u5b9a\u4f4d</h3>\n<ul>\n<li><strong>\u6f14\u793a\u5de5\u5177</strong>: \u4e3b\u8981\u7528\u4e8e\u5c55\u793a\u7cfb\u7edf\u80fd\u529b</li>\n<li><strong>\u6d4b\u8bd5\u5e73\u53f0</strong>: \u7528\u4e8e\u9a8c\u8bc1\u4e0d\u540c\u540e\u7aef\u7684\u529f\u80fd</li>\n<li><strong>\u6027\u80fd\u57fa\u51c6</strong>: \u53ef\u7528\u4e8e\u57fa\u672c\u7684\u6027\u80fd\u6d4b\u8bd5</li>\n</ul>\n<h2 id=\"_27\">\u5c40\u9650\u6027\u548c\u6539\u8fdb\u65b9\u5411</h2>\n<h3 id=\"_28\">\u5f53\u524d\u5c40\u9650</h3>\n<ol>\n<li><strong>\u751f\u4ea7\u5c31\u7eea\u6027</strong>: \u58f0\u660e\u4ec5\u7528\u4e8e\u6f14\u793a\uff0c\u4e0d\u9002\u5408\u751f\u4ea7</li>\n<li><strong>\u529f\u80fd\u5b8c\u6574\u6027</strong>: \u7f3a\u5c11\u5bf9\u8bdd\u5386\u53f2\u3001\u5de5\u5177\u8c03\u7528\u7b49\u9ad8\u7ea7\u529f\u80fd</li>\n<li><strong>\u9519\u8bef\u5904\u7406</strong>: \u9519\u8bef\u5904\u7406\u76f8\u5bf9\u7b80\u5355</li>\n</ol>\n<h3 id=\"_29\">\u63a8\u8350\u66ff\u4ee3</h3>\n<ul>\n<li><strong>\u751f\u4ea7\u4f7f\u7528</strong>: \u63a8\u8350\u4f7f\u7528 <code>gpt_oss.chat</code> </li>\n<li><strong>\u5b8c\u6574\u529f\u80fd</strong>: chat \u6a21\u5757\u5305\u542b Harmony \u89e3\u6790\u5668\u7b49\u9ad8\u7ea7\u529f\u80fd</li>\n<li><strong>API \u670d\u52a1</strong>: \u901a\u8fc7 <code>responses_api</code> \u63d0\u4f9b\u5b8c\u6574\u7684 API \u670d\u52a1</li>\n</ul>\n<h2 id=\"_30\">\u6267\u884c\u5165\u53e3</h2>\n<p><strong>\u4f4d\u7f6e</strong>: \u7b2c 81-83 \u884c</p>\n<pre class=\"codehilite\"><code class=\"language-python\">args = parser.parse_args()\nmain(args)\n</code></pre>\n\n<h2 id=\"_31\">\u603b\u7ed3</h2>\n<p>\u8fd9\u4e2a\u811a\u672c\u867d\u7136\u76f8\u5bf9\u7b80\u5355\uff0c\u4f46\u5b83\u5c55\u73b0\u4e86 GPT-OSS \u9879\u76ee\u7684\u51e0\u4e2a\u91cd\u8981\u7279\u6027\uff1a</p>\n<ol>\n<li><strong>\u6a21\u5757\u5316\u67b6\u6784</strong>: \u6e05\u6670\u7684\u540e\u7aef\u62bd\u8c61\u548c\u7edf\u4e00\u63a5\u53e3</li>\n<li><strong>\u591a\u540e\u7aef\u652f\u6301</strong>: Torch\u3001Triton\u3001VLLM \u7684\u65e0\u7f1d\u5207\u6362</li>\n<li><strong>\u5206\u5e03\u5f0f\u5c31\u7eea</strong>: \u5929\u7136\u652f\u6301\u591a GPU \u5e76\u884c\u63a8\u7406</li>\n<li><strong>\u7528\u6237\u53cb\u597d</strong>: \u7b80\u6d01\u7684\u547d\u4ee4\u884c\u63a5\u53e3\u548c\u5b9e\u65f6\u8f93\u51fa</li>\n<li><strong>\u8c03\u8bd5\u652f\u6301</strong>: \u8be6\u7ec6\u7684\u4ee4\u724c\u7ea7\u8f93\u51fa\u548c\u6982\u7387\u4fe1\u606f</li>\n</ol>\n<p>\u5b83\u4e3a\u5f00\u53d1\u8005\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5feb\u901f\u6d4b\u8bd5\u548c\u9a8c\u8bc1\u6a21\u578b\u529f\u80fd\u7684\u4fbf\u5229\u5de5\u5177\uff0c\u540c\u65f6\u4e5f\u5c55\u793a\u4e86\u9879\u76ee\u7684\u6838\u5fc3\u6280\u672f\u80fd\u529b\u3002</p>"
  },
  "../06_responses_api_server.md": {
    "hash": "2724fb7e19684d15ea08aa8314a6d752",
    "content": "<h1 id=\"responses-api-server-api\">Responses API Server \u54cd\u5e94\u5f0fAPI\u670d\u52a1\u5668\u5206\u6790</h1>\n<h2 id=\"_1\">\u6587\u4ef6\u4f4d\u7f6e</h2>\n<p><code>/Users/georgezhou/Downloads/gpt-oss/gpt_oss/responses_api/api_server.py</code></p>\n<h2 id=\"_2\">\u6982\u8ff0</h2>\n<p>\u8fd9\u662f\u4e00\u4e2a\u57fa\u4e8e FastAPI \u7684\u5f02\u6b65\u54cd\u5e94\u5f0f API \u670d\u52a1\u5668\uff0c\u5b9e\u73b0\u4e86\u7c7b\u4f3c OpenAI \u7684\u5bf9\u8bdd API\u3002\u652f\u6301\u6d41\u5f0f\u54cd\u5e94\u3001\u51fd\u6570\u8c03\u7528\u3001\u5de5\u5177\u4f7f\u7528\u3001\u63a8\u7406\u6a21\u5f0f\u548c\u7f51\u7edc\u641c\u7d22\u529f\u80fd\u3002\u91c7\u7528\u4e8b\u4ef6\u9a71\u52a8\u67b6\u6784\uff0c\u63d0\u4f9b\u5b9e\u65f6\u7684\u751f\u6210\u72b6\u6001\u53cd\u9988\u3002</p>\n<h2 id=\"_3\">\u6838\u5fc3\u5e38\u91cf\u548c\u5de5\u5177\u51fd\u6570</h2>\n<h3 id=\"_4\">\u914d\u7f6e\u5e38\u91cf</h3>\n<p><strong>\u4f4d\u7f6e</strong>: \u7b2c 61 \u884c</p>\n<pre class=\"codehilite\"><code class=\"language-python\">DEFAULT_TEMPERATURE = 0.0\n</code></pre>\n\n<h3 id=\"_5\">\u5de5\u5177\u51fd\u6570</h3>\n<p><strong>\u4f4d\u7f6e</strong>: \u7b2c 64-74 \u884c</p>\n<pre class=\"codehilite\"><code class=\"language-python\">def get_reasoning_effort(effort: Literal[&quot;low&quot;, &quot;medium&quot;, &quot;high&quot;]) -&gt; ReasoningEffort\ndef is_not_builtin_tool(recipient: str) -&gt; bool\n</code></pre>\n\n<h2 id=\"_6\">\u4e3b\u8981\u529f\u80fd\u6a21\u5757</h2>\n<h3 id=\"api\">API\u670d\u52a1\u5668\u5de5\u5382\u51fd\u6570</h3>\n<p><strong>\u4f4d\u7f6e</strong>: \u7b2c 76-915 \u884c</p>\n<pre class=\"codehilite\"><code class=\"language-python\">def create_api_server(\n    infer_next_token: Callable[[list[int], float], int], \n    encoding: HarmonyEncoding\n) -&gt; FastAPI\n</code></pre>\n\n<h4 id=\"_7\">\u53c2\u6570\u8bf4\u660e:</h4>\n<ul>\n<li><code>infer_next_token</code>: \u6a21\u578b\u63a8\u7406\u51fd\u6570\uff0c\u7ed9\u5b9a\u4ee4\u724c\u5e8f\u5217\u548c\u6e29\u5ea6\u8fd4\u56de\u4e0b\u4e00\u4e2a\u4ee4\u724c</li>\n<li><code>encoding</code>: Harmony \u7f16\u7801\u5668\uff0c\u7528\u4e8e\u4ee4\u724c\u7f16\u89e3\u7801\u548c\u6d88\u606f\u89e3\u6790</li>\n</ul>\n<h2 id=\"_8\">\u6838\u5fc3\u7c7b\u548c\u65b9\u6cd5</h2>\n<h3 id=\"generate_response\">\u54cd\u5e94\u751f\u6210\u51fd\u6570 <code>generate_response</code></h3>\n<p><strong>\u4f4d\u7f6e</strong>: \u7b2c 82-280 \u884c\n<strong>\u529f\u80fd</strong>: \u5c06\u6a21\u578b\u8f93\u51fa\u4ee4\u724c\u8f6c\u6362\u4e3a\u7ed3\u6784\u5316\u54cd\u5e94\u5bf9\u8c61</p>\n<h4 id=\"_9\">\u5173\u952e\u5904\u7406\u6d41\u7a0b:</h4>\n<ol>\n<li><strong>\u4ee4\u724c\u89e3\u6790</strong> (\u7b2c 95-111 \u884c):</li>\n</ol>\n<pre class=\"codehilite\"><code class=\"language-python\">entries = encoding.parse_messages_from_completion_tokens(\n    output_tokens, Role.ASSISTANT\n)\n</code></pre>\n\n<ol start=\"2\">\n<li>\n<p><strong>\u6d88\u606f\u7c7b\u578b\u5904\u7406</strong>:\n   - <strong>\u51fd\u6570\u8c03\u7528</strong> (\u7b2c 117-140 \u884c): \u5904\u7406 <code>functions.</code> \u524d\u7f00\u7684\u8c03\u7528\n   - <strong>\u6d4f\u89c8\u5668\u5de5\u5177</strong> (\u7b2c 141-190 \u884c): \u5904\u7406 <code>browser.</code> \u524d\u7f00\u7684\u641c\u7d22\u8c03\u7528<br />\n   - <strong>\u6700\u7ec8\u8f93\u51fa</strong> (\u7b2c 191-216 \u884c): \u5904\u7406 <code>final</code> \u901a\u9053\u7684\u7528\u6237\u53ef\u89c1\u5185\u5bb9\n   - <strong>\u63a8\u7406\u5185\u5bb9</strong> (\u7b2c 217-232 \u884c): \u5904\u7406 <code>analysis</code> \u901a\u9053\u7684\u601d\u8003\u8fc7\u7a0b</p>\n</li>\n<li>\n<p><strong>\u5f15\u7528\u5904\u7406</strong> (\u7b2c 194-199 \u884c):</p>\n</li>\n</ol>\n<pre class=\"codehilite\"><code class=\"language-python\">if browser_tool:\n    text_content, annotation_entries, _has_partial_citations = browser_tool.normalize_citations(content_entry[&quot;text&quot;])\n    annotations = [UrlCitation(**a) for a in annotation_entries]\n</code></pre>\n\n<h3 id=\"streamresponsesevents\">\u6d41\u5f0f\u54cd\u5e94\u4e8b\u4ef6\u5904\u7406\u5668 <code>StreamResponsesEvents</code></h3>\n<p><strong>\u4f4d\u7f6e</strong>: \u7b2c 282-739 \u884c\n<strong>\u529f\u80fd</strong>: \u5904\u7406\u5b9e\u65f6\u6d41\u5f0f\u54cd\u5e94\uff0c\u751f\u6210\u5404\u79cd\u4e8b\u4ef6\u7c7b\u578b</p>\n<h4 id=\"_10\">\u6838\u5fc3\u5c5e\u6027:</h4>\n<pre class=\"codehilite\"><code class=\"language-python\">class StreamResponsesEvents:\n    initial_tokens: list[int]      # \u521d\u59cb\u4ee4\u724c\u5e8f\u5217\n    tokens: list[int]              # \u5f53\u524d\u4ee4\u724c\u5e8f\u5217  \n    output_tokens: list[int]       # \u8f93\u51fa\u4ee4\u724c\n    output_text: str               # \u8f93\u51fa\u6587\u672c\n    request_body: ResponsesRequest # \u8bf7\u6c42\u4f53\n    sequence_number: int           # \u4e8b\u4ef6\u5e8f\u5217\u53f7\n</code></pre>\n\n<h4 id=\"_11\">\u5173\u952e\u65b9\u6cd5:</h4>\n<h5 id=\"__init__\"><code>__init__</code> \u521d\u59cb\u5316</h5>\n<p><strong>\u4f4d\u7f6e</strong>: \u7b2c 292-328 \u884c</p>\n<ul>\n<li>\u8bbe\u7f6e\u6d41\u5f0f\u89e3\u6790\u5668</li>\n<li>\u914d\u7f6e\u6e29\u5ea6\u53c2\u6570</li>\n<li>\u521d\u59cb\u5316\u6d4f\u89c8\u5668\u5de5\u5177</li>\n</ul>\n<h5 id=\"_send_event\"><code>_send_event</code> \u4e8b\u4ef6\u53d1\u9001</h5>\n<p><strong>\u4f4d\u7f6e</strong>: \u7b2c 330-336 \u884c</p>\n<pre class=\"codehilite\"><code class=\"language-python\">def _send_event(self, event: ResponseEvent):\n    event.sequence_number = self.sequence_number\n    self.sequence_number += 1\n    # SSE \u683c\u5f0f\u6216\u5bf9\u8c61\u683c\u5f0f\n</code></pre>\n\n<h5 id=\"run\"><code>run</code> \u4e3b\u5904\u7406\u5faa\u73af</h5>\n<p><strong>\u4f4d\u7f6e</strong>: \u7b2c 338-739 \u884c\n<strong>\u529f\u80fd</strong>: \u6267\u884c\u4ee4\u724c\u751f\u6210\u548c\u4e8b\u4ef6\u6d41\u5904\u7406</p>\n<h6 id=\"_12\">\u6838\u5fc3\u5904\u7406\u6d41\u7a0b:</h6>\n<ol>\n<li><strong>\u521d\u59cb\u5316\u54cd\u5e94</strong> (\u7b2c 341-361 \u884c):</li>\n</ol>\n<pre class=\"codehilite\"><code class=\"language-python\">yield self._send_event(ResponseCreatedEvent(...))\nyield self._send_event(ResponseInProgressEvent(...))\n</code></pre>\n\n<ol start=\"2\">\n<li><strong>\u4ee4\u724c\u751f\u6210\u5faa\u73af</strong> (\u7b2c 375-715 \u884c):</li>\n</ol>\n<pre class=\"codehilite\"><code class=\"language-python\">while True:\n    next_tok = infer_next_token(self.tokens, temperature=self.temperature)\n    self.tokens.append(next_tok)\n    self.parser.process(next_tok)\n</code></pre>\n\n<ol start=\"3\">\n<li>\n<p><strong>\u5b9e\u65f6\u4e8b\u4ef6\u5904\u7406</strong>:\n   - <strong>\u5185\u5bb9\u589e\u91cf</strong> (\u7b2c 506-568 \u884c): \u5904\u7406\u6587\u672c\u589e\u91cf\u66f4\u65b0\n   - <strong>\u63a8\u7406\u5185\u5bb9</strong> (\u7b2c 570-601 \u884c): \u5904\u7406\u601d\u8003\u8fc7\u7a0b\n   - <strong>\u5de5\u5177\u8c03\u7528</strong> (\u7b2c 612-708 \u884c): \u5904\u7406\u6d4f\u89c8\u5668\u5de5\u5177\u8c03\u7528</p>\n</li>\n<li>\n<p><strong>\u6d4f\u89c8\u5668\u5de5\u5177\u5904\u7406</strong> (\u7b2c 616-703 \u884c):</p>\n</li>\n</ol>\n<pre class=\"codehilite\"><code class=\"language-python\">if self.use_browser_tool and last_message.recipient.startswith(&quot;browser.&quot;):\n    # \u89e3\u6790\u5de5\u5177\u53c2\u6570\n    parsed_args = browser_tool.process_arguments(last_message)\n    # \u6267\u884c\u5de5\u5177\u8c03\u7528\n    result = await run_tool()\n    # \u5904\u7406\u8fd4\u56de\u7ed3\u679c\n</code></pre>\n\n<ol start=\"5\">\n<li><strong>\u5f15\u7528\u5904\u7406</strong> (\u7b2c 531-556 \u884c):</li>\n</ol>\n<pre class=\"codehilite\"><code class=\"language-python\">if browser_tool:\n    updated_output_text, annotations, has_partial_citations = browser_tool.normalize_citations(...)\n    # \u53d1\u9001\u65b0\u7684\u5f15\u7528\u6ce8\u91ca\n</code></pre>\n\n<h3 id=\"api_1\">\u4e3b\u8981API\u7aef\u70b9</h3>\n<h4 id=\"post-v1responses\">POST <code>/v1/responses</code></h4>\n<p><strong>\u4f4d\u7f6e</strong>: \u7b2c 741-913 \u884c\n<strong>\u529f\u80fd</strong>: \u5904\u7406\u5bf9\u8bdd\u8bf7\u6c42\uff0c\u652f\u6301\u6d41\u5f0f\u548c\u975e\u6d41\u5f0f\u54cd\u5e94</p>\n<h5 id=\"_13\">\u6838\u5fc3\u5904\u7406\u6b65\u9aa4:</h5>\n<ol>\n<li><strong>\u5de5\u5177\u521d\u59cb\u5316</strong> (\u7b2c 745-756 \u884c):</li>\n</ol>\n<pre class=\"codehilite\"><code class=\"language-python\">use_browser_tool = any(\n    getattr(tool, &quot;type&quot;, None) == &quot;browser_search&quot;\n    for tool in (body.tools or [])\n)\n</code></pre>\n\n<ol start=\"2\">\n<li>\n<p><strong>\u5386\u53f2\u5bf9\u8bdd\u5408\u5e76</strong> (\u7b2c 758-779 \u884c):\n   \u5904\u7406 <code>previous_response_id</code> \u6765\u5ef6\u7eed\u5bf9\u8bdd</p>\n</li>\n<li>\n<p><strong>\u7cfb\u7edf\u6d88\u606f\u6784\u5efa</strong> (\u7b2c 782-795 \u884c):</p>\n</li>\n</ol>\n<pre class=\"codehilite\"><code class=\"language-python\">system_message_content = SystemContent.new().with_conversation_start_date(...)\nif body.reasoning is not None:\n    reasoning_effort = get_reasoning_effort(body.reasoning.effort)\n</code></pre>\n\n<ol start=\"4\">\n<li>\n<p><strong>\u6d88\u606f\u5e8f\u5217\u6784\u5efa</strong> (\u7b2c 825-884 \u884c):\n   - \u5904\u7406\u6587\u672c\u6d88\u606f\n   - \u5904\u7406\u51fd\u6570\u8c03\u7528\u548c\u8f93\u51fa\n   - \u5904\u7406\u63a8\u7406\u5185\u5bb9\n   - \u8bbe\u7f6e\u6d88\u606f\u901a\u9053\u548c\u63a5\u6536\u8005</p>\n</li>\n<li>\n<p><strong>\u4ee4\u724c\u7f16\u7801</strong> (\u7b2c 887-889 \u884c):</p>\n</li>\n</ol>\n<pre class=\"codehilite\"><code class=\"language-python\">initial_tokens = encoding.render_conversation_for_completion(\n    conversation, Role.ASSISTANT\n)\n</code></pre>\n\n<ol start=\"6\">\n<li><strong>\u54cd\u5e94\u751f\u6210</strong> (\u7b2c 896-913 \u884c):</li>\n</ol>\n<pre class=\"codehilite\"><code class=\"language-python\">if body.stream:\n    return StreamingResponse(event_stream.run(), media_type=&quot;text/event-stream&quot;)\nelse:\n    # \u975e\u6d41\u5f0f\u54cd\u5e94\n</code></pre>\n\n<h2 id=\"_14\">\u4e8b\u4ef6\u7c7b\u578b\u7cfb\u7edf</h2>\n<h3 id=\"_15\">\u54cd\u5e94\u751f\u547d\u5468\u671f\u4e8b\u4ef6</h3>\n<ul>\n<li><code>ResponseCreatedEvent</code>: \u54cd\u5e94\u521b\u5efa</li>\n<li><code>ResponseInProgressEvent</code>: \u54cd\u5e94\u8fdb\u884c\u4e2d  </li>\n<li><code>ResponseCompletedEvent</code>: \u54cd\u5e94\u5b8c\u6210</li>\n</ul>\n<h3 id=\"_16\">\u8f93\u51fa\u9879\u4e8b\u4ef6</h3>\n<ul>\n<li><code>ResponseOutputItemAdded</code>: \u8f93\u51fa\u9879\u6dfb\u52a0</li>\n<li><code>ResponseOutputItemDone</code>: \u8f93\u51fa\u9879\u5b8c\u6210</li>\n</ul>\n<h3 id=\"_17\">\u5185\u5bb9\u4e8b\u4ef6</h3>\n<ul>\n<li><code>ResponseContentPartAdded</code>: \u5185\u5bb9\u90e8\u5206\u6dfb\u52a0</li>\n<li><code>ResponseContentPartDone</code>: \u5185\u5bb9\u90e8\u5206\u5b8c\u6210</li>\n<li><code>ResponseOutputTextDelta</code>: \u6587\u672c\u589e\u91cf</li>\n<li><code>ResponseOutputTextDone</code>: \u6587\u672c\u5b8c\u6210</li>\n</ul>\n<h3 id=\"_18\">\u63a8\u7406\u4e8b\u4ef6</h3>\n<ul>\n<li><code>ResponseReasoningTextDelta</code>: \u63a8\u7406\u6587\u672c\u589e\u91cf</li>\n<li><code>ResponseReasoningTextDone</code>: \u63a8\u7406\u6587\u672c\u5b8c\u6210</li>\n</ul>\n<h3 id=\"_19\">\u5de5\u5177\u8c03\u7528\u4e8b\u4ef6</h3>\n<ul>\n<li><code>ResponseWebSearchCallInProgress</code>: \u641c\u7d22\u8fdb\u884c\u4e2d</li>\n<li><code>ResponseWebSearchCallSearching</code>: \u641c\u7d22\u4e2d</li>\n<li><code>ResponseWebSearchCallCompleted</code>: \u641c\u7d22\u5b8c\u6210</li>\n</ul>\n<h2 id=\"_20\">\u9ad8\u7ea7\u7279\u6027</h2>\n<h3 id=\"_21\">\u6d41\u5f0f\u5904\u7406</h3>\n<ul>\n<li><strong>\u4e8b\u4ef6\u6d41</strong>: \u57fa\u4e8e Server-Sent Events (SSE)</li>\n<li><strong>\u5b9e\u65f6\u53cd\u9988</strong>: \u4ee4\u724c\u7ea7\u522b\u7684\u5b9e\u65f6\u751f\u6210</li>\n<li><strong>\u65ad\u5f00\u68c0\u6d4b</strong>: \u5ba2\u6237\u7aef\u65ad\u5f00\u68c0\u6d4b\u548c\u6e05\u7406</li>\n</ul>\n<h3 id=\"_22\">\u5de5\u5177\u96c6\u6210</h3>\n<ul>\n<li><strong>\u6d4f\u89c8\u5668\u641c\u7d22</strong>: \u96c6\u6210 Exa \u641c\u7d22\u540e\u7aef</li>\n<li><strong>\u51fd\u6570\u8c03\u7528</strong>: \u652f\u6301\u81ea\u5b9a\u4e49\u51fd\u6570\u5de5\u5177</li>\n<li><strong>\u53c2\u6570\u89e3\u6790</strong>: \u81ea\u52a8\u89e3\u6790\u5de5\u5177\u8c03\u7528\u53c2\u6570</li>\n</ul>\n<h3 id=\"_23\">\u63a8\u7406\u6a21\u5f0f</h3>\n<ul>\n<li><strong>\u4e09\u4e2a\u7ea7\u522b</strong>: low, medium, high</li>\n<li><strong>\u5206\u6790\u901a\u9053</strong>: \u72ec\u7acb\u7684\u601d\u8003\u8fc7\u7a0b\u8ddf\u8e2a</li>\n<li><strong>\u900f\u660e\u5ea6</strong>: \u5411\u7528\u6237\u5c55\u793a\u63a8\u7406\u8fc7\u7a0b</li>\n</ul>\n<h3 id=\"_24\">\u5f15\u7528\u7cfb\u7edf</h3>\n<ul>\n<li><strong>URL\u5f15\u7528</strong>: \u81ea\u52a8\u63d0\u53d6\u548c\u6807\u6ce8\u7f51\u7edc\u5185\u5bb9\u5f15\u7528</li>\n<li><strong>\u589e\u91cf\u66f4\u65b0</strong>: \u5b9e\u65f6\u66f4\u65b0\u5f15\u7528\u6ce8\u91ca</li>\n<li><strong>\u7d22\u5f15\u7ba1\u7406</strong>: \u907f\u514d\u91cd\u590d\u5f15\u7528</li>\n</ul>\n<h2 id=\"_25\">\u6027\u80fd\u4f18\u5316</h2>\n<h3 id=\"_26\">\u5f02\u6b65\u5904\u7406</h3>\n<ul>\n<li><strong>\u534f\u7a0b\u652f\u6301</strong>: \u5168\u5f02\u6b65 API \u8bbe\u8ba1</li>\n<li><strong>\u5e76\u53d1\u5b89\u5168</strong>: \u9002\u5f53\u7684\u72b6\u6001\u7ba1\u7406</li>\n<li><strong>\u8d44\u6e90\u6e05\u7406</strong>: \u81ea\u52a8\u6e05\u7406\u65ad\u5f00\u8fde\u63a5</li>\n</ul>\n<h3 id=\"_27\">\u5185\u5b58\u7ba1\u7406</h3>\n<ul>\n<li><strong>\u54cd\u5e94\u7f13\u5b58</strong>: <code>responses_store</code> \u5b58\u50a8\u5bf9\u8bdd\u5386\u53f2</li>\n<li><strong>\u4ee4\u724c\u7ba1\u7406</strong>: \u9ad8\u6548\u7684\u4ee4\u724c\u5e8f\u5217\u5904\u7406</li>\n<li><strong>\u589e\u91cf\u5904\u7406</strong>: \u907f\u514d\u5927\u91cf\u5185\u5b58\u5206\u914d</li>\n</ul>\n<h2 id=\"_28\">\u4e0e\u5176\u4ed6\u6a21\u5757\u7684\u5173\u7cfb</h2>\n<h3 id=\"_29\">\u6838\u5fc3\u4f9d\u8d56</h3>\n<ul>\n<li><code>openai_harmony</code>: \u6d88\u606f\u7f16\u7801\u548c\u89e3\u6790</li>\n<li><code>fastapi</code>: Web \u6846\u67b6</li>\n<li><code>gpt_oss.tools.simple_browser</code>: \u6d4f\u89c8\u5668\u5de5\u5177</li>\n</ul>\n<h3 id=\"_30\">\u7c7b\u578b\u5b9a\u4e49</h3>\n<ul>\n<li>\u5bfc\u5165\u5927\u91cf\u4e8b\u4ef6\u548c\u7c7b\u578b\u5b9a\u4e49 (\u7b2c 26-59 \u884c)</li>\n<li>\u652f\u6301\u5b8c\u6574\u7684\u7c7b\u578b\u5b89\u5168</li>\n</ul>\n<h2 id=\"_31\">\u4f7f\u7528\u793a\u4f8b</h2>\n<pre class=\"codehilite\"><code class=\"language-python\">from gpt_oss.responses_api.api_server import create_api_server\n\n# \u521b\u5efa\u63a8\u7406\u51fd\u6570\ndef my_infer_function(tokens, temperature):\n    # \u6a21\u578b\u63a8\u7406\u903b\u8f91\n    return next_token\n\n# \u521b\u5efaAPI\u670d\u52a1\u5668\napp = create_api_server(my_infer_function, encoding)\n\n# \u542f\u52a8\u670d\u52a1\u5668\nimport uvicorn\nuvicorn.run(app, host=&quot;0.0.0.0&quot;, port=8000)\n</code></pre>\n\n<p>\u8fd9\u4e2a\u6a21\u5757\u662f\u6574\u4e2a GPT-OSS \u9879\u76ee\u7684 API \u7f51\u5173\uff0c\u63d0\u4f9b\u4e86\u5b8c\u6574\u7684\u5bf9\u8bdd\u5f0f AI \u670d\u52a1\u63a5\u53e3\uff0c\u652f\u6301\u73b0\u4ee3 AI \u5e94\u7528\u6240\u9700\u7684\u5404\u79cd\u9ad8\u7ea7\u529f\u80fd\u3002</p>"
  },
  "../05_torch_weights.md": {
    "hash": "6b908c4a59b91f7ebcec318ea277427e",
    "content": "<h1 id=\"torch-weights\">Torch Weights \u6743\u91cd\u52a0\u8f7d\u6a21\u5757\u5206\u6790</h1>\n<h2 id=\"_1\">\u6587\u4ef6\u4f4d\u7f6e</h2>\n<p><code>/Users/georgezhou/Downloads/gpt-oss/gpt_oss/torch/weights.py</code></p>\n<h2 id=\"_2\">\u6982\u8ff0</h2>\n<p>\u8fd9\u662f\u4e00\u4e2a\u4e13\u95e8\u5904\u7406 MXFP4 (Mixed-Precision 4-bit Floating Point) \u91cf\u5316\u6743\u91cd\u7684\u52a0\u8f7d\u6a21\u5757\u3002\u5b83\u8d1f\u8d23\u4ece SafeTensors \u683c\u5f0f\u7684\u68c0\u67e5\u70b9\u6587\u4ef6\u4e2d\u52a0\u8f7d\u6a21\u578b\u6743\u91cd\uff0c\u5e76\u652f\u6301\u9ad8\u6548\u7684 MXFP4 \u91cf\u5316\u683c\u5f0f\u89e3\u7801\u3002</p>\n<h2 id=\"_3\">\u6838\u5fc3\u5e38\u91cf\u5b9a\u4e49</h2>\n<h3 id=\"mxfp4\">MXFP4 \u76f8\u5173\u5e38\u91cf</h3>\n<p><strong>\u4f4d\u7f6e</strong>: \u7b2c 8-14 \u884c</p>\n<pre class=\"codehilite\"><code class=\"language-python\">BYTES_PER_BLOCK = 16  # 32\u4e2aFP4\u6570\u5b57\u6253\u5305\u572816\u5b57\u8282\u4e2d\nFP4_VALUES = [\n    +0.0, +0.5, +1.0, +1.5, +2.0, +3.0, +4.0, +6.0,  # \u6b63\u503c\n    -0.0, -0.5, -1.0, -1.5, -2.0, -3.0, -4.0, -6.0,  # \u8d1f\u503c\n]\n</code></pre>\n\n<ul>\n<li><strong>BYTES_PER_BLOCK</strong>: \u6bcf\u4e2a MXFP4 \u5757\u5305\u542b 32 \u4e2a FP4 \u6570\u5b57\uff0c\u538b\u7f29\u5230 16 \u5b57\u8282</li>\n<li><strong>FP4_VALUES</strong>: FP4 \u683c\u5f0f\u652f\u6301\u7684 16 \u4e2a\u6d6e\u70b9\u503c\u7684\u67e5\u627e\u8868</li>\n</ul>\n<h3 id=\"_4\">\u53c2\u6570\u540d\u6620\u5c04</h3>\n<p><strong>\u4f4d\u7f6e</strong>: \u7b2c 16-25 \u884c</p>\n<pre class=\"codehilite\"><code class=\"language-python\">PARAM_NAME_MAP = {\n    f&quot;block.{n}.mlp.mlp1_bias&quot;: f&quot;block.{n}.mlp.mlp1_bias&quot; for n in range(36)\n} | {\n    f&quot;block.{n}.mlp.mlp1_weight&quot;: (f&quot;block.{n}.mlp.mlp1_weight.blocks&quot;, f&quot;block.{n}.mlp.mlp1_weight.scales&quot;) for n in range(36)\n} | {\n    f&quot;block.{n}.mlp.mlp2_bias&quot;: f&quot;block.{n}.mlp.mlp2_bias&quot; for n in range(36)\n} | {\n    f&quot;block.{n}.mlp.mlp2_weight&quot;: (f&quot;block.{n}.mlp.mlp2_weight.blocks&quot;, f&quot;block.{n}.mlp.mlp2_weight.scales&quot;) for n in range(36)\n}\n</code></pre>\n\n<p>\u5c06\u903b\u8f91\u53c2\u6570\u540d\u6620\u5c04\u5230\u68c0\u67e5\u70b9\u4e2d\u7684\u5b9e\u9645\u5f20\u91cf\u540d\uff0c\u652f\u6301 36 \u4e2a transformer \u5757\u3002</p>\n<h2 id=\"checkpoint\">\u6838\u5fc3\u7c7b: Checkpoint</h2>\n<h3 id=\"__init__\">\u6784\u9020\u51fd\u6570 <code>__init__</code></h3>\n<p><strong>\u4f4d\u7f6e</strong>: \u7b2c 29-50 \u884c\n<strong>\u529f\u80fd</strong>: \u521d\u59cb\u5316\u68c0\u67e5\u70b9\u52a0\u8f7d\u5668</p>\n<h4 id=\"_5\">\u5b9e\u73b0\u8fc7\u7a0b:</h4>\n<ol>\n<li><strong>\u8bbe\u5907\u5b57\u7b26\u4e32\u6784\u5efa</strong> (\u7b2c 30-35 \u884c):</li>\n</ol>\n<pre class=\"codehilite\"><code class=\"language-python\">device_str = (\n    device.type if device.index is None\n    else device.type + &quot;:&quot; + str(device.index)\n)\n</code></pre>\n\n<ol start=\"2\">\n<li>\n<p><strong>SafeTensors \u6587\u4ef6\u626b\u63cf</strong> (\u7b2c 37-42 \u884c):\n   \u626b\u63cf\u68c0\u67e5\u70b9\u76ee\u5f55\u4e2d\u6240\u6709 <code>.safetensors</code> \u6587\u4ef6</p>\n</li>\n<li>\n<p><strong>\u5f20\u91cf\u6620\u5c04\u6784\u5efa</strong> (\u7b2c 43-49 \u884c):</p>\n</li>\n</ol>\n<pre class=\"codehilite\"><code class=\"language-python\">tensor_name_to_file = {}\nfor safetensor_file in safetensor_files:\n    with safe_open(safetensor_file, framework=&quot;pt&quot;, device=device_str) as f:\n        for key in f.keys():\n            tensor_name_to_file[key] = safetensor_file\n</code></pre>\n\n<h3 id=\"_6\">\u4e3b\u8981\u65b9\u6cd5</h3>\n<h4 id=\"getname-str-torchtensor\"><code>get(name: str) -&gt; torch.Tensor</code></h4>\n<p><strong>\u4f4d\u7f6e</strong>: \u7b2c 52-59 \u884c\n<strong>\u529f\u80fd</strong>: \u6839\u636e\u53c2\u6570\u540d\u83b7\u53d6\u5f20\u91cf</p>\n<p>\u5b9e\u73b0\u903b\u8f91:</p>\n<ol>\n<li>\u4f7f\u7528\u53c2\u6570\u540d\u6620\u5c04\u67e5\u627e\u5b9e\u9645\u5f20\u91cf\u540d</li>\n<li>\u5982\u679c\u8fd4\u56de\u5143\u7ec4 (blocks_name, scales_name)\uff0c\u8c03\u7528 <code>_get_mxfp4_tensor</code></li>\n<li>\u5982\u679c\u8fd4\u56de\u5355\u4e2a\u540d\u79f0\uff0c\u8c03\u7528 <code>_get_tensor</code></li>\n</ol>\n<h4 id=\"_get_tensorname-str-torchtensor\"><code>_get_tensor(name: str) -&gt; torch.Tensor</code></h4>\n<p><strong>\u4f4d\u7f6e</strong>: \u7b2c 61-66 \u884c\n<strong>\u529f\u80fd</strong>: \u52a0\u8f7d\u666e\u901a\u5f20\u91cf\uff08\u504f\u7f6e\u7b49\uff09</p>\n<h4 id=\"_get_mxfp4_tensor-torchtensor\"><code>_get_mxfp4_tensor(...) -&gt; torch.Tensor</code></h4>\n<p><strong>\u4f4d\u7f6e</strong>: \u7b2c 68-117 \u884c\n<strong>\u529f\u80fd</strong>: \u89e3\u7801 MXFP4 \u91cf\u5316\u6743\u91cd</p>\n<h5 id=\"_7\">\u6838\u5fc3\u89e3\u7801\u7b97\u6cd5:</h5>\n<ol>\n<li><strong>\u6570\u636e\u52a0\u8f7d</strong> (\u7b2c 83-84 \u884c):</li>\n</ol>\n<pre class=\"codehilite\"><code class=\"language-python\">blocks = self._get_tensor(blocks_name)\nscales = self._get_tensor(scales_name).to(torch.int32) - 127\n</code></pre>\n\n<ol start=\"2\">\n<li><strong>\u67e5\u627e\u8868\u521b\u5efa</strong> (\u7b2c 90 \u884c):</li>\n</ol>\n<pre class=\"codehilite\"><code class=\"language-python\">lut = torch.tensor(FP4_VALUES, dtype=dtype, device=blocks.device)\n</code></pre>\n\n<ol start=\"3\">\n<li><strong>\u5206\u5757\u5904\u7406</strong> (\u7b2c 100-116 \u884c):</li>\n</ol>\n<pre class=\"codehilite\"><code class=\"language-python\">for r0 in range(0, rows_total, rows_per_chunk):\n    # \u63d0\u53d6\u4f4e4\u4f4d\u548c\u9ad84\u4f4d\n    idx_lo = (blk &amp; 0x0F).to(torch.long)\n    idx_hi = (blk &gt;&gt; 4).to(torch.long)\n\n    # \u67e5\u627e\u8868\u6620\u5c04\n    sub[:, 0::2] = lut[idx_lo]\n    sub[:, 1::2] = lut[idx_hi]\n\n    # \u5e94\u7528\u7f29\u653e\u56e0\u5b50\n    torch.ldexp(sub, exp, out=sub)\n</code></pre>\n\n<h2 id=\"mxfp4_1\">MXFP4 \u91cf\u5316\u539f\u7406</h2>\n<h3 id=\"_8\">\u6570\u636e\u683c\u5f0f</h3>\n<ol>\n<li><strong>Blocks</strong>: \u6bcf\u5b57\u8282\u5305\u542b\u4e24\u4e2a 4 \u4f4d\u7d22\u5f15\uff08\u4f4e4\u4f4d\u548c\u9ad84\u4f4d\uff09</li>\n<li><strong>Scales</strong>: \u6bcf\u7ec4\u5bf9\u5e94\u7684\u6307\u6570\u7f29\u653e\u56e0\u5b50</li>\n<li><strong>\u89e3\u7801</strong>: <code>value = FP4_VALUES[index] * 2^(scale-127)</code></li>\n</ol>\n<h3 id=\"_9\">\u5185\u5b58\u6548\u7387</h3>\n<ul>\n<li><strong>\u538b\u7f29\u6bd4</strong>: 16:1 (\u76f8\u5bf9\u4e8e FP16)</li>\n<li><strong>\u5206\u5757\u5904\u7406</strong>: \u907f\u514d\u5927\u5f20\u91cf\u4e00\u6b21\u6027\u52a0\u8f7d\u5230\u5185\u5b58</li>\n<li><strong>\u4ea4\u9519\u5b58\u50a8</strong>: \u652f\u6301 SwiGLU \u6fc0\u6d3b\u7684\u9ad8\u6548\u8ba1\u7b97</li>\n</ul>\n<h2 id=\"_10\">\u4f18\u5316\u7248\u672c\u5bf9\u6bd4</h2>\n<h3 id=\"_get_mxfp4_tensor\"><code>_get_mxfp4_tensor</code> (\u5185\u5b58\u4f18\u5316\u7248)</h3>\n<p><strong>\u4f4d\u7f6e</strong>: \u7b2c 68-117 \u884c</p>\n<ul>\n<li>\u5206\u5757\u5904\u7406\uff0c\u5185\u5b58\u4f7f\u7528\u5c11</li>\n<li>\u9002\u5408\u5927\u578b\u6a21\u578b\u63a8\u7406</li>\n</ul>\n<h3 id=\"_get_mxfp4_tensor_copy\"><code>_get_mxfp4_tensor_copy</code> (\u7b80\u5316\u7248)</h3>\n<p><strong>\u4f4d\u7f6e</strong>: \u7b2c 119-137 \u884c</p>\n<ul>\n<li>\u4e00\u6b21\u6027\u5904\u7406\u6240\u6709\u6570\u636e</li>\n<li>\u5185\u5b58\u4f7f\u7528\u591a\u4f46\u4ee3\u7801\u7b80\u6d01</li>\n</ul>\n<h2 id=\"_11\">\u4e0e\u5176\u4ed6\u6a21\u5757\u7684\u5173\u7cfb</h2>\n<h3 id=\"_12\">\u4f9d\u8d56\u6a21\u5757</h3>\n<ul>\n<li><code>torch</code>: PyTorch \u6846\u67b6</li>\n<li><code>safetensors</code>: \u5b89\u5168\u5f20\u91cf\u683c\u5f0f</li>\n<li><code>math</code>: \u6570\u5b66\u8fd0\u7b97</li>\n</ul>\n<h3 id=\"_13\">\u88ab\u8c03\u7528\u8005</h3>\n<ul>\n<li><code>gpt_oss/torch/model.py</code>: Torch \u6a21\u578b\u5b9e\u73b0</li>\n<li><code>gpt_oss/triton/model.py</code>: Triton \u6a21\u578b\u5b9e\u73b0</li>\n</ul>\n<h2 id=\"_14\">\u6027\u80fd\u7279\u5f81</h2>\n<h3 id=\"_15\">\u5185\u5b58\u4f18\u5316</h3>\n<ul>\n<li>\u5206\u5757\u52a0\u8f7d\u907f\u514d OOM</li>\n<li>\u652f\u6301\u4e0d\u540c\u8bbe\u5907 (CPU/GPU)</li>\n<li>\u5185\u5b58\u6620\u5c04\u6587\u4ef6\u8bfb\u53d6</li>\n</ul>\n<h3 id=\"_16\">\u8ba1\u7b97\u4f18\u5316</h3>\n<ul>\n<li>\u67e5\u627e\u8868\u5feb\u901f\u89e3\u7801</li>\n<li>\u5411\u91cf\u5316\u64cd\u4f5c</li>\n<li>\u539f\u5730\u8ba1\u7b97\u51cf\u5c11\u5185\u5b58\u5206\u914d</li>\n</ul>\n<h2 id=\"_17\">\u4f7f\u7528\u793a\u4f8b</h2>\n<pre class=\"codehilite\"><code class=\"language-python\">import torch\nfrom gpt_oss.torch.weights import Checkpoint\n\n# \u521d\u59cb\u5316\u68c0\u67e5\u70b9\u52a0\u8f7d\u5668\ndevice = torch.device(&quot;cuda:0&quot;)\ncheckpoint = Checkpoint(&quot;path/to/checkpoint/&quot;, device)\n\n# \u52a0\u8f7d\u666e\u901a\u6743\u91cd (bias)\nbias = checkpoint.get(&quot;block.0.mlp.mlp1_bias&quot;)\n\n# \u52a0\u8f7d\u91cf\u5316\u6743\u91cd (\u81ea\u52a8\u89e3\u7801 MXFP4)\nweight = checkpoint.get(&quot;block.0.mlp.mlp1_weight&quot;)\n</code></pre>\n\n<h2 id=\"_18\">\u6280\u672f\u4eae\u70b9</h2>\n<ol>\n<li><strong>\u9ad8\u6548\u91cf\u5316</strong>: MXFP4 \u683c\u5f0f\u5728\u4fdd\u6301\u7cbe\u5ea6\u7684\u540c\u65f6\u5927\u5e45\u51cf\u5c11\u5185\u5b58\u4f7f\u7528</li>\n<li><strong>\u7075\u6d3b\u6620\u5c04</strong>: \u652f\u6301\u4e0d\u540c\u7684\u53c2\u6570\u547d\u540d\u7ea6\u5b9a</li>\n<li><strong>\u5206\u5757\u5904\u7406</strong>: \u5904\u7406\u8d85\u5927\u6743\u91cd\u65f6\u7684\u5185\u5b58\u5b89\u5168</li>\n<li><strong>\u8bbe\u5907\u611f\u77e5</strong>: \u81ea\u52a8\u9002\u914d\u4e0d\u540c\u7684 PyTorch \u8bbe\u5907</li>\n</ol>"
  },
  "../09_metal_model.md": {
    "hash": "56c0781385154ff7b552853cd1599865",
    "content": "<h1 id=\"metal-model-c\">Metal Model C\u8bed\u8a00\u5b9e\u73b0\u6a21\u5757\u5206\u6790</h1>\n<h2 id=\"_1\">\u6587\u4ef6\u4f4d\u7f6e</h2>\n<p><code>/Users/georgezhou/Downloads/gpt-oss/gpt_oss/metal/source/model.c</code></p>\n<h2 id=\"_2\">\u6982\u8ff0</h2>\n<p>\u8fd9\u662f GPT-OSS \u9879\u76ee\u7684 Metal (Apple GPU) \u540e\u7aef C \u8bed\u8a00\u5b9e\u73b0\uff0c\u63d0\u4f9b\u4e86\u4ece\u6587\u4ef6\u52a0\u8f7d\u6a21\u578b\u3001\u521d\u59cb\u5316 Metal \u8bbe\u5907\u548c\u5185\u6838\u3001\u7ba1\u7406\u6743\u91cd\u7f13\u51b2\u533a\u7b49\u6838\u5fc3\u529f\u80fd\u3002\u5b83\u662f\u5728 Apple Silicon \u8bbe\u5907\u4e0a\u8fdb\u884c\u9ad8\u6027\u80fd GPU \u63a8\u7406\u7684\u5173\u952e\u6a21\u5757\u3002</p>\n<h2 id=\"_3\">\u6838\u5fc3\u7cfb\u7edf\u5305\u542b</h2>\n<p><strong>\u4f4d\u7f6e</strong>: \u7b2c 1-24 \u884c</p>\n<pre class=\"codehilite\"><code class=\"language-c\">#include &lt;assert.h&gt;\n#include &lt;inttypes.h&gt;\n#include &lt;stdatomic.h&gt;\n#include &lt;stdint.h&gt;\n#include &lt;stdlib.h&gt;\n#include &lt;string.h&gt;\n#include &lt;errno.h&gt;\n#include &lt;fcntl.h&gt;\n#include &lt;mach/vm_page_size.h&gt;  // Apple \u7cfb\u7edf\u9875\u9762\u5927\u5c0f\n#include &lt;sys/mman.h&gt;           // \u5185\u5b58\u6620\u5c04\n#include &lt;sys/stat.h&gt;\n#include &lt;sys/types.h&gt;\n#include &lt;unistd.h&gt;\n#include &lt;gpt-oss.h&gt;            // \u9879\u76ee\u4e3b\u5934\u6587\u4ef6\n</code></pre>\n\n<h2 id=\"_4\">\u6838\u5fc3\u5de5\u5177\u51fd\u6570</h2>\n<h3 id=\"_5\">\u5185\u5b58\u9875\u9762\u5bf9\u9f50\u51fd\u6570</h3>\n<h4 id=\"round_up_to_page_size\"><code>round_up_to_page_size</code></h4>\n<p><strong>\u4f4d\u7f6e</strong>: \u7b2c 27-34 \u884c</p>\n<pre class=\"codehilite\"><code class=\"language-c\">static size_t round_up_to_page_size(size_t bytes) {\n    const size_t page_size_mask = (size_t) vm_page_size - 1;\n    if ((bytes &amp; page_size_mask) != 0) {\n        bytes |= page_size_mask;\n        bytes += 1;\n    }\n    return bytes;\n}\n</code></pre>\n\n<h4 id=\"round_down_to_page_size\"><code>round_down_to_page_size</code></h4>\n<p><strong>\u4f4d\u7f6e</strong>: \u7b2c 36-39 \u884c</p>\n<pre class=\"codehilite\"><code class=\"language-c\">static size_t round_down_to_page_size(size_t bytes) {\n    const size_t page_size_mask = (size_t) vm_page_size - 1;\n    return bytes &amp; ~page_size_mask;\n}\n</code></pre>\n\n<h4 id=\"_6\">\u529f\u80fd\u8bf4\u660e:</h4>\n<ul>\n<li><strong>\u9875\u9762\u5bf9\u9f50</strong>: \u786e\u4fdd\u5185\u5b58\u5206\u914d\u7b26\u5408\u7cfb\u7edf\u9875\u9762\u8fb9\u754c\u8981\u6c42</li>\n<li><strong>\u6027\u80fd\u4f18\u5316</strong>: \u9875\u9762\u5bf9\u9f50\u7684\u5185\u5b58\u8bbf\u95ee\u66f4\u9ad8\u6548</li>\n<li><strong>\u7cfb\u7edf\u517c\u5bb9</strong>: \u9002\u914d\u4e0d\u540c Apple \u8bbe\u5907\u7684\u9875\u9762\u5927\u5c0f</li>\n</ul>\n<h3 id=\"io\">\u6587\u4ef6 I/O \u51fd\u6570</h3>\n<h4 id=\"read_fd\"><code>read_fd</code> \u5b8c\u6574\u6587\u4ef6\u8bfb\u53d6</h4>\n<p><strong>\u4f4d\u7f6e</strong>: \u7b2c 41-59 \u884c</p>\n<pre class=\"codehilite\"><code class=\"language-c\">static enum gptoss_status read_fd(int fd, void* data, size_t size, const char* path) {\n    size_t bytes_to_read = size;\n    char* current_byte = (char*) data;\n    do {\n        const ssize_t read_result = read(fd, current_byte, bytes_to_read);\n        if (read_result &lt; 0) {\n            GPTOSS_LOG_ERROR(&quot;reading %zu bytes from file %s failed with error %d&quot;,\n                size, path, errno);\n            return gptoss_status_io_error;\n        }\n        current_byte += (size_t) read_result;\n        bytes_to_read -= (size_t) read_result;\n    } while (bytes_to_read != 0);\n    return gptoss_status_success;\n}\n</code></pre>\n\n<h4 id=\"_7\">\u7279\u6027:</h4>\n<ul>\n<li><strong>\u5b8c\u6574\u8bfb\u53d6</strong>: \u5faa\u73af\u8bfb\u53d6\u786e\u4fdd\u6240\u6709\u6570\u636e\u90fd\u88ab\u8bfb\u53d6</li>\n<li><strong>\u9519\u8bef\u5904\u7406</strong>: \u8be6\u7ec6\u7684\u9519\u8bef\u65e5\u5fd7\u548c\u72b6\u6001\u8fd4\u56de</li>\n<li><strong>\u9c81\u68d2\u6027</strong>: \u5904\u7406\u90e8\u5206\u8bfb\u53d6\u60c5\u51b5</li>\n</ul>\n<h4 id=\"prefetch_fd\"><code>prefetch_fd</code> \u6587\u4ef6\u9884\u53d6\u4f18\u5316</h4>\n<p><strong>\u4f4d\u7f6e</strong>: \u7b2c 61-78 \u884c</p>\n<pre class=\"codehilite\"><code class=\"language-c\">static void prefetch_fd(int fd, size_t offset, size_t size, const char* path) {\n    const size_t prefetch_max = round_down_to_page_size((size_t) INT_MAX);\n    do {\n        const size_t prefetch_size = math_min(size, prefetch_max);\n        const struct radvisory ra = {\n            .ra_offset = offset,\n            .ra_count = (int) prefetch_size,\n        };\n        if (fcntl(fd, F_RDADVISE, &amp;ra) == -1) {\n            GPTOSS_LOG_WARNING(&quot;fcntl(%s, F_RDADVISE, .ra_offset=%zu, .ra_count=%d) failed with error %d\\\\n&quot;,\n                path, (size_t) ra.ra_offset, ra.ra_count, errno);\n            return;\n        }\n        offset += prefetch_size;\n        size -= prefetch_size;\n    } while (size != 0);\n}\n</code></pre>\n\n<h4 id=\"_8\">\u529f\u80fd:</h4>\n<ul>\n<li><strong>\u9884\u53d6\u4f18\u5316</strong>: \u544a\u77e5\u7cfb\u7edf\u5373\u5c06\u8bbf\u95ee\u7684\u6570\u636e\uff0c\u63d0\u524d\u52a0\u8f7d\u5230\u7f13\u5b58</li>\n<li><strong>\u5206\u5757\u5904\u7406</strong>: \u5904\u7406\u5927\u6587\u4ef6\u65f6\u5206\u5757\u9884\u53d6\u907f\u514d\u7cfb\u7edf\u9650\u5236</li>\n<li><strong>\u6027\u80fd\u63d0\u5347</strong>: \u663e\u8457\u63d0\u9ad8\u540e\u7eed\u6587\u4ef6\u8bbf\u95ee\u901f\u5ea6</li>\n</ul>\n<h2 id=\"api\">\u4e3b\u8981API\u51fd\u6570</h2>\n<h3 id=\"gptoss_model_create_from_file\"><code>gptoss_model_create_from_file</code> \u6a21\u578b\u52a0\u8f7d</h3>\n<p><strong>\u4f4d\u7f6e</strong>: \u7b2c 80-440 \u884c\n<strong>\u529f\u80fd</strong>: \u4ece\u6587\u4ef6\u52a0\u8f7d\u5b8c\u6574\u7684 GPT \u6a21\u578b</p>\n<h4 id=\"_9\">\u6838\u5fc3\u6267\u884c\u6d41\u7a0b:</h4>\n<h5 id=\"1-92-106\">1. \u6587\u4ef6\u6253\u5f00\u548c\u57fa\u672c\u9a8c\u8bc1 (\u7b2c 92-106 \u884c)</h5>\n<pre class=\"codehilite\"><code class=\"language-c\">fd = open(path, O_RDONLY);\nif (fd == -1) {\n    GPTOSS_LOG_ERROR(&quot;open(%s) failed with error %d&quot;, path, errno);\n    switch (errno) {\n        case EISDIR:\n        case ENOENT:\n        case ENOTDIR:\n            status = gptoss_status_invalid_argument;\n            break;\n        default:\n            status = gptoss_status_io_error;\n            break;\n    }\n    goto cleanup;\n}\n</code></pre>\n\n<h5 id=\"2-108-132\">2. \u6587\u4ef6\u5934\u9a8c\u8bc1 (\u7b2c 108-132 \u884c)</h5>\n<pre class=\"codehilite\"><code class=\"language-c\">struct gptoss_file_header file_header;\nstatus = read_fd(fd, &amp;file_header, sizeof(file_header), path);\n\n// Magic number \u9a8c\u8bc1: &quot;GPT-OSS v1.0&quot;\nif (file_header.magic[0] != 'G' ||\n    file_header.magic[1] != 'P' ||\n    file_header.magic[2] != 'T' ||\n    file_header.magic[3] != '-' ||\n    file_header.magic[4] != 'O' ||\n    file_header.magic[5] != 'S' ||\n    file_header.magic[6] != 'S' ||\n    file_header.magic[7] != ' ' ||\n    file_header.magic[8] != 'v' ||\n    file_header.magic[9] != '1' ||\n    file_header.magic[10] != '.' ||\n    file_header.magic[11] != '0' ||\n    file_header.zero != 0)\n{\n    GPTOSS_LOG_ERROR(&quot;invalid magic in file %s&quot;, path);\n    status = gptoss_status_invalid_argument;\n    goto cleanup;\n}\n</code></pre>\n\n<h5 id=\"3-uuid-134-165\">3. \u6a21\u578b UUID \u548c\u5934\u4fe1\u606f\u9a8c\u8bc1 (\u7b2c 134-165 \u884c)</h5>\n<pre class=\"codehilite\"><code class=\"language-c\">struct gptoss_uuid model_uuid;\nstatus = read_fd(fd, &amp;model_uuid, sizeof(model_uuid), path);\nif (!gptoss_is_gptoss_model_uuid(&amp;model_uuid)) {\n    GPTOSS_LOG_ERROR(&quot;unsupported model UUID &quot; UUID_FORMAT, UUID_ARGS(model_uuid));\n    status = gptoss_status_invalid_argument;\n    goto cleanup;\n}\n\nstruct gptoss_gptoss_model_header model_header;\nstatus = read_fd(fd, &amp;model_header, sizeof(model_header), path);\n\nstruct gptoss_uuid layout_uuid;  \nstatus = read_fd(fd, &amp;layout_uuid, sizeof(layout_uuid), path);\nif (!gptoss_is_applegpu_layout_uuid(&amp;layout_uuid)) {\n    GPTOSS_LOG_ERROR(&quot;unsupported layout UUID &quot; UUID_FORMAT, UUID_ARGS(layout_uuid));\n    status = gptoss_status_invalid_argument;\n    goto cleanup;\n}\n</code></pre>\n\n<h5 id=\"4-167-194\">4. \u6a21\u578b\u7ed3\u6784\u4f53\u5206\u914d\u548c\u521d\u59cb\u5316 (\u7b2c 167-194 \u884c)</h5>\n<pre class=\"codehilite\"><code class=\"language-c\">const size_t model_size = sizeof(struct gptoss_model) + model_header.num_blocks * sizeof(struct gptoss_metal_buffer);\nmodel = malloc(model_size);\nif (model == NULL) {\n    GPTOSS_LOG_ERROR(&quot;failed to allocate %zu bytes for model descriptor&quot;, model_size);\n    status = gptoss_status_insufficient_memory;\n    goto cleanup;\n}\nmemset(model, 0, model_size);\n\natomic_store_explicit(&amp;model-&gt;ref_count, 1, memory_order_relaxed);\nmodel-&gt;context_length = model_header.context_length;\nmodel-&gt;num_blocks = model_header.num_blocks;\nmodel-&gt;num_experts = model_header.num_experts;\n// ... \u66f4\u591a\u6a21\u578b\u53c2\u6570\u521d\u59cb\u5316\n</code></pre>\n\n<h5 id=\"5-197-265\">5. \u5206\u8bcd\u5668\u52a0\u8f7d (\u7b2c 197-265 \u884c)</h5>\n<pre class=\"codehilite\"><code class=\"language-c\">struct gptoss_uuid tokenizer_uuid;\nstatus = read_fd(fd, &amp;tokenizer_uuid, sizeof(tokenizer_uuid), path);\nif (!gptoss_is_tiktoken_tokenizer_uuid(&amp;tokenizer_uuid)) {\n    GPTOSS_LOG_ERROR(&quot;unsupported tokenizer UUID &quot; UUID_FORMAT, UUID_ARGS(tokenizer_uuid));\n    status = gptoss_status_invalid_argument;\n    goto cleanup;\n}\n\n// \u5185\u5b58\u6620\u5c04\u5206\u8bcd\u5668\u6570\u636e\nconst size_t tokenizer_mapping_size = round_up_to_page_size(tokenizer_end_offset) - tokenizer_mapping_start;\nvoid* tokenizer_mapping_ptr = mmap(NULL, tokenizer_mapping_size, PROT_READ, MAP_PRIVATE, fd, tokenizer_mapping_start);\n</code></pre>\n\n<h5 id=\"6-metal-293-356\">6. Metal \u8bbe\u5907\u548c\u5185\u6838\u521d\u59cb\u5316 (\u7b2c 293-356 \u884c)</h5>\n<pre class=\"codehilite\"><code class=\"language-c\">// \u521d\u59cb\u5316 Metal \u8bbe\u5907\nstatus = gptoss_metal_device_create_system_default(&amp;model-&gt;device);\nmodel-&gt;max_threadgroups = model-&gt;device.num_cores * 3;\nstatus = gptoss_metal_command_queue_create(&amp;model-&gt;device, &amp;model-&gt;command_queue);\n\n// \u52a0\u8f7d Metal \u5e93\u548c\u5185\u6838\u51fd\u6570\nstatus = gptoss_metal_library_create_default(&amp;model-&gt;device, &amp;model-&gt;library);\nstatus = gptoss_metal_function_create(&amp;model-&gt;library, &quot;gptoss_bf16_f32_embeddings&quot;, &amp;model-&gt;bf16_f32_embeddings_fn);\nstatus = gptoss_metal_function_create(&amp;model-&gt;library, &quot;gptoss_f32_bf16w_rmsnorm&quot;, &amp;model-&gt;f32_bf16w_rmsnorm_fn);\n// ... \u52a0\u8f7d\u66f4\u591a\u5185\u6838\u51fd\u6570\n</code></pre>\n\n<h5 id=\"7-358-422\">7. \u6743\u91cd\u7f13\u51b2\u533a\u6620\u5c04 (\u7b2c 358-422 \u884c)</h5>\n<pre class=\"codehilite\"><code class=\"language-c\">// \u8ba1\u7b97\u5404\u5c42\u6743\u91cd\u504f\u79fb\u91cf\nconst size_t embedding_weight_size = math_round_up_po2(model-&gt;vocabulary_size * model-&gt;embedding_dim * sizeof(gptoss_bfloat16), 16);\nmodel-&gt;attn_rmsnorm_gain_offset = embedding_weight_size;\n// ... \u66f4\u591a\u504f\u79fb\u91cf\u8ba1\u7b97\n\n// \u521b\u5efa\u5171\u4eab\u6743\u91cd\u7f13\u51b2\u533a\nstatus = gptoss_metal_buffer_wrap(&amp;model-&gt;device, shared_weights_size, current_ptr, &amp;model-&gt;shared_weight_buffer);\n\n// \u4e3a\u6bcf\u4e2a\u5757\u521b\u5efa MoE \u6743\u91cd\u7f13\u51b2\u533a\nfor (uint32_t n = 0; n &lt; model-&gt;num_blocks; n++) {\n    status = gptoss_metal_buffer_wrap(&amp;model-&gt;device, moe_block_weight_size, current_ptr, &amp;model-&gt;block_weight_buffers[n]);\n    current_ptr += moe_block_weight_size;\n    model-&gt;weights_size += moe_block_weight_size;\n}\n</code></pre>\n\n<h3 id=\"api_1\">\u8f85\u52a9API\u51fd\u6570</h3>\n<h4 id=\"gptoss_model_get_tokenizer\"><code>gptoss_model_get_tokenizer</code></h4>\n<p><strong>\u4f4d\u7f6e</strong>: \u7b2c 442-450 \u884c</p>\n<pre class=\"codehilite\"><code class=\"language-c\">enum gptoss_status GPTOSS_ABI gptoss_model_get_tokenizer(\n    gptoss_model_t model,\n    gptoss_tokenizer_t* tokenizer_out)\n{\n    gptoss_tokenizer_t tokenizer = model-&gt;tokenizer;\n    atomic_fetch_add_explicit(&amp;tokenizer-&gt;ref_count, 1, memory_order_relaxed);\n    *tokenizer_out = tokenizer;\n    return gptoss_status_success;\n}\n</code></pre>\n\n<h4 id=\"gptoss_model_get_max_context_length\"><code>gptoss_model_get_max_context_length</code></h4>\n<p><strong>\u4f4d\u7f6e</strong>: \u7b2c 452-458 \u884c</p>\n<pre class=\"codehilite\"><code class=\"language-c\">enum gptoss_status GPTOSS_ABI gptoss_model_get_max_context_length(\n    gptoss_model_t model,\n    size_t* max_context_length_out)\n{\n    *max_context_length_out = model-&gt;context_length;\n    return gptoss_status_success;\n}\n</code></pre>\n\n<h3 id=\"_10\">\u5185\u5b58\u7ba1\u7406</h3>\n<h4 id=\"gptoss_model_retain\"><code>gptoss_model_retain</code> \u5f15\u7528\u8ba1\u6570\u589e\u52a0</h4>\n<p><strong>\u4f4d\u7f6e</strong>: \u7b2c 460-465 \u884c</p>\n<pre class=\"codehilite\"><code class=\"language-c\">enum gptoss_status GPTOSS_ABI gptoss_model_retain(gptoss_model_t model)\n{\n    atomic_fetch_add_explicit(&amp;model-&gt;ref_count, 1, memory_order_relaxed);\n    return gptoss_status_success;\n}\n</code></pre>\n\n<h4 id=\"gptoss_model_release\"><code>gptoss_model_release</code> \u8d44\u6e90\u91ca\u653e</h4>\n<p><strong>\u4f4d\u7f6e</strong>: \u7b2c 467-511 \u884c</p>\n<pre class=\"codehilite\"><code class=\"language-c\">enum gptoss_status GPTOSS_ABI gptoss_model_release(gptoss_model_t model)\n{\n    if (model != NULL) {\n        if (atomic_fetch_sub_explicit(&amp;model-&gt;ref_count, 1, memory_order_acq_rel) == 1) {\n            // \u91ca\u653e\u5206\u8bcd\u5668\n            gptoss_tokenizer_release(model-&gt;tokenizer);\n\n            // \u91ca\u653e\u6743\u91cd\u7f13\u51b2\u533a\n            gptoss_metal_buffer_release(&amp;model-&gt;shared_weight_buffer);\n            for (uint32_t n = 0; n &lt; model-&gt;num_blocks; n++) {\n                gptoss_metal_buffer_release(&amp;model-&gt;block_weight_buffers[n]);\n            }\n\n            // \u91ca\u653e Metal \u5185\u6838\u548c\u8d44\u6e90\n            gptoss_metal_function_release(&amp;model-&gt;bf16_f32_embeddings_fn);\n            // ... \u91ca\u653e\u6240\u6709\u5185\u6838\u51fd\u6570\n            gptoss_metal_library_release(&amp;model-&gt;library);\n            gptoss_metal_command_queue_release(&amp;model-&gt;command_queue);\n            gptoss_metal_device_release(&amp;model-&gt;device);\n\n            // \u89e3\u9664\u5185\u5b58\u6620\u5c04\n            if (model-&gt;mapping_ptr != NULL &amp;&amp; model-&gt;mapping_size != 0) {\n                if (munmap(model-&gt;mapping_ptr, model-&gt;mapping_size) != 0) {\n                    GPTOSS_LOG_WARNING(&quot;munmap for model weight mapping failed with error %d&quot;, errno);\n                }\n            }\n\n            // \u6e05\u96f6\u5e76\u91ca\u653e\u7ed3\u6784\u4f53\n            memset(model, 0, model_size);\n            free(model);\n        }\n    }\n    return gptoss_status_success;\n}\n</code></pre>\n\n<h2 id=\"_11\">\u5185\u5b58\u5e03\u5c40\u8bbe\u8ba1</h2>\n<h3 id=\"_12\">\u6743\u91cd\u5b58\u50a8\u7ed3\u6784</h3>\n<ol>\n<li><strong>\u5d4c\u5165\u6743\u91cd</strong>: \u8bcd\u6c47\u8868 \u00d7 \u5d4c\u5165\u7ef4\u5ea6</li>\n<li><strong>\u6bcf\u5c42\u5171\u4eab\u6743\u91cd</strong>: \n   - \u6ce8\u610f\u529b\u6743\u91cd (Q, K, V)\n   - \u6ce8\u610f\u529b\u8f93\u51fa\u6743\u91cd\n   - MLP \u95e8\u63a7\u6743\u91cd\n   - LayerNorm \u6743\u91cd</li>\n<li><strong>MoE \u4e13\u5bb6\u6743\u91cd</strong>: \u6bcf\u5c42\u7684\u4e13\u5bb6\u7279\u5b9a\u6743\u91cd</li>\n<li><strong>\u8f93\u51fa\u6743\u91cd</strong>: \u6700\u7ec8\u7684\u8bcd\u6c47\u8868\u6295\u5f71</li>\n</ol>\n<h3 id=\"_13\">\u5185\u5b58\u5bf9\u9f50\u7b56\u7565</h3>\n<ul>\n<li><strong>16\u5b57\u8282\u5bf9\u9f50</strong>: \u6240\u6709\u6743\u91cd\u7f13\u51b2\u533a16\u5b57\u8282\u5bf9\u9f50\uff0c\u4f18\u5316 Metal GPU \u8bbf\u95ee</li>\n<li><strong>\u9875\u9762\u5bf9\u9f50</strong>: \u5185\u5b58\u6620\u5c04\u533a\u57df\u9875\u9762\u5bf9\u9f50\uff0c\u63d0\u9ad8\u7cfb\u7edf\u6548\u7387</li>\n<li><strong>\u8fde\u7eed\u5e03\u5c40</strong>: \u6743\u91cd\u6309\u8bbf\u95ee\u6a21\u5f0f\u8fde\u7eed\u5b58\u50a8</li>\n</ul>\n<h2 id=\"metal-gpu\">Metal GPU \u96c6\u6210</h2>\n<h3 id=\"_14\">\u5185\u6838\u51fd\u6570\u5217\u8868</h3>\n<ul>\n<li><code>gptoss_bf16_f32_embeddings</code>: \u5d4c\u5165\u5c42\u8ba1\u7b97</li>\n<li><code>gptoss_f32_bf16w_rmsnorm</code>: RMSNorm \u5f52\u4e00\u5316</li>\n<li><code>gptoss_f32_bf16w_matmul</code>: \u77e9\u9635\u4e58\u6cd5</li>\n<li><code>gptoss_f32_rope</code>: RoPE \u4f4d\u7f6e\u7f16\u7801</li>\n<li><code>gptoss_f32_mf4w_moe_matmul_swiglu</code>: MoE + SwiGLU \u878d\u5408\u8ba1\u7b97</li>\n<li><code>gptoss_f32_topk_softmax_e*_k4</code>: Top-K Softmax \u8def\u7531</li>\n<li><code>gptoss_f32_sdpa_q8_d64</code>: \u7f29\u653e\u70b9\u79ef\u6ce8\u610f\u529b</li>\n</ul>\n<h3 id=\"_15\">\u8bbe\u5907\u7ba1\u7406</h3>\n<ul>\n<li><strong>\u7cfb\u7edf\u9ed8\u8ba4\u8bbe\u5907</strong>: \u81ea\u52a8\u9009\u62e9\u6700\u4f73 GPU</li>\n<li><strong>\u547d\u4ee4\u961f\u5217</strong>: \u7ba1\u7406 GPU \u8ba1\u7b97\u4efb\u52a1</li>\n<li><strong>\u7ebf\u7a0b\u7ec4\u914d\u7f6e</strong>: \u57fa\u4e8e GPU \u6838\u5fc3\u6570\u4f18\u5316\u5e76\u884c\u5ea6</li>\n</ul>\n<h2 id=\"_16\">\u9519\u8bef\u5904\u7406\u548c\u8bca\u65ad</h2>\n<h3 id=\"_17\">\u72b6\u6001\u7801\u7cfb\u7edf</h3>\n<pre class=\"codehilite\"><code class=\"language-c\">enum gptoss_status {\n    gptoss_status_success,\n    gptoss_status_invalid_argument,\n    gptoss_status_io_error,\n    gptoss_status_insufficient_memory,\n    // ...\n};\n</code></pre>\n\n<h3 id=\"_18\">\u65e5\u5fd7\u7cfb\u7edf</h3>\n<ul>\n<li><strong>\u5206\u7ea7\u65e5\u5fd7</strong>: ERROR, WARNING, INFO \u7b49\u7ea7\u522b</li>\n<li><strong>\u8be6\u7ec6\u4fe1\u606f</strong>: \u5305\u542b\u6587\u4ef6\u540d\u3001\u5927\u5c0f\u3001\u9519\u8bef\u7801\u7b49\u4e0a\u4e0b\u6587</li>\n<li><strong>\u8c03\u8bd5\u652f\u6301</strong>: \u4fbf\u4e8e\u95ee\u9898\u8bca\u65ad\u548c\u6027\u80fd\u5206\u6790</li>\n</ul>\n<h2 id=\"_19\">\u6027\u80fd\u4f18\u5316\u7279\u6027</h2>\n<h3 id=\"io_1\">I/O \u4f18\u5316</h3>\n<ul>\n<li><strong>\u5185\u5b58\u6620\u5c04</strong>: \u907f\u514d\u6570\u636e\u62f7\u8d1d\uff0c\u76f4\u63a5\u6620\u5c04\u6587\u4ef6\u5230\u5185\u5b58</li>\n<li><strong>\u9884\u53d6</strong>: \u4e3b\u52a8\u9884\u53d6\u5373\u5c06\u8bbf\u95ee\u7684\u6570\u636e</li>\n<li><strong>\u5206\u5757\u8bfb\u53d6</strong>: \u5927\u6587\u4ef6\u5206\u5757\u5904\u7406\u907f\u514d\u5185\u5b58\u538b\u529b</li>\n</ul>\n<h3 id=\"_20\">\u5185\u5b58\u4f18\u5316</h3>\n<ul>\n<li><strong>\u5f15\u7528\u8ba1\u6570</strong>: \u5b89\u5168\u7684\u8d44\u6e90\u5171\u4eab\u548c\u91ca\u653e</li>\n<li><strong>\u9875\u9762\u5bf9\u9f50</strong>: \u4f18\u5316\u7cfb\u7edf\u5185\u5b58\u7ba1\u7406</li>\n<li><strong>\u96f6\u62f7\u8d1d</strong>: \u6743\u91cd\u76f4\u63a5\u4ece\u6587\u4ef6\u6620\u5c04\u4f7f\u7528</li>\n</ul>\n<h3 id=\"gpu\">GPU \u4f18\u5316</h3>\n<ul>\n<li><strong>\u878d\u5408\u5185\u6838</strong>: \u591a\u4e2a\u64cd\u4f5c\u5408\u5e76\u4e3a\u5355\u4e2a GPU \u5185\u6838</li>\n<li><strong>\u6df7\u5408\u7cbe\u5ea6</strong>: BFloat16 \u548c FP32 \u6df7\u5408\u4f7f\u7528</li>\n<li><strong>\u4e13\u95e8\u5316</strong>: \u9488\u5bf9\u4e0d\u540c\u4e13\u5bb6\u6570\u91cf\u7684\u4e13\u95e8\u5185\u6838</li>\n</ul>\n<h2 id=\"_21\">\u4e0e\u5176\u4ed6\u6a21\u5757\u7684\u5173\u7cfb</h2>\n<h3 id=\"python\">Python \u63a5\u53e3</h3>\n<ul>\n<li>\u901a\u8fc7 Python C \u6269\u5c55\u66b4\u9732\u7ed9\u4e0a\u5c42</li>\n<li>\u652f\u6301 <code>gpt_oss.metal</code> \u6a21\u5757\u8c03\u7528</li>\n</ul>\n<h3 id=\"_22\">\u4f9d\u8d56\u6a21\u5757</h3>\n<ul>\n<li>\u5185\u90e8\u6570\u636e\u7c7b\u578b\u5b9a\u4e49 (<code>internal/datatype.h</code>)</li>\n<li>Metal GPU \u62bd\u8c61\u5c42 (<code>internal/metal.h</code>)</li>\n<li>\u6570\u5b66\u5de5\u5177\u51fd\u6570 (<code>internal/math.h</code>)</li>\n</ul>\n<h2 id=\"_23\">\u4f7f\u7528\u793a\u4f8b</h2>\n<pre class=\"codehilite\"><code class=\"language-c\">#include &lt;gpt-oss.h&gt;\n\nint main() {\n    gptoss_model_t model;\n    enum gptoss_status status;\n\n    // \u4ece\u6587\u4ef6\u52a0\u8f7d\u6a21\u578b\n    status = gptoss_model_create_from_file(&quot;model.gptoss&quot;, &amp;model);\n    if (status != gptoss_status_success) {\n        // \u9519\u8bef\u5904\u7406\n        return -1;\n    }\n\n    // \u83b7\u53d6\u5206\u8bcd\u5668\n    gptoss_tokenizer_t tokenizer;\n    gptoss_model_get_tokenizer(model, &amp;tokenizer);\n\n    // \u4f7f\u7528\u6a21\u578b...\n\n    // \u6e05\u7406\u8d44\u6e90\n    gptoss_tokenizer_release(tokenizer);\n    gptoss_model_release(model);\n\n    return 0;\n}\n</code></pre>\n\n<h2 id=\"_24\">\u6280\u672f\u4eae\u70b9</h2>\n<h3 id=\"1\">1. <strong>\u7cfb\u7edf\u7ea7\u4f18\u5316</strong></h3>\n<p>\u5145\u5206\u5229\u7528 Apple \u7cfb\u7edf\u7279\u6027\uff0c\u5982\u5185\u5b58\u6620\u5c04\u3001\u9884\u53d6\u7b49</p>\n<h3 id=\"2-gpu\">2. <strong>GPU \u539f\u751f\u652f\u6301</strong></h3>\n<p>\u6df1\u5ea6\u96c6\u6210 Metal GPU \u8ba1\u7b97\uff0c\u63d0\u4f9b\u6700\u4f73\u6027\u80fd</p>\n<h3 id=\"3\">3. <strong>\u5185\u5b58\u5b89\u5168</strong></h3>\n<p>\u4e25\u683c\u7684\u5f15\u7528\u8ba1\u6570\u548c\u8d44\u6e90\u7ba1\u7406\uff0c\u907f\u514d\u5185\u5b58\u6cc4\u6f0f</p>\n<h3 id=\"4\">4. <strong>\u9519\u8bef\u6062\u590d</strong></h3>\n<p>\u5b8c\u5584\u7684\u9519\u8bef\u5904\u7406\u548c\u8d44\u6e90\u6e05\u7406\u673a\u5236</p>\n<h3 id=\"5\">5. <strong>\u53ef\u79fb\u690d\u6027</strong></h3>\n<p>\u867d\u7136\u9488\u5bf9 Apple \u5e73\u53f0\u4f18\u5316\uff0c\u4f46\u4fdd\u6301\u4e86\u826f\u597d\u7684\u4ee3\u7801\u7ed3\u6784</p>\n<p>\u8fd9\u4e2a\u6a21\u5757\u4ee3\u8868\u4e86\u5728 Apple \u5e73\u53f0\u4e0a\u8fdb\u884c\u9ad8\u6027\u80fd AI \u63a8\u7406\u7684\u6700\u4f73\u5b9e\u8df5\uff0c\u5c06\u7cfb\u7edf\u7ea7\u4f18\u5316\u3001GPU \u8ba1\u7b97\u548c\u5185\u5b58\u7ba1\u7406\u5b8c\u7f8e\u7ed3\u5408\u3002</p>"
  },
  "../00_\u9879\u76ee\u603b\u89c8.md": {
    "hash": "212f20de00dbf7904979774ea0f5a17a",
    "content": "<h1 id=\"gpt-oss\">GPT-OSS \u9879\u76ee\u6280\u672f\u5206\u6790\u603b\u89c8</h1>\n<h2 id=\"_1\">\u9879\u76ee\u6982\u8ff0</h2>\n<p>GPT-OSS \u662f OpenAI \u5f00\u6e90\u7684\u5927\u8bed\u8a00\u6a21\u578b\u9879\u76ee\uff0c\u5305\u542b\u4e24\u4e2a\u6a21\u578b\u53d8\u4f53\uff1a</p>\n<ul>\n<li><strong>gpt-oss-120b</strong>: 117B \u53c2\u6570\uff0c5.1B \u6d3b\u8dc3\u53c2\u6570\uff0c\u9488\u5bf9\u751f\u4ea7\u73af\u5883\u4f18\u5316</li>\n<li><strong>gpt-oss-20b</strong>: 21B \u53c2\u6570\uff0c3.6B \u6d3b\u8dc3\u53c2\u6570\uff0c\u9002\u5408\u4f4e\u5ef6\u8fdf\u548c\u672c\u5730\u90e8\u7f72</li>\n</ul>\n<p>\u9879\u76ee\u91c7\u7528 Apache 2.0 \u8bb8\u53ef\u8bc1\uff0c\u63d0\u4f9b\u4e86\u5b8c\u6574\u7684\u63a8\u7406\u5b9e\u73b0\u3001\u5de5\u5177\u7cfb\u7edf\u548c API \u670d\u52a1\u3002</p>\n<h2 id=\"_2\">\u6838\u5fc3\u6280\u672f\u6808</h2>\n<h3 id=\"1\">1. \u6a21\u578b\u67b6\u6784</h3>\n<ul>\n<li><strong>Transformer</strong> \u57fa\u7840\u67b6\u6784 + <strong>MoE (Mixture of Experts)</strong> \u6df7\u5408\u4e13\u5bb6\u7cfb\u7edf</li>\n<li><strong>MXFP4</strong> \u539f\u751f\u91cf\u5316\u652f\u6301\uff084-bit \u91cf\u5316\uff0c16:1 \u538b\u7f29\u6bd4\uff09</li>\n<li><strong>RoPE</strong> \u4f4d\u7f6e\u7f16\u7801 + <strong>YaRN</strong> \u6269\u5c55</li>\n<li><strong>SwiGLU</strong> \u6fc0\u6d3b\u51fd\u6570</li>\n<li><strong>RMSNorm</strong> \u5f52\u4e00\u5316</li>\n<li><strong>GQA (Grouped Query Attention)</strong> \u5206\u7ec4\u67e5\u8be2\u6ce8\u610f\u529b</li>\n<li><strong>\u6ed1\u52a8\u7a97\u53e3\u6ce8\u610f\u529b</strong>\u673a\u5236</li>\n</ul>\n<h3 id=\"2\">2. \u63a8\u7406\u5f15\u64ce</h3>\n<ul>\n<li><strong>PyTorch</strong> \u53c2\u8003\u5b9e\u73b0\uff08\u6559\u80b2\u76ee\u7684\uff09</li>\n<li><strong>Triton</strong> \u4f18\u5316\u5b9e\u73b0\uff08\u751f\u4ea7\u7ea7\u522b\uff09</li>\n<li><strong>Metal</strong> \u5b9e\u73b0\uff08Apple Silicon\uff09</li>\n<li><strong>vLLM</strong> \u96c6\u6210</li>\n<li><strong>Ollama</strong> \u652f\u6301</li>\n</ul>\n<h3 id=\"3\">3. \u5de5\u5177\u751f\u6001</h3>\n<ul>\n<li><strong>Harmony</strong> \u6d88\u606f\u683c\u5f0f</li>\n<li><strong>\u6d4f\u89c8\u5668\u5de5\u5177</strong>\uff08\u641c\u7d22\u3001\u6253\u5f00\u3001\u67e5\u627e\uff09</li>\n<li><strong>Python \u6267\u884c\u5de5\u5177</strong>\uff08Docker \u5bb9\u5668\uff09</li>\n<li><strong>\u6587\u4ef6\u8865\u4e01\u5de5\u5177</strong>\uff08apply_patch\uff09</li>\n</ul>\n<h2 id=\"_3\">\u9879\u76ee\u7ed3\u6784</h2>\n<pre class=\"codehilite\"><code>gpt-oss/\n\u251c\u2500\u2500 gpt_oss/              # \u6838\u5fc3 Python \u5305\n\u2502   \u251c\u2500\u2500 torch/            # PyTorch \u63a8\u7406\u5b9e\u73b0\n\u2502   \u251c\u2500\u2500 triton/           # Triton \u4f18\u5316\u5b9e\u73b0\n\u2502   \u251c\u2500\u2500 metal/            # Metal GPU \u5b9e\u73b0\n\u2502   \u251c\u2500\u2500 tools/            # \u5de5\u5177\u7cfb\u7edf\n\u2502   \u251c\u2500\u2500 responses_api/    # API \u670d\u52a1\u5668\n\u2502   \u251c\u2500\u2500 chat.py           # \u4ea4\u4e92\u5f0f\u804a\u5929\n\u2502   \u251c\u2500\u2500 generate.py       # \u6587\u672c\u751f\u6210\n\u2502   \u2514\u2500\u2500 tokenizer.py      # \u5206\u8bcd\u5668\n\u251c\u2500\u2500 claude_doc/           # \u4e2d\u6587\u6280\u672f\u6587\u6863\n\u2514\u2500\u2500 examples/             # \u4f7f\u7528\u793a\u4f8b\n</code></pre>\n\n<h2 id=\"_4\">\u6838\u5fc3\u6a21\u5757\u5206\u6790</h2>\n<h3 id=\"_5\">\u63a8\u7406\u5c42</h3>\n<ol>\n<li><strong>torch/model.py</strong> - \u57fa\u7840 PyTorch \u6a21\u578b\u5b9e\u73b0 <a href=\"./01_torch_model.md\">\u8be6\u89c1\u6587\u6863</a></li>\n<li><strong>triton/model.py</strong> - GPU \u4f18\u5316\u63a8\u7406\u5f15\u64ce <a href=\"./02_triton_model.md\">\u8be6\u89c1\u6587\u6863</a></li>\n<li><strong>metal/source/model.c</strong> - Apple Silicon \u5b9e\u73b0 <a href=\"./09_metal_model.md\">\u8be6\u89c1\u6587\u6863</a></li>\n</ol>\n<h3 id=\"_6\">\u5e94\u7528\u5c42</h3>\n<ol start=\"4\">\n<li><strong>chat.py</strong> - \u4ea4\u4e92\u5f0f\u5bf9\u8bdd\u7cfb\u7edf <a href=\"./03_chat.md\">\u8be6\u89c1\u6587\u6863</a></li>\n<li><strong>generate.py</strong> - \u6587\u672c\u751f\u6210\u63a5\u53e3 <a href=\"./10_generate.md\">\u8be6\u89c1\u6587\u6863</a></li>\n<li><strong>responses_api/api_server.py</strong> - HTTP API \u670d\u52a1 <a href=\"./06_responses_api_server.md\">\u8be6\u89c1\u6587\u6863</a></li>\n</ol>\n<h3 id=\"_7\">\u57fa\u7840\u8bbe\u65bd</h3>\n<ol start=\"7\">\n<li><strong>tokenizer.py</strong> - Harmony \u683c\u5f0f\u5206\u8bcd\u5668 <a href=\"./04_tokenizer.md\">\u8be6\u89c1\u6587\u6863</a></li>\n<li><strong>torch/weights.py</strong> - \u6743\u91cd\u52a0\u8f7d\u548c\u91cf\u5316 <a href=\"./05_torch_weights.md\">\u8be6\u89c1\u6587\u6863</a></li>\n<li><strong>tools/tool.py</strong> - \u5de5\u5177\u7cfb\u7edf\u57fa\u7c7b <a href=\"./07_tools_tool.md\">\u8be6\u89c1\u6587\u6863</a></li>\n<li><strong>triton/moe.py</strong> - MoE \u4f18\u5316\u5b9e\u73b0 <a href=\"./08_triton_moe.md\">\u8be6\u89c1\u6587\u6863</a></li>\n</ol>\n<h2 id=\"_8\">\u5173\u952e\u6280\u672f\u672f\u8bed</h2>\n<h3 id=\"_9\">\u540d\u8bcd\u89e3\u91ca</h3>\n<ul>\n<li><strong>MoE</strong>: \u6df7\u5408\u4e13\u5bb6\u6a21\u578b\uff0c\u901a\u8fc7\u7a00\u758f\u6fc0\u6d3b\u964d\u4f4e\u8ba1\u7b97\u6210\u672c</li>\n<li><strong>MXFP4</strong>: \u5fae\u8f6f\u63d0\u51fa\u7684 4-bit \u6d6e\u70b9\u683c\u5f0f\uff0c\u7528\u4e8e\u6a21\u578b\u91cf\u5316</li>\n<li><strong>RoPE</strong>: \u65cb\u8f6c\u4f4d\u7f6e\u7f16\u7801\uff0c\u6539\u8fdb\u7684\u4f4d\u7f6e\u7f16\u7801\u65b9\u6cd5</li>\n<li><strong>YaRN</strong>: Yet another RoPE extensioN\uff0cRoPE \u7684\u6269\u5c55\u65b9\u6cd5</li>\n<li><strong>GQA</strong>: \u5206\u7ec4\u67e5\u8be2\u6ce8\u610f\u529b\uff0c\u51cf\u5c11 KV \u7f13\u5b58\u5185\u5b58\u5360\u7528</li>\n<li><strong>SwiGLU</strong>: Swish-Gated Linear Unit\uff0c\u9ad8\u6548\u7684\u6fc0\u6d3b\u51fd\u6570</li>\n<li><strong>Harmony</strong>: OpenAI \u7684\u6807\u51c6\u5316\u5bf9\u8bdd\u683c\u5f0f</li>\n<li><strong>Triton</strong>: OpenAI \u7684 GPU \u7f16\u7a0b\u8bed\u8a00\u548c\u7f16\u8bd1\u5668</li>\n</ul>\n<h3 id=\"_10\">\u4e3b\u8981\u64cd\u4f5c</h3>\n<ul>\n<li><strong>generate</strong>: \u751f\u6210 token \u5e8f\u5217</li>\n<li><strong>sample</strong>: \u4ece\u6982\u7387\u5206\u5e03\u91c7\u6837 token</li>\n<li><strong>forward</strong>: \u6a21\u578b\u524d\u5411\u4f20\u64ad</li>\n<li><strong>quantize/dequantize</strong>: \u91cf\u5316/\u53cd\u91cf\u5316\u6743\u91cd</li>\n<li><strong>route</strong>: MoE \u4e13\u5bb6\u8def\u7531</li>\n<li><strong>cache</strong>: KV \u72b6\u6001\u7f13\u5b58</li>\n<li><strong>stream</strong>: \u6d41\u5f0f\u54cd\u5e94\u751f\u6210</li>\n</ul>\n<h2 id=\"_11\">\u8c03\u7528\u5173\u7cfb\u56fe</h2>\n<pre class=\"codehilite\"><code class=\"language-mermaid\">graph TD\n    A[\u7528\u6237\u8f93\u5165] --&gt; B[chat.py/generate.py]\n    B --&gt; C[TokenGenerator\u63a5\u53e3]\n    C --&gt; D1[TorchGenerator]\n    C --&gt; D2[TritonGenerator]\n    C --&gt; D3[VLLMGenerator]\n    D1 --&gt; E[torch/model.py]\n    D2 --&gt; F[triton/model.py]\n    E --&gt; G[torch/weights.py]\n    F --&gt; H[triton/moe.py]\n    B --&gt; I[Harmony Tokenizer]\n    B --&gt; J[\u5de5\u5177\u7cfb\u7edf]\n    J --&gt; K[\u6d4f\u89c8\u5668\u5de5\u5177]\n    J --&gt; L[Python\u5de5\u5177]\n    J --&gt; M[\u8865\u4e01\u5de5\u5177]\n    N[API Server] --&gt; C\n    N --&gt; J\n</code></pre>\n\n<h2 id=\"_12\">\u6027\u80fd\u7279\u6027</h2>\n<h3 id=\"_13\">\u5185\u5b58\u4f18\u5316</h3>\n<ul>\n<li>MXFP4 \u91cf\u5316\u51cf\u5c11 75% \u6743\u91cd\u5185\u5b58</li>\n<li>KV \u7f13\u5b58\u5faa\u73af\u590d\u7528</li>\n<li>\u5206\u5757\u52a0\u8f7d\u907f\u514d OOM</li>\n<li>CUDA \u7edf\u4e00\u5185\u5b58\u652f\u6301</li>\n</ul>\n<h3 id=\"_14\">\u8ba1\u7b97\u4f18\u5316</h3>\n<ul>\n<li>Triton \u81ea\u5b9a\u4e49 CUDA \u5185\u6838</li>\n<li>\u878d\u5408\u64cd\u4f5c\u51cf\u5c11\u5185\u5b58\u8bbf\u95ee</li>\n<li>CUDA \u56fe\u4f18\u5316\u63a8\u7406\u5ef6\u8fdf</li>\n<li>\u7a00\u758f MoE \u51cf\u5c11\u8ba1\u7b97\u91cf</li>\n</ul>\n<h3 id=\"_15\">\u6269\u5c55\u6027</h3>\n<ul>\n<li>\u5206\u5e03\u5f0f\u5f20\u91cf\u5e76\u884c</li>\n<li>\u591a GPU \u652f\u6301</li>\n<li>\u6d41\u5f0f\u751f\u6210</li>\n<li>\u5f02\u6b65\u5de5\u5177\u8c03\u7528</li>\n</ul>\n<h2 id=\"_16\">\u4f7f\u7528\u573a\u666f</h2>\n<ol>\n<li><strong>\u751f\u4ea7\u90e8\u7f72</strong>: \u4f7f\u7528 Triton \u540e\u7aef + API \u670d\u52a1\u5668</li>\n<li><strong>\u672c\u5730\u5f00\u53d1</strong>: \u4f7f\u7528 Ollama \u6216 vLLM</li>\n<li><strong>\u7814\u7a76\u5b9e\u9a8c</strong>: \u4f7f\u7528 PyTorch \u53c2\u8003\u5b9e\u73b0</li>\n<li><strong>Apple \u8bbe\u5907</strong>: \u4f7f\u7528 Metal \u5b9e\u73b0</li>\n<li><strong>\u5de5\u5177\u589e\u5f3a</strong>: \u96c6\u6210\u6d4f\u89c8\u5668\u548c Python \u5de5\u5177</li>\n</ol>\n<h2 id=\"_17\">\u9879\u76ee\u7279\u70b9</h2>\n<ol>\n<li><strong>\u5b8c\u6574\u6027</strong>: \u63d0\u4f9b\u4ece\u6a21\u578b\u5230 API \u7684\u5b8c\u6574\u5b9e\u73b0</li>\n<li><strong>\u6a21\u5757\u5316</strong>: \u6e05\u6670\u7684\u6a21\u5757\u5212\u5206\uff0c\u6613\u4e8e\u7406\u89e3\u548c\u6269\u5c55</li>\n<li><strong>\u591a\u540e\u7aef</strong>: \u652f\u6301\u591a\u79cd\u63a8\u7406\u5f15\u64ce\uff0c\u9002\u5e94\u4e0d\u540c\u573a\u666f</li>\n<li><strong>\u5de5\u5177\u96c6\u6210</strong>: \u539f\u751f\u652f\u6301\u5de5\u5177\u8c03\u7528\uff0c\u589e\u5f3a\u6a21\u578b\u80fd\u529b</li>\n<li><strong>\u4f18\u5316\u5145\u5206</strong>: \u4ece\u7b97\u6cd5\u5230\u7cfb\u7edf\u7684\u5168\u65b9\u4f4d\u4f18\u5316</li>\n<li><strong>\u5f00\u6e90\u53cb\u597d</strong>: Apache 2.0 \u8bb8\u53ef\uff0c\u65e0\u4e13\u5229\u98ce\u9669</li>\n</ol>\n<h2 id=\"_18\">\u6587\u6863\u7d22\u5f15</h2>\n<ol>\n<li><a href=\"./01_torch_model.md\">PyTorch \u6a21\u578b\u5b9e\u73b0</a></li>\n<li><a href=\"./02_triton_model.md\">Triton \u4f18\u5316\u5f15\u64ce</a></li>\n<li><a href=\"./03_chat.md\">\u4ea4\u4e92\u5f0f\u804a\u5929\u7cfb\u7edf</a></li>\n<li><a href=\"./04_tokenizer.md\">Harmony \u5206\u8bcd\u5668</a></li>\n<li><a href=\"./05_torch_weights.md\">\u6743\u91cd\u52a0\u8f7d\u7cfb\u7edf</a></li>\n<li><a href=\"./06_responses_api_server.md\">API \u670d\u52a1\u5668</a></li>\n<li><a href=\"./07_tools_tool.md\">\u5de5\u5177\u7cfb\u7edf\u57fa\u7c7b</a></li>\n<li><a href=\"./08_triton_moe.md\">MoE \u4f18\u5316\u5b9e\u73b0</a></li>\n<li><a href=\"./09_metal_model.md\">Metal GPU \u540e\u7aef</a></li>\n<li><a href=\"./10_generate.md\">\u6587\u672c\u751f\u6210\u63a5\u53e3</a></li>\n</ol>\n<hr />\n<p>\u672c\u6587\u6863\u96c6\u5408\u4e3a GPT-OSS \u9879\u76ee\u7684\u5b8c\u6574\u6280\u672f\u5206\u6790\uff0c\u65e8\u5728\u5e2e\u52a9\u7406\u89e3\u9879\u76ee\u67b6\u6784\u3001\u6838\u5fc3\u6280\u672f\u548c\u5b9e\u73b0\u7ec6\u8282\uff0c\u4e3a\u9879\u76ee\u91cd\u5199\u6216\u4e8c\u6b21\u5f00\u53d1\u63d0\u4f9b\u6280\u672f\u57fa\u7840\u3002</p>"
  }
}